{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ${CUDA_DIR}/nvvm/libdevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "!set TF_GPU_THREAD_MODE=gpu_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import math\n",
    "from json import dumps\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(f\"gpus={gpus}\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten,\\\n",
    "                                    Reshape, LeakyReLU as LR,\\\n",
    "                                    Activation, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display # If using IPython, Colab or Jupyter\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://drive.google.com/uc?export=download&id=0B7EVK8r0v71pZjFTYXZWM3FlRnM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vertical_lines_noise(x, shifts=2, line_height=2):\n",
    "    x = np.copy(x)\n",
    "    axis_for_roll = 1\n",
    "    y = np.roll(x, -shifts, axis=axis_for_roll)\n",
    "    j = 0\n",
    "    for i in range(x.shape[axis_for_roll]):\n",
    "        if j <= line_height:\n",
    "            x[:,i,:] = y[:,i,:]\n",
    "            \n",
    "        j+=1\n",
    "        if j == line_height * 2:\n",
    "            j = 0\n",
    "#     print(x.shape)\n",
    "    return x\n",
    "\n",
    "def add_horizontal_lines_noise(x, shifts=2, line_height=2):\n",
    "    x = np.copy(x)\n",
    "    axis_for_roll = 0\n",
    "    y = np.roll(x, -shifts, axis=1)\n",
    "    j = 0\n",
    "    for i in range(x.shape[axis_for_roll]):\n",
    "        if j <= line_height:\n",
    "            x[i,:,:] = y[i,:,:]\n",
    "            \n",
    "        \n",
    "        if j == line_height * 2:\n",
    "            j = 0\n",
    "        else:\n",
    "            j+=1\n",
    "#     print(x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from functools import reduce\n",
    "splits = tfds.even_splits('train', n=200, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_H = 480\n",
    "IMG_W = 720\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_len = 7164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 3\n",
    "# EPOCHS=100\n",
    "# steps_per_epoch=int(train_len/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def unsharp(x):\n",
    "    image = Image.fromarray(x)\n",
    "    return image.filter(ImageFilter.UnsharpMask(radius=2, percent=150))\n",
    "\n",
    "def pixelation_noise(x, ranges=[1/3]):\n",
    "    downsize_image_ratio = random.choice(ranges)\n",
    "    sh = tf.cast(tf.shape(x), tf.float32)\n",
    "    \n",
    "    resized_size_h = sh[0]\n",
    "    resized_size_w = sh[1]\n",
    "    down = tf.image.resize(\n",
    "        x,\n",
    "        [tf.cast(resized_size_h * downsize_image_ratio, tf.int32), tf.cast(resized_size_w * downsize_image_ratio, tf.int32)],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "    x= tf.image.resize(\n",
    "        down,\n",
    "        [resized_size_h, resized_size_w],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "    return x\n",
    "\n",
    "def random_invert_img(x, p=0.5):\n",
    "    if  tf.random.uniform([]) < p:\n",
    "        x = (255-x)\n",
    "    else:\n",
    "        x\n",
    "    return x\n",
    "\n",
    "def random_apply_saturation(x, p=0.5):\n",
    "    if  tf.random.uniform([]) < p:\n",
    "        return tf.image.random_saturation(x, 5, 10)\n",
    "    return x\n",
    "\n",
    "def augment_img(x):\n",
    "#     x = tf.image.stateless_random_brightness(x, 0.2, seed)\n",
    "#     x = tf.image.random_contrast(x, 0.2, 0.5)\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    x = random_invert_img(x, p=0.4)\n",
    "    x = random_apply_saturation(x, p=0.4)\n",
    "    return x\n",
    "\n",
    "# def split_fn(x, y):\n",
    "#     print(x, y)\n",
    "#     return tf.image.resize(x, size=[480, 720]), y\n",
    "\n",
    "@tf.function\n",
    "def random_noise_and_resize(y):\n",
    "    def rn(x): \n",
    "        ts = [\n",
    "            lambda x: add_horizontal_lines_noise(x, random.randint(-10, -8), random.randint(2, 5)),\n",
    "            pixelation_noise,\n",
    "#             lambda x: unsharp(np.array(x)), \n",
    "            lambda x: add_horizontal_lines_noise(pixelation_noise(x,ranges=[1/3]), random.randint(-10, -8), random.randint(2, 5))\n",
    "             ]\n",
    "        fn = random.choice(ts)\n",
    "\n",
    "        return fn(x)\n",
    "    \n",
    "    x = tf.image.resize(y, size=[480, 720])\n",
    "    return tf.numpy_function(func=rn, inp=[x], Tout=tf.float32), y\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def random_noise(y):\n",
    "    def rn(x): \n",
    "        ts = [\n",
    "            lambda x: add_horizontal_lines_noise(x, random.randint(-10, -8), random.randint(2, 5)),\n",
    "            pixelation_noise,\n",
    "#             lambda x: unsharp(np.array(x)), \n",
    "            lambda x: add_horizontal_lines_noise(pixelation_noise(x,ranges=[1/3]), random.randint(-10, -8), random.randint(2, 5))\n",
    "             ]\n",
    "        fn = random.choice(ts)\n",
    "\n",
    "        return fn(x)\n",
    "\n",
    "    return tf.numpy_function(func=rn, inp=[y], Tout=tf.float32), y\n",
    "\n",
    "\n",
    "def set_shapes(image, label):\n",
    "    image.set_shape((480, 720, 3))\n",
    "    label.set_shape((720, 1080, 3))\n",
    "    return image, label\n",
    "\n",
    "def ccast(x, y):\n",
    "    return tf.cast(x, tf.float16), tf.cast(y, tf.float16)\n",
    "\n",
    "def div2k_ds(split):\n",
    "    return tfds.load('div2k', split=split, shuffle_files=True)\\\n",
    "        .map(lambda x: x[\"hr\"])\\\n",
    "        .map(lambda y:tf.image.resize_with_crop_or_pad(y, 720, 1080))\\\n",
    "        .map(lambda z: tf.cast(z, tf.float16))\\\n",
    "        .map(augment_img)\\\n",
    "        .map(random_noise_and_resize)\\\n",
    "        .map(set_shapes)\\\n",
    "        .map(ccast)\\\n",
    "\n",
    "def div2k_ds_same_size(split):\n",
    "    return tfds.load('div2k', split=split, shuffle_files=True)\\\n",
    "        .map(lambda x: x[\"hr\"])\\\n",
    "        .map(lambda y:tf.image.resize_with_crop_or_pad(y, 480, 720))\\\n",
    "        .map(lambda z: tf.cast(z, tf.float16))\\\n",
    "        .map(augment_img)\\\n",
    "        .map(random_noise_and_resize)\\\n",
    "        .map(set_shapes)\n",
    "\n",
    "div2k_ds_train = div2k_ds('train').batch(2)\n",
    "div2k_ds_test = div2k_ds('validation').batch(2)\n",
    "\n",
    "# # i = iter(div2k_ds_train)\n",
    "# # for j in range(3):\n",
    "# #     x, y = next(i)\n",
    "# #     plt.figure()\n",
    "# #     plt.imshow(tf.cast(x, tf.uint8))\n",
    "# #     plt.figure()\n",
    "# #     plt.imshow(tf.cast(y, tf.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import NoiseUtil, ImgUtils, DataLoader, DataManager\n",
    "\n",
    "           \n",
    "# def add_noise(x,y):\n",
    "#     downsize_image_ratio = random.choice([1/5])\n",
    "#     sh = tf.cast(tf.shape(x), tf.float32)\n",
    "    \n",
    "#     print(x)\n",
    "    \n",
    "#     resized_size_h = sh[0]\n",
    "#     resized_size_w = sh[1]\n",
    "#     down = tf.image.resize(\n",
    "#         x,\n",
    "#         [tf.cast(resized_size_h * downsize_image_ratio, tf.int32), tf.cast(resized_size_w * downsize_image_ratio, tf.int32)],\n",
    "#         preserve_aspect_ratio=True,\n",
    "#         antialias=False,\n",
    "#         name=None)\n",
    "    \n",
    "    \n",
    "\n",
    "#     x= tf.image.resize(\n",
    "#         down,\n",
    "#         [resized_size_h, resized_size_w],\n",
    "#         preserve_aspect_ratio=True,\n",
    "#         antialias=False,\n",
    "#         name=None)\n",
    "        \n",
    "#     return tf.reshape(x, (resized_size_h, resized_size_w, 3)), y\n",
    "    \n",
    "    \n",
    "# #     print(x.shape)\n",
    "\n",
    "    \n",
    "# #     n = NoiseUtil.pixel_noise(x, random.choice([50,60]), 15, downsize_image_ratios=[1/4, 1/6])\n",
    "\n",
    "# #     n = x + 0.2 * tf.random.normal(\n",
    "# #         x.shape[1:],\n",
    "# #         mean=0.0,\n",
    "# #         stddev=1.0,\n",
    "# #         dtype=tf.dtypes.float32,\n",
    "# #     )\n",
    "\n",
    "# #     return n,y\n",
    "\n",
    "# random_bright = tf.keras.layers.RandomBrightness(factor=0.2)\n",
    "# random_contrast = tf.keras.layers.RandomContrast(factor=0.2)\n",
    "# random_flip = tf.keras.layers.RandomFlip()\n",
    "\n",
    "\n",
    "# def augment(x):\n",
    "# #     seed = (random.randint(0, 100),random.randint(0, 100))\n",
    "#     x = random_bright(x, training=False)\n",
    "#     x = random_contrast(x, training=False)\n",
    "#     x = random_flip(x, training=False)\n",
    "#     return x\n",
    "\n",
    "# def saturation(x):\n",
    "#     return tf.image.random_saturation(x, 5, 10)\n",
    "\n",
    "# def get_train_data():\n",
    "#     return tf.data.Dataset.from_generator(train_gen, output_signature=tf.TensorSpec(shape=(480, 720, 3)))\n",
    "    \n",
    "# def get_test_data():\n",
    "#     return tf.data.Dataset.from_generator(test_gen, output_signature=tf.TensorSpec(shape=(480, 720, 3)))\n",
    "\n",
    "\n",
    "# def get_dist_ds(ds, ds_len):\n",
    "#     c = ds.map(normm).map(expp).map(augment)\n",
    "#     a = c.map(lambda y: (y,1))\n",
    "#     b = c.map(lambda y: (y,0)).map(add_noise)\n",
    "#     return a.concatenate(b).batch(BATCH_SIZE)\n",
    "\n",
    "# def get_gen_ds(ds):\n",
    "#     return ds.map(augment).map(lambda x: (x,x)).map(add_noise).batch(BATCH_SIZE)\n",
    "\n",
    "# # train_ds = get_gen_ds(get_train_data())\n",
    "# # test_ds = get_gen_ds(get_test_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig:\n",
    "    def __init__(self,\n",
    "                 dropout_rate=0.1,\n",
    "                 ff_dropout_rate=0.4,\n",
    "                 kernel_regularizer = tf.keras.regularizers.L2(0.001),\n",
    "                 learning_rate=[5e-5, 1e-5, 9e-6, 7e-6],\n",
    "                optimizer=\"adamf\"):\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        self.ff_dropout_rate = ff_dropout_rate\n",
    "        self.learning_rate =learning_rate\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def to_map(self):\n",
    "        return {\"dropout_rate\":self.dropout_rate, \"kernel_regularizer\":self.kernel_regularizer.get_config(), \"ff_dropout_rate\":self.ff_dropout_rate, \"learning_rate\":self.learning_rate, \"optimizer\": self.optimizer}\n",
    "\n",
    "    def to_hp_map(self):\n",
    "        assert self.kernel_regularizer.get_config()[\"l2\"] is not None\n",
    "        return {\"dropout_rate\":self.dropout_rate, \"kernel_regularizer\":self.kernel_regularizer.get_config()[\"l2\"], \"ff_dropout_rate\":self.ff_dropout_rate}\n",
    "    \n",
    "    def toString(self):\n",
    "        return dumps(self.to_map())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.toString()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def now():\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime('%Y_%m_%d_T%H_%M_%S') + ('_%02d' % (now.microsecond / 10000))\n",
    "\n",
    "def minute():\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime('%H_%M') \n",
    "\n",
    "minute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MetricsManager:\n",
    "#     def __init__(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# HP_NUM_UNITS = hp.HParam('dropout_rate', hp.Discrete([0.1, 0.2]))\n",
    "# HP_DROPOUT = hp.HParam('ff_dropout_rate', hp.Discrete([0.1,0.4]))\n",
    "# HP_OPTIMIZER = hp.HParam('kernel_regularizer', hp.Discrete([\n",
    "#     tf.keras.regularizers.L2(1e-2),\n",
    "#     tf.keras.regularizers.L2(1e-5),\n",
    "# ]))\n",
    "# class HpSearch():\n",
    "#     def __init__(self, log_dir):\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "METRIC_LOSS = 'loss'\n",
    "METRIC_MSE = 'mse'\n",
    "\n",
    "class TensorboardHPSearch():\n",
    "    def __init__(self, log_dir, name, prefix=f\"t{minute()}\", v=1):\n",
    "        self.log_dir_base = log_dir\n",
    "        self.log_dir = f\"{log_dir}/{name}\"\n",
    "        self.log_dir_name = name\n",
    "        self.prefix = prefix\n",
    "        self.hp_writer = tf.summary.create_file_writer(self.log_dir)\n",
    "\n",
    "        \n",
    "    def init(self, config):\n",
    "#         with self.hp_writer.as_default():\n",
    "#             hp.hparams(config.to_hp_map())\n",
    "        print(f\"HPs: {config.to_hp_map()}, logdir={self.log_dir}\")\n",
    "        return hp.KerasCallback(self.log_dir, config.to_hp_map())\n",
    "            \n",
    "    def log_results(self, name, loss, accuracy, mse):\n",
    "        with tf.summary.create_file_writer(f\"{self.log_dir_base}/{name}\").as_default():\n",
    "            tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "            tf.summary.scalar(METRIC_LOSS, loss, step=1)\n",
    "            tf.summary.scalar(METRIC_MSE, mse, step=1)\n",
    "\n",
    "        \n",
    "    def hp_search(self,\n",
    "                  dropout_rate=[0.1, 0.2],\n",
    "                  ff_dropout_rate=[0.1,0.4],\n",
    "                  regularizers=[1e-2,1e-5],\n",
    "                  learning_rate=[(5e-5, 7e-6)],\n",
    "                  optimizer=[\"adamf\", \"adam\"],\n",
    "                  run=lambda config, callback, name:0):\n",
    "        \n",
    "        DROPOUT_RATE = hp.HParam('dropout_rate', hp.Discrete(dropout_rate))\n",
    "        FF_DROPOUT_RATE = hp.HParam('ff_dropout_rate', hp.Discrete(ff_dropout_rate))\n",
    "        KERNEL_REGULARIZER = hp.HParam('kernel_regularizer', hp.Discrete(regularizers))\n",
    "        LR = hp.HParam('learning_rate', hp.Discrete(map(lambda x: str(x), learning_rate)))\n",
    "        OPTIMIZER = hp.HParam('optimizer', hp.Discrete(optimizer))\n",
    "\n",
    "        \n",
    "        with self.hp_writer.as_default():\n",
    "    #                         group = f\"t{t}/validation\"\n",
    "            hp.hparams_config(\n",
    "                hparams=[DROPOUT_RATE, FF_DROPOUT_RATE, KERNEL_REGULARIZER, LR, OPTIMIZER],\n",
    "                metrics=[\n",
    "                    hp.Metric(METRIC_ACCURACY, display_name='Accuracy'),\n",
    "                    hp.Metric(METRIC_LOSS, display_name='Perceptual Loss'),\n",
    "                    hp.Metric(METRIC_MSE, display_name='MSE')\n",
    "                ],\n",
    "            )\n",
    "                        \n",
    "        configs = []\n",
    "        t = 1\n",
    "        for dr in DROPOUT_RATE.domain.values:\n",
    "            for ffdr in FF_DROPOUT_RATE.domain.values:\n",
    "                for reg in KERNEL_REGULARIZER.domain.values:\n",
    "                    for lr in learning_rate: \n",
    "                        for opt in OPTIMIZER.domain.values:\n",
    "                            config = TrainingConfig(dropout_rate=dr, ff_dropout_rate=ffdr,\n",
    "                                                   kernel_regularizer=tf.keras.regularizers.L2(reg),\n",
    "                                                   learning_rate=lr,\n",
    "                                                   optimizer=opt)\n",
    "\n",
    "                            hpConfig = {\n",
    "                                DROPOUT_RATE:dr,\n",
    "                                FF_DROPOUT_RATE: ffdr,\n",
    "                                KERNEL_REGULARIZER: reg,\n",
    "                                LR: str(lr),\n",
    "                                OPTIMIZER:opt\n",
    "                            }\n",
    "                            run(config, hp.KerasCallback(\n",
    "                                f\"{self.log_dir}/{self.prefix}{t}\", hpConfig, trial_id = f\"{self.prefix}{t}\"),\n",
    "                                f\"{self.log_dir_name}/{self.prefix}{t}\")\n",
    "                            configs.append(config)\n",
    "                            t += 1\n",
    "        return configs\n",
    "\n",
    "class TensorboardUtil():\n",
    "    def __init__(self, log_dir):\n",
    "        self.log_dir = log_dir\n",
    "        self.file_writer = tf.summary.create_file_writer(log_dir)\n",
    "        self.hp_writer = tf.summary.create_file_writer(f\"t_{log_dir}/{now()}\")\n",
    "        \n",
    "    def log_text(self, data, name, step=0):\n",
    "        with self.file_writer.as_default():\n",
    "            tf.summary.text(name, data, step=step, description=None)\n",
    "            \n",
    "    def log_scalar(self, value, name, step=0):\n",
    "        with self.file_writer.as_default():\n",
    "            tf.summary.scalar(name, value, step=step)            \n",
    "    \n",
    "#         hp.KerasCallback(logdir, hparams)\n",
    "\n",
    "    def save_image(self, image, label, step=0):\n",
    "        with self.file_writer.as_default():\n",
    "            print(f\"Saved {label} to Tensorboard\")\n",
    "            tf.summary.image(label, image, step=step)\n",
    "        \n",
    "    def get_callback(self, profile_batch=0):\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir = self.log_dir,\n",
    "                      write_graph=True,\n",
    "                      histogram_freq = 1,\n",
    "                      profile_batch=profile_batch)\n",
    "\n",
    "# tb_util = TensorboardUtil(\"test\")\n",
    "# [s.toString() for s in tb_util.hp_search()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.vgg16 import VGG16\n",
    "# from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "# import tensorflow.keras.backend as K\n",
    "\n",
    "# def build_perceptual_loss(input_shape=(480, 720, 3)):\n",
    "#     print(input_shape)\n",
    "#     vgg = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "#     vgg.trainable = False ## Not trainable weights\n",
    "\n",
    "\n",
    "#     selected_layers = ['block1_conv1', 'block2_conv2',\"block3_conv3\" ,'block4_conv3','block5_conv3']\n",
    "#     selected_layer_weights = [1.0, 4.0 , 4.0 , 8.0 , 16.0]\n",
    "\n",
    "\n",
    "#     outputs = [vgg.get_layer(l).output for l in selected_layers]\n",
    "#     prediction_model = Model(vgg.input, outputs, name=\"perceptual_loss_model\")\n",
    "#     prediction_model.trainable = False\n",
    "\n",
    "#     @tf.function\n",
    "#     def perceptual_loss(input_image , reconstruct_image):\n",
    "#         input_image = tf.keras.applications.vgg16.preprocess_input(input_image)\n",
    "#         reconstruct_image = tf.keras.applications.vgg16.preprocess_input(reconstruct_image)\n",
    "\n",
    "#         h1_list = prediction_model(input_image, training=False)\n",
    "#         h2_list = prediction_model(reconstruct_image, training=False)\n",
    "\n",
    "#         rc_loss = 0.0\n",
    "\n",
    "#         for h1, h2, weight in zip(h1_list, h2_list, selected_layer_weights):\n",
    "#             h1 = K.batch_flatten(h1)\n",
    "#             h2 = K.batch_flatten(h2)\n",
    "#             rc_loss = rc_loss + weight * K.sum(K.square(h1 - h2), axis=-1)\n",
    "\n",
    "#         return rc_loss\n",
    "    \n",
    "#     return perceptual_loss\n",
    "\n",
    "# build_perceptual_loss(input_shape=(480, 720, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "\n",
    "class LossNetwork(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(LossNetwork, self).__init__()\n",
    "        vgg = VGG16(include_top=False, weights='imagenet')\n",
    "        vgg.trainable = False\n",
    "        \n",
    "        self.selected_layers = ['block1_conv1', 'block2_conv2',\"block3_conv3\" ,'block4_conv3','block5_conv3']\n",
    "        self.selected_layer_weights = [0.1, 0.4 , 0.4 , 0.8 , 1.6]\n",
    "        \n",
    "        model_outputs = [vgg.get_layer(name).output for name in self.selected_layers]\n",
    "        self.model = tf.keras.models.Model(vgg.input, model_outputs)\n",
    "        # mixed precision float32 output\n",
    "        self.linear = layers.Activation('linear', dtype='float32') \n",
    "\n",
    "    def call(self, x):\n",
    "        x = preprocess_input(x)\n",
    "        x = self.model(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @tf.function\n",
    "    def loss(self, x, y):\n",
    "        h1_list = self.model(x)\n",
    "        h2_list = self.model(y)\n",
    "        \n",
    "        rc_loss = 0.0\n",
    "        \n",
    "        for h1, h2, weight in zip(h1_list, h2_list, self.selected_layer_weights):\n",
    "            h1 = tf.cast(h1, tf.float32)\n",
    "            h2 = tf.cast(h2, tf.float32)\n",
    "            h1 = K.batch_flatten(h1)\n",
    "            h2 = K.batch_flatten(h2)\n",
    "            rc_loss = rc_loss + tf.cast(tf.reduce_mean((h1 - h2)**2), tf.float32) * weight   \n",
    "            rc_loss = tf.cast(rc_loss, tf.float32)\n",
    "      \n",
    "        return rc_loss\n",
    "\n",
    "class PeceptualLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super(PeceptualLoss, self).__init__()\n",
    "        self.loss_network = LossNetwork()\n",
    "        self.loss_network.trainable = False\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        return self.loss_network.loss(y_true,y_pred)\n",
    "\n",
    "    \n",
    "def build_perceptual_loss(*args, **kwargs):\n",
    "    return PeceptualLoss()\n",
    "\n",
    "x = tf.zeros((1,720,1080,3))\n",
    "y = tf.ones((1,720,1080,3)) * 255.\n",
    "ploss = build_perceptual_loss()\n",
    "ploss(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRenderer():\n",
    "    def __init__(self, batch_size, max_size=20):\n",
    "            self.batch_size = batch_size\n",
    "            self.tb_util = None\n",
    "            self.save = False\n",
    "            self.max_size = max_size\n",
    "            self.tb_dataset = None\n",
    "\n",
    "    def withTensorboard(self, tensorboard_util, tb_sample=4, tb_batch=4):\n",
    "        self.tb_util = tensorboard_util\n",
    "        self.tb_batch = tb_batch\n",
    "        self.tb_sample = tb_sample\n",
    "        return self\n",
    "    \n",
    "    def saveImages(self, path):\n",
    "        self.save = True\n",
    "        self.save_path = path\n",
    "        return self\n",
    "    \n",
    "    def render(self, model, datasets=([], []), batch=1):\n",
    "        batch_size = self.batch_size\n",
    "        train_ds, test_ds = datasets\n",
    "        \n",
    "        if self.tb_dataset is None:\n",
    "            self.tb_dataset = [(x,y) for x,y in test_ds.map(lambda x,y: (x[0], y[0])).take(self.tb_batch).batch(self.tb_batch)]\n",
    "        \n",
    "        def save_to_tb():\n",
    "            results = [(model(x),x, y) for x,y in self.tb_dataset]\n",
    "            for x,x_prev, y in results:\n",
    "                x = tf.cast(x, tf.uint8)\n",
    "                x_prev = tf.cast(x_prev, tf.uint8)\n",
    "                y = tf.cast(y, tf.uint8)\n",
    "                if self.tb_util is not None:\n",
    "                    self.tb_util.save_image(x, f\"denoised\", batch)\n",
    "                    self.tb_util.save_image(x_prev, f\"with_noise\", batch)\n",
    "                    self.tb_util.save_image(y, f\"original\", batch)\n",
    "        save_to_tb()\n",
    "                \n",
    "        dataset = test_ds.map(lambda x,y: (x[0], y[0])).take(batch_size).batch(batch_size)\n",
    "                \n",
    "        rows = batch_size\n",
    "        cols = 3\n",
    "        results = [(model(x),x, y) for x,y in dataset]\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "        plt.figure(figsize=((self.max_size+15) / cols, self.max_size / rows))\n",
    "        for x,x_prev, y in results:\n",
    "            x = tf.cast(x, tf.uint8)\n",
    "            x_prev = tf.cast(x_prev, tf.uint8)\n",
    "            y = tf.cast(y, tf.uint8)\n",
    "\n",
    "            for i in range(x.shape[0]):\n",
    "                im = x[i,:,:,:]\n",
    "                plt.subplot(cols, rows, i+1)\n",
    "                plt.imshow(im)\n",
    "                plt.title(\"Denoised\")\n",
    "                plt.axis('off')\n",
    "\n",
    "            for i in range(x_prev.shape[0]):\n",
    "                im = x_prev[i,:,:,:]\n",
    "                plt.subplot(cols, rows, i+x_prev.shape[0]+1)\n",
    "                plt.imshow(im)\n",
    "                plt.title(\"With noise\")\n",
    "                plt.axis('off')\n",
    "\n",
    "\n",
    "            for i in range(y.shape[0]):\n",
    "                im = y[i,:,:,:]\n",
    "                plt.subplot(cols, rows, i+x.shape[0]+x_prev.shape[0]+1)\n",
    "                plt.imshow(im)\n",
    "                plt.title(\"Original\")\n",
    "                plt.axis('off')\n",
    "\n",
    "        plt.subplots_adjust(wspace = 0.1, hspace = 0.5)\n",
    "        if self.save:\n",
    "            plt.savefig(self.save_path)\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.001)\n",
    "            \n",
    "# def rndd(x):\n",
    "#     assert len(x.shape) == 4\n",
    "#     return x\n",
    "# ImageRenderer(2).withTensorboard(TensorboardUtil(\"prepa_autencoder_logs\")).render(model=lambda x:x, datasets=(div2k_ds_train, div2k_ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(filters, kernel_size, strides, norm=False, use_init = True, use_bias=True, activation=\"relu\", config=None, **args):\n",
    "    return layers.Conv2D(filters,\n",
    "                         kernel_size=kernel_size,\n",
    "                         strides=strides,\n",
    "                         padding=\"same\",\n",
    "                         use_bias=use_bias,\n",
    "                         activation=activation,\n",
    "                         kernel_regularizer=config.kernel_regularizer,\n",
    "#                          kernel_initializer=tf.keras.initializers.HeNormal(seed=32) if use_init else None,\n",
    "                         **args)\n",
    "\n",
    "\n",
    "class Resblock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, config=None, *args, **kwargs):\n",
    "        super(Resblock, self).__init__(*args, **kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.config = config\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"conv_size\": 3,\n",
    "            \"res_activation\": \"relu\",\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv1 = conv(self.filters, kernel_size=self.kernel_size, strides=1, config=self.config)\n",
    "        self.conv2 = conv(self.filters, kernel_size=self.kernel_size, strides=1, config=self.config)\n",
    "        self.conv3 = conv(self.filters, kernel_size=self.kernel_size, strides=1, config=self.config)\n",
    "        self.add = layers.Add()\n",
    "        self.activation = layers.Activation('relu', dtype=tf.float16) \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        y = self.conv2(x)\n",
    "        y = self.conv3(y)\n",
    "        out = self.add ([x,y])\n",
    "        return self.activation(out)\n",
    "\n",
    "\n",
    "class MyRescale(tf.keras.layers.Layer):\n",
    "  def __init__(self):\n",
    "    super(MyRescale, self).__init__()\n",
    "  def build(self, input_shape):\n",
    "     self.kernel = self.add_weight(\"kernel\", initializer=tf.keras.initializers.Constant(value=255))\n",
    "\n",
    "\n",
    "  def call(self, inputs):\n",
    "   return inputs * self.kernel\n",
    "\n",
    "\n",
    "class MyDeconv(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, name, resize_to=None, config=None):\n",
    "        super(MyDeconv, self).__init__(name=name)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.resize_to = resize_to\n",
    "        self.strides = strides\n",
    "        self.config = config\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"resize_to\": self.resize_to,\n",
    "            \"strides\": self.strides,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        filters = self.filters\n",
    "        kernel_size = self.kernel_size\n",
    "        name = self.name\n",
    "        \n",
    "        strides = self.strides if isinstance(self.strides, tuple) else (self.strides,self.strides)\n",
    "                     \n",
    "        if self.resize_to is None:\n",
    "            h,w = input_shape[1], input_shape[2]\n",
    "            self.resize_to = (int(h*strides[0]),int(w*strides[1]))\n",
    "        \n",
    "        self.resize_layer = layers.Lambda(lambda x: tf.image.resize(x, self.resize_to, method=\"nearest\"), name=f\"resize_nearest_{name}\")\n",
    "        self.resblock = Resblock(filters, kernel_size, config=self.config)\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.resize_layer(inputs)\n",
    "        return self.resblock(x)\n",
    "\n",
    "\n",
    "def maxconv_name():\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        yield f\"max_conv_{i}\"\n",
    "\n",
    "        \n",
    "max_conv_name = iter(maxconv_name())\n",
    "\n",
    "\n",
    "def maxpoolconv(filters, pool_kernel_size, kernel_size=3, strides=1, config=None):\n",
    "    name = next(max_conv_name)\n",
    "    def fn(x):\n",
    "#         y = conv(filters, kernel_size=kernel_size, strides=1, name=f\"{name}_1\", norm=norm)(x)\n",
    "#         y = conv(filters, kernel_size=kernel_size, strides=1, name=f\"{name}_2\", norm=norm)(y)\n",
    "#         x = layers.Add()(x,y)\n",
    "#         x = layers.ReLU(x)\n",
    "        x = Resblock(filters, kernel_size, name=f\"resblock_{name}_1\", config=config)(x)\n",
    "#         x = conv(filters, kernel_size=kernel_size, strides=1, name=f\"{name}_3\", norm=norm)(x)\n",
    "        x = layers.MaxPool2D(pool_kernel_size, name=f\"{name}_maxpool\")(x)\n",
    "        return x\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder_large_v3(config):    \n",
    "    inputs = keras.Input(shape=(480, 720, 3))\n",
    "    norm = True\n",
    "    \n",
    "\n",
    "    def deconv_with_ff(filters, x, ff, kernel_size, stride, name):\n",
    "        x = MyDeconv(filters, kernel_size, stride, name=name, resize_to=None, config=config)(x)\n",
    "        x = layers.SpatialDropout2D(config.dropout_rate)(x)\n",
    "        x = tf.add(x,ff)\n",
    "        x = layers.ReLU()(x)\n",
    "        return x\n",
    "    \n",
    "    x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "#     x = layers.Lambda(lambda x: tf.image.per_image_standardization(x))(inputs)\n",
    "    \n",
    "    ffs = []\n",
    "    \n",
    "    def conv_with_ff(x, filters, strides):\n",
    "        x = maxpoolconv(filters, strides, config=config)(x)\n",
    "        ffs.append(layers.SpatialDropout2D(config.ff_dropout_rate)(x))\n",
    "        return x\n",
    "#     large_inputs = MyDeconv(16, 3, 1, name=\"input_ff\", resize_to=(720, 1080), norm=norm)(inputs)\n",
    "#     large_inputs = MyDeconv(32, 3, 1, name=\"input_ff\", resize_to=None, norm=norm)(inputs)\n",
    "    \n",
    "#     x = conv(32, 3, 1, name=\"first_conv1\", use_bias=True, norm=norm)(x)\n",
    "#     x = conv(32, 5, 1, name=\"first_conv2\", use_bias=True, norm=norm)(x)\n",
    "    x = Resblock(16, 3, name=f\"first_resblock\", config=config)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(config.ff_dropout_rate)(x))\n",
    "    \n",
    "    x = conv_with_ff(x, 32, 2)\n",
    "    x = conv_with_ff(x, 64, 2)\n",
    "    x = conv_with_ff(x, 128, 2)\n",
    "    x = conv_with_ff(x, 512, 2)\n",
    "    x = maxpoolconv(1024, (2,3), config=config)(x)\n",
    "    x = layers.SpatialDropout2D(config.dropout_rate)(x)\n",
    "        \n",
    "    ffs.reverse()\n",
    "    x = conv(1024, 3, 1, name=\"middle_conv\", use_bias=True, config=config)(x)\n",
    "    \n",
    "  \n",
    "    x = deconv_with_ff(512, x, ffs[0], 3, (2,3), \"mydeconv7\")\n",
    "    x = deconv_with_ff(128, x, ffs[1], 3, 2, \"mydeconv6\")\n",
    "    x = deconv_with_ff(64, x, ffs[2], 3, 2, \"mydeconv5\")\n",
    "    x = deconv_with_ff(32, x, ffs[3], 3, 2, \"mydeconv4\")\n",
    "    x = Resblock(32, 3, name=f\"rb1\",config=config)(x)\n",
    "    x = deconv_with_ff(16, x, ffs[4], 3, 2, \"mydeconv3\")\n",
    "    \n",
    "    x = MyDeconv(16, 3, 1, name=\"mydeconv2\", resize_to=(360, 540), config=config)(x)\n",
    "    x = Resblock(16, 5, name=f\"rb2\", config=config)(x)\n",
    "    x = MyDeconv(16, 3, 2, name=\"mydeconv1\", resize_to=None, config=config)(x)\n",
    "#     x = deconv_with_ff(16, x, large_inputs, 3, 2, \"mydeconv1\")\n",
    "    \n",
    "    x = conv(16, 5, 1, name=\"last_conv1\", use_bias=True, config=config)(x)\n",
    "    x = Resblock(9, 3, name=f\"last_resconv\", config=config)(x)\n",
    "    x = conv(3, 3, 1, name=\"output_conv\", activation=\"sigmoid\", use_bias=True, config=config)(x)\n",
    "\n",
    "#     x = deconv(64, kernel_size=1, strides=1, name=\"prelast_deconv\", norm=True)(x)\n",
    "#     x = deconv(3, kernel_size=1, strides=1, name=\"last_deconv\", norm=True)(x)\n",
    "#     x = layers.Conv2DTranspose(3, kernel_size=3, strides=1, padding=\"same\", \n",
    "#                       activation=\"sigmoid\", kernel_initializer=tf.keras.initializers.HeNormal(seed=32))(x)\n",
    "    \n",
    "#     x = MyRescale()(x)\n",
    "    x = tf.keras.layers.Rescaling(255.)(x)\n",
    "#     x = tf.keras.layers.Lambda(lambda x: tf.cast(x, tf.uint8))(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the best range of learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_lr_range = [1e-4, 5e-7]\n",
    "best_lr_range = [5e-6, 5e-7]\n",
    "\n",
    "initial_learning_rate = best_lr_range[0]\n",
    "search_epochs = 100\n",
    "\n",
    "def lr_from_search(epochs):\n",
    "    lrs = tf.linspace(best_lr_range[0], best_lr_range[1], epochs, name=None, axis=0)\n",
    "    def fn(epoch, lr):\n",
    "        return lrs[epoch]\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_from_range(epochs, lr_range):\n",
    "    start,end = lr_range\n",
    "    lrs = tf.linspace(start, end, epochs, name=None, axis=0)\n",
    "    def fn(epoch, lr):\n",
    "        if epoch > epochs:\n",
    "            return end\n",
    "        return lrs[epoch]\n",
    "    return fn\n",
    "    \n",
    "lr_from_range(10, (5e-6, 5e-7))(4, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RangedExpDecay(tf.keras.optimizers.schedules.ExponentialDecay):\n",
    "    def __init__(self, end, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.end = end\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        return tf.math.minimum(super().__call__(step), self.end)\n",
    "\n",
    "def schedule_exp_lr_range(start, end):\n",
    "    return RangedExpDecay(\n",
    "        end,\n",
    "        start,\n",
    "        decay_steps=50,\n",
    "        decay_rate=0.95,\n",
    "        staircase=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an exponential rate optimizer from a range of learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExponentialOptimizer(start, end, epochs):\n",
    "    t = 1/tf.math.maximum(epochs-1, 1)\n",
    "    r = tf.math.pow(end/start, t)\n",
    "\n",
    "    return tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=start, decay_steps=1,decay_rate=r)\n",
    "\n",
    "def getPieceWiseOptimizer(values, epochs):\n",
    "    epochs_per_range = int(epochs / len(values))\n",
    "    \n",
    "    start = values[0]\n",
    "    curr_epochs = 0\n",
    "    new_values = None\n",
    "    for iend, end in enumerate(values):\n",
    "        if iend == len(values)-1:\n",
    "            epochs_per_range = epochs - curr_epochs\n",
    "        ls = tf.linspace(start, end, epochs_per_range)\n",
    "        curr_epochs += epochs_per_range\n",
    "        start = end\n",
    "        if new_values is None:\n",
    "            new_values = ls\n",
    "        else:\n",
    "            new_values = tf.concat([new_values, ls], axis=0)\n",
    "    \n",
    "\n",
    "    boundaries = list(range(epochs-1))\n",
    "    print(f\"{tf.squeeze(new_values).shape} ls={new_values}\")\n",
    "    print(f\"epochs_per_range = {epochs_per_range}, boundaries={boundaries} \")\n",
    "    \n",
    "    v = [i for i in new_values]\n",
    "    \n",
    "    return keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "        boundaries, v)\n",
    "\n",
    "    \n",
    "\n",
    "# ran = getDecayRateOptimizer(1e-8,1e-3, 10)\n",
    "ran = getPieceWiseOptimizer([0.1, 0.2, 0.1], 11)\n",
    "for i in range(11):\n",
    "    print(ran(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainStep(tf.keras.Model):\n",
    "    def __init__(self, n_gradients, autoencoder, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.autoencoder = autoencoder\n",
    "        print(f\"CustomTrainStep: n_gradients = {n_gradients}\")\n",
    "        self.n_gradients = tf.Variable(n_gradients, dtype=tf.int32, trainable=False)\n",
    "        self.n_acum_step = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "        self.update_count = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "        self.gradient_accumulation = [tf.Variable(tf.zeros_like(v, dtype=tf.float32), \n",
    "                                                  trainable=False) for v in self.trainable_variables]\n",
    "\n",
    "        \n",
    "    def call(self, data):\n",
    "        return self.autoencoder(data, training=False)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        self.n_acum_step.assign_add(1)\n",
    "\n",
    "        x, y = data\n",
    "        # Gradient Tape\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.autoencoder(x, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "            scaled_loss = self.optimizer.get_scaled_loss(loss)\n",
    "            \n",
    "            \n",
    "        # Calculate batch gradients\n",
    "        scaled_grads = tape.gradient(scaled_loss, self.autoencoder.trainable_variables)\n",
    "        gradients = self.optimizer.get_unscaled_gradients(scaled_grads)\n",
    "        # Accumulate batch gradients\n",
    "        for i in range(len(self.gradient_accumulation)):\n",
    "            self.gradient_accumulation[i].assign_add(gradients[i])\n",
    " \n",
    "        # If n_acum_step reach the n_gradients then we apply accumulated gradients to update the variables otherwise do nothing\n",
    "        tf.cond(tf.equal(self.n_acum_step, self.n_gradients), self.apply_accu_gradients, lambda: None)\n",
    "\n",
    "        # update metrics\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def apply_accu_gradients(self):\n",
    "        # apply accumulated gradients\n",
    "        self.optimizer.apply_gradients(zip(self.gradient_accumulation, self.autoencoder.trainable_variables))\n",
    "        self.update_count.assign_add(1)\n",
    "\n",
    "        # reset\n",
    "        self.n_acum_step.assign(0)\n",
    "        for i in range(len(self.gradient_accumulation)):\n",
    "            self.gradient_accumulation[i].assign(tf.zeros_like(self.autoencoder.trainable_variables[i], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result yet:\n",
    "\n",
    "- In 150/300 epochs, with ranges best_lr_range = [3e-5, 5e-7] and linspace of size 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "class LRMetric(tf.keras.metrics.Mean):\n",
    "    def __init__(self, model, name=\"lr_metric\", **kwargs):\n",
    "        super(LRMetric, self).__init__(name=name, **kwargs)\n",
    "        self.model = model\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        super().update_state(self.model.optimizer.lr)\n",
    "\n",
    "class GradientUpdates(tf.keras.metrics.Metric):\n",
    "    def __init__(self, model, name='gradient_updates_metric', **kwargs):\n",
    "        super(GradientUpdates, self).__init__(name=name, **kwargs)\n",
    "        self.model = model\n",
    "        self.true_positives = self.add_weight(name='gradient_updates', initializer='zeros', dtype=tf.int32)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.true_positives.assign(self.model.update_count)\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, name, output_size):\n",
    "        self.name = name\n",
    "        self.output_size = output_size\n",
    "        self.v = 1\n",
    "        self.lossFn = build_perceptual_loss(input_shape=(self.output_size[0], self.output_size[1], 3))\n",
    "        self.aggregate = False\n",
    "        self.useLRRange = False\n",
    "        self.callbacks = []\n",
    "        self.early_stop = False\n",
    "        self.n_gradients = None\n",
    "        self.lr_range = None\n",
    "        self.loss_fn_name = \"perceptual_loss\"\n",
    "        self.opt = None\n",
    "        self.lrs = None\n",
    "        self.tb_util = None\n",
    "        self.run_eagerly = False\n",
    "        self.use_hp = False\n",
    "        self.log_dir = None\n",
    "#         print(\"clear session:\")\n",
    "#         tf.keras.backend.clear_session()\n",
    "\n",
    "    def withCallbacks(self, callbacks = []):\n",
    "        self.callbacks = callbacks\n",
    "        return self\n",
    "        \n",
    "    def withVersion(self, v):\n",
    "        self.v = v\n",
    "        return self\n",
    "        \n",
    "    def setLoss(self, loss_name, lossFn):\n",
    "        self.lossFn = lossFn\n",
    "        self.loss_fn_name = loss_name\n",
    "            \n",
    "    def withMSEPerceptualLoss(self, ploss_downscale=10000):\n",
    "        perceptual_loss = build_perceptual_loss(input_shape=(self.output_size[0], self.output_size[1], 3))\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        def custom_loss(x,y):\n",
    "            return tf.cast(mse(x,y), tf.float32) * (perceptual_loss(x,y)/tf.cast(ploss_downscale, tf.float32))\n",
    "        self.lossFn = custom_loss\n",
    "        self.loss_fn_name = \"mse_perceptual_loss\"\n",
    "        self.add_hp_callback = None\n",
    "        return self\n",
    "        \n",
    "    def withEagerRun(self, active=True):\n",
    "        self.run_eagerly = active\n",
    "        return self\n",
    "    \n",
    "    def withLRRange(self, lr_range):\n",
    "        self.lr_range = lr_range\n",
    "        self.useLRRange = True\n",
    "        return self\n",
    "    \n",
    "    def withFindBestLR(self, lr_range, epochs):       \n",
    "        self.lrs = tf.keras.callbacks.LearningRateScheduler(getExponentialOptimizer(lr_range[0],lr_range[1],epochs), verbose=1)\n",
    "        return self\n",
    "    \n",
    "    def withLRScheduler(self, lrs):\n",
    "        self.lrs = lrs\n",
    "    \n",
    "    def withOptimizer(self, opt):\n",
    "        self.opt = opt\n",
    "        return self\n",
    "        \n",
    "    def withGradientAggregation(self, n_gradients=3):\n",
    "        self.aggregate = True\n",
    "        self.n_gradients = n_gradients\n",
    "        return self\n",
    "        \n",
    "    def getCheckpointPath(self):\n",
    "        return f'./prepa_{self.name}_ckpt'\n",
    "    \n",
    "    def getSavedModelPath(self):\n",
    "        return f'./saved_models/{self.name}_{self.v}'\n",
    "    \n",
    "    \n",
    "    '''\n",
    "        Use profile batch like this: profile_batch=\"5,10\"\n",
    "    '''\n",
    "    def withTensorboard(self, logs_dir, profile_batch=0, use_hp=False):\n",
    "        log_dir = f\"./{logs_dir}/{self.name}\"\n",
    "        self.log_dir = log_dir\n",
    "        self.tb_util = TensorboardUtil(log_dir)\n",
    "        self.use_hp = use_hp\n",
    "        self.callbacks.append(self.tb_util.get_callback(profile_batch=profile_batch))\n",
    "        return self           \n",
    "\n",
    "    def withEarlyStopping(self, restore_best_weights=True, patience=5):\n",
    "        self.early_stop = True\n",
    "        self.callbacks.append(EarlyStopping(monitor='val_loss', restore_best_weights=restore_best_weights, patience=patience, min_delta=0.))\n",
    "        return self\n",
    "    \n",
    "    def getTrainingConfig(self):\n",
    "        return {\n",
    "            \"name\":self.name,\n",
    "            \"version\": self.v,\n",
    "            \"output_size\": self.output_size,\n",
    "            \"aggregate_gradients\": self.aggregate,\n",
    "            \"n_gradients\": self.n_gradients,\n",
    "            \"lr_range\": self.lr_range,\n",
    "            \"loss_fn_name\": self.loss_fn_name,\n",
    "            \"model_path\": self.getSavedModelPath(),\n",
    "            \"early_stop\": self.early_stop\n",
    "        }\n",
    "    \n",
    "    def validation_results(self, model, dataset):     \n",
    "        #loss: 214513.0625 - gradient_upds: 2.0000 - lr_metric: 5.0000e-05 - mse: 6808.1318 - accuracy: 0.3310\n",
    "        loss, gradient_upds, lr_metric, mse, accuracy = model.evaluate(dataset)\n",
    "        return {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"loss\":loss,\n",
    "            \"mse\":mse\n",
    "        }\n",
    "    \n",
    "    def getTrainingConfigPreTrain(self, epochs):\n",
    "        conf = self.getTrainingConfig()\n",
    "        conf[\"time\"] = time()\n",
    "        conf[\"epochs\"] = epochs\n",
    "        return conf\n",
    "    \n",
    "    def saveTrainingConfig(self, epochs):\n",
    "        file1 = open(\"training.log\", \"a\")  # append mode\n",
    "        file1.write(json.dumps(self.getTrainingConfigPreTrain(epochs)))\n",
    "        file1.write(\"\\n\")\n",
    "        file1.close()\n",
    "    \n",
    "    def train(self, autoencoder, train_ds, test_ds, epochs, initial_lr, load_checkpoint=True, config=None):\n",
    "        metrics = []\n",
    "        \n",
    "        if self.tb_util:\n",
    "            self.tb_util.log_text(config.toString(), \"training_config\", step=0)\n",
    "        \n",
    "        if self.aggregate:\n",
    "            model = CustomTrainStep(n_gradients=self.n_gradients, autoencoder=autoencoder)\n",
    "            metrics.append(GradientUpdates(model, name=\"gradient_upds\"))\n",
    "        else:\n",
    "            model = autoencoder\n",
    "        \n",
    "        metrics.append(LRMetric(model, name=\"lr_metric\"))\n",
    "        \n",
    "        self.saveTrainingConfig(epochs)\n",
    "        \n",
    "#         self.add_hp_callback(config)\n",
    "        \n",
    "        if self.lrs is not None:\n",
    "            lr_schedule = initial_lr\n",
    "            self.callbacks.append(self.lrs)\n",
    "        elif self.useLRRange and self.lrs is None:\n",
    "            assert initial_lr == self.lr_range[0]\n",
    "            lr_schedule=self.lr_range[0]\n",
    "            self.callbacks.append(tf.keras.callbacks.LearningRateScheduler(getPieceWiseOptimizer(self.lr_range,epochs), verbose=1))\n",
    "        else:\n",
    "            lr_schedule=initial_lr\n",
    "        \n",
    "        if self.opt is None or config.optimizer==\"adam\":\n",
    "            self.opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "#             self.opt = tfa.optimizers.AdamW(weight_decay=0.0001, learning_rate=lr_schedule, beta_1=0.8, beta_2=0.99)\n",
    "            self.opt = mixed_precision.LossScaleOptimizer(self.opt)\n",
    "        \n",
    "            \n",
    "        checkpoint_dir = f'./prepa_{self.name}_ckpt'\n",
    "        checkpoint = tf.train.Checkpoint(model=autoencoder, optimizer=self.opt)\n",
    "        ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)\n",
    "        \n",
    "        if load_checkpoint and ckpt_manager.latest_checkpoint:\n",
    "    #             checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "                checkpoint.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
    "        else:\n",
    "            print(\"No checkpoints found or loaded\")\n",
    "        \n",
    "        def save_checkpoint(batch, logs):\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            \n",
    "        images_renderer = ImageRenderer(4).withTensorboard(self.tb_util)\n",
    "        def print_images(batch, logs):\n",
    "            images_renderer.render(model=lambda x:model(x, training=False), datasets=(train_ds, test_ds), batch=batch)\n",
    "#             print_validation(lambda x:model(x, training=False), batch_size=2, save=False, path=\"./\", datasets=(train_ds, test_ds))\n",
    "      \n",
    "        def initial_print(logs):\n",
    "            print_images(0, logs)\n",
    "    \n",
    "        def clear_print(batch, logs):\n",
    "            if batch % 5 == 0:\n",
    "                display.clear_output()\n",
    "                \n",
    "        def on_epoch_end(batch, logs):\n",
    "            clear_print(batch, logs)\n",
    "            print_images(batch, logs)\n",
    "            save_checkpoint(batch, logs)\n",
    "            \n",
    "        self.callbacks.append(LambdaCallback(on_train_begin=initial_print ,on_epoch_end=on_epoch_end))\n",
    "        metrics.append(\"mse\")\n",
    "        metrics.append(\"accuracy\")\n",
    "        \n",
    "        model.compile(optimizer=self.opt, loss=self.lossFn, metrics=metrics, run_eagerly=self.run_eagerly)\n",
    "        model.fit(train_ds.prefetch(tf.data.AUTOTUNE),\n",
    "                                    epochs=epochs,\n",
    "                                    validation_data=test_ds.prefetch(tf.data.AUTOTUNE),\n",
    "                                    callbacks=self.callbacks)\n",
    "        \n",
    "        results = self.validation_results(model, test_ds)\n",
    "        \n",
    "        model_path = self.getSavedModelPath()\n",
    "        model.save(self.getSavedModelPath())\n",
    "        print(f'model saved to: {model_path}')\n",
    "        return model_path, results, model\n",
    "    \n",
    "# t = Trainer(\"test_model\", (720, 1080))\\\n",
    "#     .withMSEPerceptualLoss()\\\n",
    "#     .withLRRange((6e-5, 5e-8))\\\n",
    "#     .withGradientAggregation()\\\n",
    "#     .withTensorboard(\"prepa_autencoder_logs\")\\\n",
    "#     .withEarlyStopping()\n",
    "\n",
    "# # t.saveTrainingConfig(100)\n",
    "# t.getTrainingConfig()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 20 \n",
    "# weights_path, ghistory, model = Trainer(\"d_and_s_srch_lr\", (720, 1080))\\\n",
    "#     .withFindBestLR((5e-8, 2e-3), epochs)\\\n",
    "#     .withGradientAggregation(4)\\\n",
    "#     .withTensorboard(\"prepa_autencoder_logs\", profile_batch=0)\\\n",
    "#     .train(\n",
    "#         build_autoencoder_large_v3(),\n",
    "#         div2k_ds(\"train\").batch(4),\n",
    "#         div2k_ds(\"validation\").batch(4),\n",
    "#         epochs,\n",
    "#         1e-8,\n",
    "#         load_checkpoint=False)\n",
    "\n",
    "# 1e-4 : 7e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# lr = (5e-5, 7e-6)\n",
    "# train_config = TrainingConfig()\n",
    "\n",
    "# tb_util = TensorboardUtil(\"test\")\n",
    "# [s.toString() for s in tb_util.hp_search()]\n",
    "\n",
    "log_dir = \"prepa_autencoder_logs\"\n",
    "name = f\"aenc\"\n",
    "\n",
    "hpSearch = TensorboardHPSearch(log_dir, name)\n",
    "\n",
    "def runTest(config, hp_callback, tname):\n",
    "    lr = config.learning_rate\n",
    "    weights_path, results, model = Trainer(tname, (720, 1080))\\\n",
    "        .withCallbacks([hp_callback])\\\n",
    "        .withLRRange(lr)\\\n",
    "        .withGradientAggregation(3)\\\n",
    "        .withTensorboard(log_dir)\\\n",
    "        .train(\n",
    "                build_autoencoder_large_v3(config),\n",
    "                div2k_ds(\"train\").batch(3),\n",
    "                div2k_ds(\"validation\").batch(3),\n",
    "                epochs,\n",
    "                lr[0],\n",
    "                load_checkpoint=False,\n",
    "                config=config)\n",
    "    \n",
    "    hpSearch.log_results(tname, results[\"loss\"], results[\"accuracy\"], results[\"mse\"])\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "TensorboardHPSearch(log_dir, name).hp_search(\n",
    "    dropout_rate=[0.1],\n",
    "    ff_dropout_rate=[0.1],\n",
    "    regularizers=[1e-2],\n",
    "    learning_rate=[[1e-4, 5e-5], [1e-4,1e-4, 5e-5, 5e-5,1e-5]],\n",
    "    optimizer=[\"adam\"],\n",
    "    run=runTest)\n",
    "    \n",
    "#     model = build_autoencoder_large_v3(config)\n",
    "    \n",
    "#     loss = 0\n",
    "#     count = 0\n",
    "#     tf.keras.utils.disable_interactive_logging()\n",
    "#     tf.keras.utils.enable_interactive_logging()\n",
    "\n",
    "#     validation_ds = div2k_ds(\"validation\").take(3).batch(3)\n",
    "    \n",
    "#     model.compile(optimizer=\"adam\", loss=build_perceptual_loss(input_shape=(720, 1080, 3)), metrics=[\"mse\", \"accuracy\"])\n",
    "\n",
    "#     results = model.evaluate(validation_ds)\n",
    "    \n",
    "\n",
    "#     print(results)\n",
    "    \n",
    "# #     trainer.tb_util.log_scalar(loss, \"accuracy\", step=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 150 \n",
    "# weights_path, ghistory, model = Trainer(\"d_and_s\", (720, 1080))\\\n",
    "#     .withVersion(1.1)\\\n",
    "#     .withLRRange((1e-5, 4e-6))\\\n",
    "#     .withGradientAggregation(4)\\\n",
    "#     .withTensorboard(\"prepa_autencoder_logs\")\\\n",
    "#     .train(\n",
    "#         build_autoencoder_large_v3(),\n",
    "#         div2k_ds(\"train\").batch(4),\n",
    "#         div2k_ds(\"validation\").batch(4),\n",
    "#         epochs,\n",
    "#         1e-5,\n",
    "#         load_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploss = build_perceptual_loss(\"\")\n",
    "\n",
    "prepa = [(str(p),'png') for p in pathlib.Path(\"./prepa\").glob('*.png')]\n",
    "\n",
    "def gen_img(img_path, img_type):\n",
    "    raw_png = tf.io.read_file(str(img_path), name=img_path)\n",
    "    return tf.image.decode_png(raw_png, channels=3, name=img_path)\n",
    "\n",
    "def gen_prepa():\n",
    "    for img_path, img_type in prepa:\n",
    "        yield gen_img(img_path, img_type)\n",
    "\n",
    "it = iter(gen_prepa())    \n",
    "\n",
    "img1 = next(it)\n",
    "img2 = next(it)\n",
    "inverted = (255-img1)\n",
    "plt.figure()\n",
    "plt.imshow(img1)\n",
    "plt.figure()\n",
    "plt.imshow(inverted)\n",
    "\n",
    "contrast = tf.image.random_contrast(img1, 0.2, 0.5)\n",
    "plt.figure()\n",
    "plt.imshow(tf.cast(contrast, tf.uint32))\n",
    "\n",
    "\n",
    "sat = tf.image.random_saturation(img1, 5, 10)\n",
    "plt.figure()\n",
    "plt.imshow(tf.cast(sat, tf.uint32))\n",
    "\n",
    "\n",
    "\n",
    "def losss(x, y):\n",
    "    return ploss(tf.expand_dims(x, axis=0), tf.expand_dims(y, axis=0))\n",
    "\n",
    "print(f\"ploss self: {losss(img1, img1)}\")\n",
    "print(f\"ploss img2: {losss(img1, img2)}\")\n",
    "print(f\"ploss inverted: {losss(img1, inverted)}\")\n",
    "print(f\"ploss contrast: {losss(img1, contrast)}\")\n",
    "print(f\"ploss saturation: {losss(img1, sat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_grad_acc_model(model_name, model_fn):\n",
    "    model = model_fn()\n",
    "    model.load_weights(f'./saved_models/{model_name}')\n",
    "    return model\n",
    "\n",
    "def test_prepa(autoencoder):\n",
    "    prepa = [(str(p),'png') for p in pathlib.Path(\"./prepa\").glob('*.png')]\n",
    "\n",
    "    def gen_img(img_path, img_type):\n",
    "        raw_png = tf.io.read_file(str(img_path), name=img_path)\n",
    "        return tf.image.decode_png(raw_png, channels=3, name=img_path)\n",
    "\n",
    "    def gen_prepa():\n",
    "        for img_path, img_type in prepa:\n",
    "            yield gen_img(img_path, img_type)\n",
    "\n",
    "    it = iter(gen_prepa())    \n",
    "    for i in range(10):\n",
    "\n",
    "\n",
    "        img = next(it)\n",
    "        plt.figure()\n",
    "        plt.imshow(img)\n",
    "        plt.figure()\n",
    "        y_pred = autoencoder.predict(tf.expand_dims(img, axis=0))\n",
    "        y_pred = tf.cast(y_pred, tf.uint8)\n",
    "        plt.imshow(y_pred[0])\n",
    "\n",
    "\n",
    "    # tf.math.reduce_mean(\n",
    "    #     y_pred, axis=[1,2], keepdims=False, name=None\n",
    "    # )\n",
    "\n",
    "    # y = tf.reshape(y_pred, (1,-1,3))\n",
    "    # y = layers.AveragePooling1D(2)(tf.cast(y, tf.float32))\n",
    "    # y = layers.AveragePooling1D(2)(tf.cast(y, tf.float32))\n",
    "    # y = layers.AveragePooling1D(2)(tf.cast(y, tf.float32))\n",
    "    # # y = tf.image.resize(y, (720, 1080))\n",
    "    # y\n",
    "test_prepa(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = restore_grad_acc_model(\"denoise_and_scale_100e_large_v3_0002\", build_autoencoder_large_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "4327198819dafd55a2243f22aba11bf2a7d9f0c32aced8ba7d18a900e49d0553"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
