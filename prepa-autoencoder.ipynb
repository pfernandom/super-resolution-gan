{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda/\n",
    "!export CUDA_DIR=/usr/lib/cuda/\n",
    "# !export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:/home/pedro/miniconda3/envs/ml2/lib/\n",
    "# !export TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ${CUDA_DIR}/nvvm/libdevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import math\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(f\"gpus={gpus}\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten,\\\n",
    "                                    Reshape, LeakyReLU as LR,\\\n",
    "                                    Activation, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display # If using IPython, Colab or Jupyter\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://drive.google.com/uc?export=download&id=0B7EVK8r0v71pZjFTYXZWM3FlRnM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vertical_lines_noise(x, shifts=2, line_height=2):\n",
    "    x = np.copy(x)\n",
    "    axis_for_roll = 1\n",
    "    y = np.roll(x, -shifts, axis=axis_for_roll)\n",
    "    j = 0\n",
    "    for i in range(x.shape[axis_for_roll]):\n",
    "        if j <= line_height:\n",
    "            x[:,i,:] = y[:,i,:]\n",
    "            \n",
    "        j+=1\n",
    "        if j == line_height * 2:\n",
    "            j = 0\n",
    "#     print(x.shape)\n",
    "    return x\n",
    "\n",
    "def add_horizontal_lines_noise(x, shifts=2, line_height=2):\n",
    "    x = np.copy(x)\n",
    "    axis_for_roll = 0\n",
    "    y = np.roll(x, -shifts, axis=1)\n",
    "    j = 0\n",
    "    for i in range(x.shape[axis_for_roll]):\n",
    "        if j <= line_height:\n",
    "            x[i,:,:] = y[i,:,:]\n",
    "            \n",
    "        \n",
    "        if j == line_height * 2:\n",
    "            j = 0\n",
    "        else:\n",
    "            j+=1\n",
    "#     print(x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from functools import reduce\n",
    "splits = tfds.even_splits('train', n=200, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_H = 480\n",
    "IMG_W = 720\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_len = 7164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 3\n",
    "# EPOCHS=100\n",
    "# steps_per_epoch=int(train_len/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import NoiseUtil, ImgUtils, DataLoader, DataManager\n",
    "\n",
    "           \n",
    "def add_noise(x,y):\n",
    "    downsize_image_ratio = random.choice([1/5])\n",
    "    sh = tf.cast(tf.shape(x), tf.float32)\n",
    "    \n",
    "    print(x)\n",
    "    \n",
    "    resized_size_h = sh[0]\n",
    "    resized_size_w = sh[1]\n",
    "    down = tf.image.resize(\n",
    "        x,\n",
    "        [int(resized_size_h * downsize_image_ratio), int(resized_size_w * downsize_image_ratio)],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "    \n",
    "    \n",
    "\n",
    "    x= tf.image.resize(\n",
    "        down,\n",
    "        [resized_size_h, resized_size_w],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "        \n",
    "    return tf.reshape(x, (resized_size_h, resized_size_w, 3)), y\n",
    "    \n",
    "    \n",
    "#     print(x.shape)\n",
    "\n",
    "    \n",
    "#     n = NoiseUtil.pixel_noise(x, random.choice([50,60]), 15, downsize_image_ratios=[1/4, 1/6])\n",
    "\n",
    "#     n = x + 0.2 * tf.random.normal(\n",
    "#         x.shape[1:],\n",
    "#         mean=0.0,\n",
    "#         stddev=1.0,\n",
    "#         dtype=tf.dtypes.float32,\n",
    "#     )\n",
    "\n",
    "#     return n,y\n",
    "\n",
    "random_bright = tf.keras.layers.RandomBrightness(factor=0.2)\n",
    "random_contrast = tf.keras.layers.RandomContrast(factor=0.2)\n",
    "random_flip = tf.keras.layers.RandomFlip()\n",
    "\n",
    "\n",
    "def augment(x):\n",
    "#     seed = (random.randint(0, 100),random.randint(0, 100))\n",
    "    x = random_bright(x, training=True)\n",
    "    x = random_contrast(x, training=True)\n",
    "    x = random_flip(x, training=True)\n",
    "    return x\n",
    "\n",
    "def get_train_data():\n",
    "    return tf.data.Dataset.from_generator(train_gen, output_signature=tf.TensorSpec(shape=(480, 720, 3)))\n",
    "    \n",
    "def get_test_data():\n",
    "    return tf.data.Dataset.from_generator(test_gen, output_signature=tf.TensorSpec(shape=(480, 720, 3)))\n",
    "\n",
    "\n",
    "def get_dist_ds(ds, ds_len):\n",
    "    c = ds.map(normm).map(expp).map(augment)\n",
    "    a = c.map(lambda y: (y,1))\n",
    "    b = c.map(lambda y: (y,0)).map(add_noise)\n",
    "    return a.concatenate(b).batch(BATCH_SIZE)\n",
    "\n",
    "def get_gen_ds(ds):\n",
    "    return ds.map(augment).map(lambda x: (x,x)).map(add_noise).batch(BATCH_SIZE)\n",
    "\n",
    "# train_ds = get_gen_ds(get_train_data())\n",
    "# test_ds = get_gen_ds(get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_validation(model=lambda x:x, batch_size=5, save=False, path=\"./\", max_size=20, datasets=([], [])):\n",
    "        rows = batch_size\n",
    "        cols = 3\n",
    "        train_ds, test_ds = datasets\n",
    "        def print_ds(dataset, save=False):\n",
    "            results = [(model(x),x, y) for x,y in dataset]\n",
    "            plt.ion()\n",
    "            plt.show()\n",
    "            print(rows, cols)\n",
    "            plt.figure(figsize=((max_size+15) / cols, max_size / rows))\n",
    "            for x,x_prev, y in results:\n",
    "#                 x = (x * 127.5) + 127.5\n",
    "#                 y = (y * 127.5) + 127.5\n",
    "#                 x_prev = (x_prev * 127.5) + 127.5\n",
    "#                 x = x * 255.\n",
    "#                 y = y * 255.\n",
    "#                 x_prev = x_prev * 255.\n",
    "\n",
    "                x = tf.cast(x, tf.uint8)\n",
    "                x_prev = tf.cast(x_prev, tf.uint8)\n",
    "                y = tf.cast(y, tf.uint8)\n",
    "#                 x = tf.clip_by_value(x, 0.0, 1.0)\n",
    "#                 y = tf.clip_by_value(y, 0.0, 1.0)\n",
    "                assert x.shape == y.shape\n",
    "    \n",
    "                for i in range(x.shape[0]):\n",
    "                    im = x[i,:,:,:]\n",
    "                    plt.subplot(cols, rows, i+1)\n",
    "                    plt.imshow(im)\n",
    "                    plt.title(\"Denoised\")\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                for i in range(x_prev.shape[0]):\n",
    "                    im = x_prev[i,:,:,:]\n",
    "                    plt.subplot(cols, rows, i+x_prev.shape[0]+1)\n",
    "                    plt.imshow(im)\n",
    "                    plt.title(\"With noise\")\n",
    "                    plt.axis('off')\n",
    "\n",
    "\n",
    "                for i in range(y.shape[0]):\n",
    "                    im = y[i,:,:,:]\n",
    "                    plt.subplot(cols, rows, i+x.shape[0]+x_prev.shape[0]+1)\n",
    "                    plt.imshow(im)\n",
    "                    plt.title(\"Original\")\n",
    "                    plt.axis('off')\n",
    "            plt.subplots_adjust(wspace = 0.1, hspace = 0.5)\n",
    "            if save:\n",
    "                plt.savefig(path)\n",
    "        \n",
    "            plt.draw()\n",
    "            plt.pause(0.001)\n",
    "            \n",
    "        print_ds(test_ds.map(lambda x,y: (x[0], y[0])).take(batch_size).batch(batch_size), save=save)\n",
    "        print_ds(train_ds.map(lambda x,y: (x[0], y[0])).take(batch_size).batch(batch_size), save=False)\n",
    "        \n",
    "# print_validation(model=lambda x:x, batch_size=2, save=False, path=\"./\", datasets=(train_ds, test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def build_perceptual_loss(input_shape=(480, 720, 3)):\n",
    "    print(input_shape)\n",
    "    vgg = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    vgg.trainable = False ## Not trainable weights\n",
    "\n",
    "\n",
    "    selected_layers = ['block1_conv1', 'block2_conv2',\"block3_conv3\" ,'block4_conv3','block5_conv3']\n",
    "    selected_layer_weights = [1.0, 4.0 , 4.0 , 8.0 , 16.0]\n",
    "\n",
    "\n",
    "    outputs = [vgg.get_layer(l).output for l in selected_layers]\n",
    "    prediction_model = Model(vgg.input, outputs)\n",
    "\n",
    "    def perceptual_loss(input_image , reconstruct_image):\n",
    "        input_image = tf.keras.applications.vgg16.preprocess_input(input_image)\n",
    "        reconstruct_image = tf.keras.applications.vgg16.preprocess_input(reconstruct_image)\n",
    "\n",
    "        h1_list = prediction_model(input_image)\n",
    "        h2_list = prediction_model(reconstruct_image)\n",
    "\n",
    "        rc_loss = 0.0\n",
    "\n",
    "        for h1, h2, weight in zip(h1_list, h2_list, selected_layer_weights):\n",
    "            h1 = K.batch_flatten(h1)\n",
    "            h2 = K.batch_flatten(h2)\n",
    "            rc_loss = rc_loss + weight * K.sum(K.square(h1 - h2), axis=-1)\n",
    "\n",
    "        return rc_loss\n",
    "    \n",
    "    return perceptual_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_len\n",
    "\n",
    "# small_epochs = 30\n",
    "\n",
    "\n",
    "# small_steps_per_epoch = int((train_len/small_epochs)/BATCH_SIZE)\n",
    "# small_steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_autoencoder():\n",
    "#     inputs = keras.Input(shape=(480, 720, 3))\n",
    "#     reg = tf.keras.regularizers.l1_l2(0.1,0.1)\n",
    "#     act = layers.LeakyReLU(alpha=0.2)\n",
    "# #     args = {\"padding\":'same', \"activation\":act, \"activity_regularizer\":reg}\n",
    "#     args = {\"padding\":'same', \"activation\":act, \"kernel_initializer\":tf.keras.initializers.HeNormal(seed=32)}\n",
    "    \n",
    "#     x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "#     x = layers.Conv2D(128, kernel_size=5, strides=1, dilation_rate=2, **args)(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.MaxPool2D(2,2)(x)\n",
    "#     x = layers.SpatialDropout2D(0.3)(x)\n",
    "#     x = layers.Conv2D(128, kernel_size=3, strides=1, dilation_rate=2, **args)(x)\n",
    "#     x = layers.MaxPool2D(2,2)(x)\n",
    "#     x = layers.SpatialDropout2D(0.3)(x)\n",
    "#     x = layers.Conv2D(128, kernel_size=3, strides=1, **args)(x)\n",
    "#     x = layers.MaxPool2D(2,2)(x)\n",
    "#     x = layers.Conv2D(256, kernel_size=5, strides=2, **args)(x)\n",
    "#     x = layers.Conv2D(512, kernel_size=(2,3), strides=(2,3), **args)(x)\n",
    "    \n",
    "#     x = layers.Conv2DTranspose(512, kernel_size=(3,3), strides=(2,3), **args)(x)\n",
    "#     x = layers.Conv2DTranspose(256, kernel_size=4, strides=2, **args)(x)\n",
    "#     x = layers.Conv2DTranspose(128, kernel_size=2, strides=2, **args)(x)\n",
    "#     x = layers.Conv2DTranspose(128, kernel_size=3, strides=1, **args)(x)\n",
    "#     x = layers.UpSampling2D(2)(x)\n",
    "#     x = layers.Conv2DTranspose(64, kernel_size=3, strides=1, **args)(x)\n",
    "#     x = layers.UpSampling2D(2)(x)\n",
    "#     x = layers.Conv2DTranspose(32, kernel_size=3, strides=1, **args)(x)\n",
    "#     x = layers.Conv2DTranspose(3, kernel_size=3, strides=1, **args)(x)\n",
    "    \n",
    "#     return tf.keras.Model(inputs, x)\n",
    "    \n",
    "\n",
    "# autoencoder = build_autoencoder()\n",
    "\n",
    "class RenderImages(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        images_path = f\"./col_100_output_images/\"\n",
    "        image_name = images_path + f\"e_{epoch}.jpg\"\n",
    "#         display.clear_output()\n",
    "        print_validation(lambda x:autoencoder(x, training=False), batch_size=5, save=False, path=\"./\")\n",
    "        \n",
    "class LRMetric(tf.keras.metrics.Mean):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        lr = autoencoder.optimizer.lr\n",
    "        current_lr = lr(autoencoder.optimizer.iterations)\n",
    "        super().update_state(current_lr)\n",
    "        \n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=False,\n",
    "#                                                               patience=10, min_delta=0.)  \n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove horizontal lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelation_noise(x):\n",
    "    downsize_image_ratio = random.choice([1/2,1/5,1/10, 1/12])\n",
    "    sh = tf.cast(tf.shape(x), tf.float32)\n",
    "    \n",
    "    resized_size_h = sh[0]\n",
    "    resized_size_w = sh[1]\n",
    "    down = tf.image.resize(\n",
    "        x,\n",
    "        [int(resized_size_h * downsize_image_ratio), int(resized_size_w * downsize_image_ratio)],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "    x= tf.image.resize(\n",
    "        down,\n",
    "        [resized_size_h, resized_size_w],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "    return x\n",
    "\n",
    "def get_right_dims(shape):\n",
    "    print(shape)\n",
    "    h, w, c = shape\n",
    "    # 624, 936\n",
    "    while h > 624*1.5 and w > 936*1.5:\n",
    "        h *= 0.9\n",
    "        w *= 0.9\n",
    "    h *= 1.1\n",
    "    w *= 1.1\n",
    "    return (int(h),int(w))\n",
    "\n",
    "def random_brightness(x):\n",
    "#     x = tf.image.random_brightness(x, 0.2)\n",
    "    x = tf.image.random_contrast(x, 0.2, 0.5)\n",
    "    return x\n",
    "\n",
    "def manual_filter(slice_paths):\n",
    "    count = 1055\n",
    "    for idx, (filename, img_type) in enumerate(slice_paths):\n",
    "        input_w = 720\n",
    "        input_h = 480\n",
    "        raw_image = tf.io.read_file(filename, name=filename)\n",
    "        if img_type == \"png\":\n",
    "            img = tf.image.decode_png(raw_image, channels=3, name=filename)\n",
    "        elif img_type == \"jpg\" or img_type == \"jpeg\":\n",
    "            img = tf.image.decode_jpeg(raw_image, channels=3, name=filename)\n",
    "            \n",
    "        h,w = get_right_dims(img.shape)\n",
    "\n",
    "        img = tf.image.resize(\n",
    "            img,\n",
    "            [h, w],\n",
    "            preserve_aspect_ratio=True,\n",
    "            antialias=False,\n",
    "            name=None)\n",
    "        img = tf.cast(img, tf.uint8)\n",
    "\n",
    "        for i in range(100):\n",
    "            # * 1.3\n",
    "            cropped = tf.image.random_crop(\n",
    "              img, size=[624, 936, 3]\n",
    "            )\n",
    "            cropped_small = tf.image.resize(\n",
    "                cropped,\n",
    "                [480, 720],\n",
    "                preserve_aspect_ratio=True,\n",
    "                antialias=False,\n",
    "                name=None)\n",
    "            \n",
    "            ts = [lambda x: add_horizontal_lines_noise(x.numpy(), random.randint(-10, -8), random.randint(2, 5)),\n",
    "                 pixelation_noise,\n",
    "                  lambda x: add_horizontal_lines_noise(pixelation_noise(x).numpy(), random.randint(-10, -8), random.randint(2, 5))\n",
    "                 ]\n",
    "            \n",
    "            fn = random.choice(ts)\n",
    "            cropped_small = fn(cropped_small)\n",
    "            \n",
    "            cropped_small = tf.cast(cropped_small, tf.uint8)\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.title(f\"{cropped.shape}\")\n",
    "            plt.imshow(cropped)\n",
    "            plt.axis(\"Off\")\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.title(f\"{cropped_small.shape}\")\n",
    "            plt.imshow(cropped_small)\n",
    "            plt.axis(\"Off\")\n",
    "            plt.ion()\n",
    "            plt.show()\n",
    "            x = input()\n",
    "            \n",
    "            display.clear_output()\n",
    "            print(f\"Count={count}\")\n",
    "            if x == \"3\":\n",
    "                break\n",
    "            if x == \"1\":\n",
    "                count += 1\n",
    "                print(\"Saved!\")\n",
    "                path1 = \"./upscale_imgs/\"\n",
    "                create_dir(path1)\n",
    "                Image.fromarray(cropped.numpy()).save(f\"{path1}/{count}_large.jpeg\")\n",
    "                Image.fromarray(cropped_small.numpy()).save(f\"{path1}/{count}_small.jpeg\")\n",
    "\n",
    "# manual_filter(large_images)\n",
    "\n",
    "#                 for y1 in yield_resized_cropped(img, \"p{}_{}.jpeg\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def unsharp(x):\n",
    "    image = Image.fromarray(x)\n",
    "    return image.filter(ImageFilter.UnsharpMask(radius=2, percent=150))\n",
    "\n",
    "def pixelation_noise(x, ranges=[1/3]):\n",
    "    downsize_image_ratio = random.choice(ranges)\n",
    "    sh = tf.cast(tf.shape(x), tf.float32)\n",
    "    \n",
    "    resized_size_h = sh[0]\n",
    "    resized_size_w = sh[1]\n",
    "    down = tf.image.resize(\n",
    "        x,\n",
    "        [int(resized_size_h * downsize_image_ratio), int(resized_size_w * downsize_image_ratio)],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "    x= tf.image.resize(\n",
    "        down,\n",
    "        [resized_size_h, resized_size_w],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "    return x\n",
    "\n",
    "def random_invert_img(x, p=0.5):\n",
    "    if  tf.random.uniform([]) < p:\n",
    "        x = (255-x)\n",
    "    else:\n",
    "        x\n",
    "    return x\n",
    "\n",
    "def augment_img(x):\n",
    "#     x = tf.image.stateless_random_brightness(x, 0.2, seed)\n",
    "#     x = tf.image.random_contrast(x, 0.2, 0.5)\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    x = random_invert_img(x, p=0.4)\n",
    "    return x\n",
    "\n",
    "# def split_fn(x, y):\n",
    "#     print(x, y)\n",
    "#     return tf.image.resize(x, size=[480, 720]), y\n",
    "\n",
    "@tf.function\n",
    "def random_noise_and_resize(y):\n",
    "    def rn(x): \n",
    "        ts = [\n",
    "            lambda x: add_horizontal_lines_noise(x, random.randint(-10, -8), random.randint(2, 5)),\n",
    "            pixelation_noise,\n",
    "#             lambda x: unsharp(np.array(x)), \n",
    "            lambda x: add_horizontal_lines_noise(pixelation_noise(x,ranges=[1/3]), random.randint(-10, -8), random.randint(2, 5))\n",
    "             ]\n",
    "        fn = random.choice(ts)\n",
    "\n",
    "        return fn(x)\n",
    "    x = tf.image.resize(y, size=[480, 720])\n",
    "    return tf.numpy_function(func=rn, inp=[x], Tout=tf.float32), y\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def random_noise(y):\n",
    "    def rn(x): \n",
    "        ts = [\n",
    "            lambda x: add_horizontal_lines_noise(x, random.randint(-10, -8), random.randint(2, 5)),\n",
    "            pixelation_noise,\n",
    "#             lambda x: unsharp(np.array(x)), \n",
    "            lambda x: add_horizontal_lines_noise(pixelation_noise(x,ranges=[1/3]), random.randint(-10, -8), random.randint(2, 5))\n",
    "             ]\n",
    "        fn = random.choice(ts)\n",
    "\n",
    "        return fn(x)\n",
    "\n",
    "    return tf.numpy_function(func=rn, inp=[y], Tout=tf.float32), y\n",
    "\n",
    "def div2k_ds(split):\n",
    "    return tfds.load('div2k', split=split, shuffle_files=True)\\\n",
    "        .map(lambda x: x[\"hr\"])\\\n",
    "        .map(lambda y:tf.image.resize_with_crop_or_pad(y, 720, 1080))\\\n",
    "        .map(lambda z: tf.cast(z, tf.float32))\\\n",
    "        .map(augment_img)\\\n",
    "        .map(random_noise_and_resize)\n",
    "\n",
    "def div2k_ds_same_size(split):\n",
    "    return tfds.load('div2k', split=split, shuffle_files=True)\\\n",
    "        .map(lambda x: x[\"hr\"])\\\n",
    "        .map(lambda y:tf.image.resize_with_crop_or_pad(y, 480, 720))\\\n",
    "        .map(lambda z: tf.cast(z, tf.float32))\\\n",
    "        .map(augment_img)\\\n",
    "        .map(random_noise)\n",
    "\n",
    "div2k_ds_train = div2k_ds('train')\n",
    "div2k_ds_test = div2k_ds('validation')\n",
    "\n",
    "i = iter(div2k_ds_train)\n",
    "for j in range(3):\n",
    "    x, y = next(i)\n",
    "    plt.figure()\n",
    "    plt.imshow(tf.cast(x, tf.uint8))\n",
    "    plt.figure()\n",
    "    plt.imshow(tf.cast(y, tf.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_train_ds = create_ds(train_gen).batch(2)\n",
    "# large_test_ds = create_ds(test_gen).batch(1)\n",
    "\n",
    "# large_train_ds = create_ds_2(large_train).batch(2)\n",
    "# large_test_ds = create_ds_2(large_test).batch(1)\n",
    "\n",
    "\n",
    "\n",
    "#x = tfa.layers.GroupNormalization()(x)\n",
    "# = layers.SpatialDropout2D(0.3)(x)\n",
    "#x = layers.UpSampling2D((2,3))(x)\n",
    "\n",
    "class MyRescale(tf.keras.layers.Layer):\n",
    "  def __init__(self):\n",
    "    super(MyRescale, self).__init__()\n",
    "  def build(self, input_shape):\n",
    "     self.kernel = self.add_weight(\"kernel\", initializer=tf.keras.initializers.Constant(value=255))\n",
    "\n",
    "\n",
    "  def call(self, inputs):\n",
    "   return inputs * self.kernel\n",
    "\n",
    "class MyConcat(tf.keras.layers.Layer):\n",
    "  def __init__(self):\n",
    "    super(MyConcat, self).__init__()\n",
    "  def build(self, input_shape):\n",
    "     self.kernel = self.add_weight(\"kernel\", initializer=tf.keras.initializers.Constant(value=1))\n",
    "\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x, y = inputs\n",
    "    return tf.concat([x,y* self.kernel], axis=-1) \n",
    "\n",
    "def subpixel_deconv(filters, kernel_size, downsampleFactor):\n",
    "    def fn(x):\n",
    "#         print(f\"filters={filters}, downsampleFactor={downsampleFactor}, all_filters={filters * (downsampleFactor ** 2)}\")\n",
    "        x = tf.keras.layers.Conv2D(filters * (downsampleFactor ** 2), kernel_size, activation=\"relu\", padding=\"same\", kernel_initializer=\"Orthogonal\")(x)\n",
    "        x = tf.nn.depth_to_space(x, downsampleFactor)\n",
    "        return x\n",
    "    return fn\n",
    "\n",
    "class MyDeconv(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, name, resize_to=None, norm=True):\n",
    "        super(MyDeconv, self).__init__(name=name)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.resize_to = resize_to\n",
    "        self.strides = strides\n",
    "        self.norm = norm\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"resize_to\": self.resize_to,\n",
    "            \"strides\": self.strides,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        filters = self.filters\n",
    "        kernel_size = self.kernel_size\n",
    "        name = self.name\n",
    "        \n",
    "        strides = self.strides if isinstance(self.strides, tuple) else (self.strides,self.strides)\n",
    "                     \n",
    "        if self.resize_to is None:\n",
    "            h,w = input_shape[1], input_shape[2]\n",
    "            self.resize_to = (int(h*strides[0]),int(w*strides[1]))\n",
    "        \n",
    "        self.resize_layer = layers.Lambda(lambda x: tf.image.resize(x, self.resize_to, method=\"nearest\"), name=f\"resize_nearest_{name}\")\n",
    "        \n",
    "        def build_conv(filters, kernel_size, name):\n",
    "            conv = layers.Conv2D(filters, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=True,\n",
    "                              activation=\"relu\",\n",
    "    #                           kernel_initializer=tf.keras.initializers.HeNormal(seed=32),\n",
    "                              name=name)\n",
    "            if self.norm:\n",
    "                return tfa.layers.SpectralNormalization(conv, name=f\"{name}_spectral_norm\")\n",
    "            else:\n",
    "                return conv\n",
    "            \n",
    "        self.conv1 = build_conv(filters, kernel_size, name=f\"{name}_1\")\n",
    "        self.conv2 = build_conv(filters, kernel_size, name=f\"{name}_2\")\n",
    "        self.conv3 = build_conv(filters, kernel_size, name=f\"{name}_3\")\n",
    "        self.conv4 = build_conv(filters, kernel_size, name=f\"{name}_4\")\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.resize_layer(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        y = x\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = layers.add([x,y])\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        return x\n",
    "\n",
    "# def get_activation():\n",
    "    # return layers.LeakyReLU(alpha=0.2)\n",
    "act = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "def maxconv_name():\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        yield f\"max_conv_{i}\"\n",
    "        \n",
    "def deconv_name():\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        yield f\"deconv_{i}\"\n",
    "        \n",
    "max_conv_name = iter(maxconv_name())\n",
    "deconv_name_i = iter(deconv_name())\n",
    "\n",
    "def deconv(filters, kernel_size, strides, name, norm=False, activation=\"relu\", **args):\n",
    "    if norm:\n",
    "        return tfa.layers.SpectralNormalization(\n",
    "            layers.Conv2DTranspose(filters, kernel_size=kernel_size, strides=strides, padding=\"same\", use_bias=False,\n",
    "                          activation=activation, kernel_initializer=tf.keras.initializers.HeNormal(seed=32),\n",
    "                          name=name, **args), name=f\"{name}_spectral_norm\")\n",
    "    return layers.Conv2DTranspose(filters, kernel_size=kernel_size, strides=strides, padding=\"same\", use_bias=False, \n",
    "                      activation=activation, kernel_initializer=tf.keras.initializers.HeNormal(seed=32),\n",
    "                      name=name, **args)\n",
    "\n",
    "def conv(filters, kernel_size, strides, name, norm=False, use_init = True, use_bias=False, activation=\"relu\", **args):\n",
    "    if norm:\n",
    "        return tfa.layers.SpectralNormalization(\n",
    "            layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding=\"same\", use_bias=use_bias,\n",
    "                          activation=activation,\n",
    "                          kernel_initializer=tf.keras.initializers.HeNormal(seed=32) if use_init else None,\n",
    "                          name=name, **args), name=f\"{name}_spectral_norm\")\n",
    "    return layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding=\"same\", use_bias=use_bias,\n",
    "                      activation=activation,\n",
    "                      kernel_initializer=tf.keras.initializers.HeNormal(seed=32) if use_init else None,\n",
    "                      name=name, **args)\n",
    "\n",
    "def maxpoolconv(filters, pool_kernel_size, kernel_size=3, strides=1, norm=True):\n",
    "    name = next(max_conv_name)\n",
    "    def fn(x):\n",
    "        x = conv(filters, kernel_size=kernel_size, strides=1, name=f\"{name}_1\", norm=norm)(x)\n",
    "        y = x\n",
    "        x = conv(filters, kernel_size=kernel_size, strides=1, name=f\"{name}_2\", norm=norm)(x)\n",
    "        x = conv(filters, kernel_size=kernel_size, strides=1, name=f\"{name}_3\", norm=norm)(x)\n",
    "        x = layers.add([x,y])\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        return layers.MaxPool2D(pool_kernel_size, name=f\"{name}_maxpool\")(x)\n",
    "    return fn\n",
    "\n",
    "# def upscaleconv(filters, pool_kernel_size, kernel_size=3, strides=1, norm=True):\n",
    "#     name = next(deconv_name_i)\n",
    "#     def fn(x):\n",
    "#         x = layers.UpSampling2D(pool_kernel_size, name=f\"upsampling_{name}\")(x)\n",
    "#         x = deconv(filters, kernel_size=kernel_size, strides=strides, name=name, norm=norm)(x)\n",
    "#         return x\n",
    "#     return fn\n",
    "\n",
    "# def resizeconv(filters, new_size, kernel_size=3, strides=1, norm=True):\n",
    "#     name = next(deconv_name_i)\n",
    "#     def fn(x):\n",
    "#         x = layers.Lambda(lambda x: tf.image.resize(x, new_size, method=\"nearest\"), name=f\"resize_nearest_{name}\")(x)\n",
    "#         x = deconv(filters, kernel_size=kernel_size, strides=strides, name=name, norm=norm)(x)\n",
    "#         return x\n",
    "#     return fn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# selected_layers = ['block1_conv1', 'block2_conv2',\"block3_conv3\" ,'block4_conv3','block5_conv3']\n",
    "# selected_layer_weights = [1.0, 4.0 , 4.0 , 8.0 , 16.0]\n",
    "\n",
    "\n",
    "# outputs = [vgg.get_layer(l).output for l in selected_layers]\n",
    "# prediction_model = Model(vgg.input, outputs)\n",
    "\n",
    "def build_autoencoder_large():\n",
    "    inputs = keras.Input(shape=(480, 720, 3))\n",
    "    norm = True\n",
    "    \n",
    "    x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "#     x = layers.Lambda(lambda x: tf.image.per_image_standardization(x))(inputs)\n",
    "    \n",
    "    ffs = []\n",
    "    \n",
    "    x = conv(16, 3, 1, name=\"first_conv1\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(16, 5, 1, name=\"first_conv2\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(16, 3, 1, name=\"first_conv3\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(32, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(64, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(128, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(256, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "#     x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = maxpoolconv(512, (2,3), norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    \n",
    "    ffs.reverse()\n",
    "    x = conv(512, 3, 1, name=\"middle_conv\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    \n",
    "    x = MyDeconv(256, 3, (2,3), name=\"mydeconv7\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = layers.add([x, ffs[0]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(128, 3, 2, name=\"mydeconv6\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = layers.add([x, ffs[1]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(64, 3, 2, name=\"mydeconv5\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.add([x, ffs[2]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(32, 3, 2, name=\"mydeconv4\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.add([x, ffs[3]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(16, 3, 2, name=\"mydeconv3\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.add([x, ffs[4]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(16, 3, 1, name=\"mydeconv2\", resize_to=(360, 540))(x)\n",
    "#     x = MyDeconv(16, 3, 1, name=\"mydeconv1\", resize_to=(720, 1080), norm=norm)(x)\n",
    "    x = MyDeconv(16, 3, 2, name=\"mydeconv1\", resize_to=None, norm=norm)(x)\n",
    "    x = conv(9, 5, 1, name=\"last_conv1\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(9, 3, 1, name=\"last_conv2\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(9, 3, 1, name=\"last_conv3\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(3, 3, 1, name=\"last_conv5\", activation=\"sigmoid\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "\n",
    "#     x = deconv(64, kernel_size=1, strides=1, name=\"prelast_deconv\", norm=True)(x)\n",
    "#     x = deconv(3, kernel_size=1, strides=1, name=\"last_deconv\", norm=True)(x)\n",
    "#     x = layers.Conv2DTranspose(3, kernel_size=3, strides=1, padding=\"same\", \n",
    "#                       activation=\"sigmoid\", kernel_initializer=tf.keras.initializers.HeNormal(seed=32))(x)\n",
    "    \n",
    "#     x = MyRescale()(x)\n",
    "    x = tf.keras.layers.Rescaling(255.)(x)\n",
    "#     x = tf.keras.layers.Lambda(lambda x: tf.cast(x, tf.uint8))(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, x)\n",
    "    \n",
    "\n",
    "# class RenderImages(keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs):\n",
    "#         images_path = f\"./col_100_output_images/\"\n",
    "#         image_name = images_path + f\"e_{epoch}.jpg\"\n",
    "# #         display.clear_output()\n",
    "#         print_validation(lambda x:autoencoder(x, training=False), batch_size=5, save=False, path=\"./\", datasets=(large_train_ds, large_test_ds))\n",
    "        \n",
    "class LRMetric(tf.keras.metrics.Mean):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        lr = autoencoder.optimizer.lr\n",
    "        current_lr = lr(autoencoder.optimizer.iterations)\n",
    "        super().update_state(current_lr)\n",
    "        \n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=False,\n",
    "#                                                               patience=10, min_delta=0.)  \n",
    "\n",
    "# autoencoder = build_autoencoder_large()\n",
    "# autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder_v2():\n",
    "    class MyDeconv(tf.keras.layers.Layer):\n",
    "        def __init__(self, filters, kernel_size, strides, name, resize_to=None, norm=True):\n",
    "            super(MyDeconv, self).__init__(name=name)\n",
    "            self.filters = filters\n",
    "            self.kernel_size = kernel_size\n",
    "            self.resize_to = resize_to\n",
    "            self.strides = strides\n",
    "            self.norm = norm\n",
    "\n",
    "        def get_config(self):\n",
    "            config = super().get_config()\n",
    "            config.update({\n",
    "                \"filters\": self.filters,\n",
    "                \"kernel_size\": self.kernel_size,\n",
    "                \"resize_to\": self.resize_to,\n",
    "                \"strides\": self.strides,\n",
    "            })\n",
    "            return config\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            filters = self.filters\n",
    "            kernel_size = self.kernel_size\n",
    "            name = self.name\n",
    "\n",
    "            strides = self.strides if isinstance(self.strides, tuple) else (self.strides,self.strides)\n",
    "\n",
    "            if self.resize_to is None:\n",
    "                h,w = input_shape[1], input_shape[2]\n",
    "                self.resize_to = (int(h*strides[0]),int(w*strides[1]))\n",
    "\n",
    "            self.resize_layer = layers.Lambda(lambda x: tf.image.resize(x, self.resize_to, method=\"nearest\"), name=f\"resize_nearest_{name}\")\n",
    "\n",
    "            def build_conv(filters, kernel_size, name):\n",
    "                conv = layers.Conv2D(filters, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=True,\n",
    "                                  activation=\"relu\",\n",
    "        #                           kernel_initializer=tf.keras.initializers.HeNormal(seed=32),\n",
    "                                  name=name)\n",
    "                if self.norm:\n",
    "                    return tfa.layers.SpectralNormalization(conv, name=f\"{name}_spectral_norm\")\n",
    "                else:\n",
    "                    return conv\n",
    "\n",
    "            self.conv1 = build_conv(filters, kernel_size, name=f\"{name}_1\")\n",
    "            self.conv2 = build_conv(filters, kernel_size, name=f\"{name}_2\")\n",
    "\n",
    "\n",
    "        def call(self, inputs):\n",
    "            x = self.resize_layer(inputs)\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            return x\n",
    "    def maxpoolconv(filters, pool_kernel_size, kernel_size=3, strides=1, norm=True):\n",
    "        name = next(max_conv_name)\n",
    "        def fn(x):\n",
    "            x = conv(filters, kernel_size=3, strides=1, name=f\"{name}_1\", norm=norm)(x)\n",
    "            x = conv(filters, kernel_size=5, strides=1, name=f\"{name}_2\", norm=norm)(x)\n",
    "            return layers.MaxPool2D(pool_kernel_size, name=f\"{name}_maxpool\")(x)\n",
    "        return fn\n",
    "    \n",
    "    inputs = keras.Input(shape=(480, 720, 3))\n",
    "    norm = True\n",
    "    \n",
    "    x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "#     x = layers.Lambda(lambda x: tf.image.per_image_standardization(x))(inputs)\n",
    "    \n",
    "    ffs = []\n",
    "    \n",
    "    x = conv(16, 3, 1, name=\"first_conv1\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(32, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(64, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(128, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(512, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "#     x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = maxpoolconv(1024, (2,3), norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    \n",
    "    ffs.reverse()\n",
    "    x = conv(1024, 3, 1, name=\"middle_conv\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    \n",
    "    x = MyDeconv(512, 3, (2,3), name=\"mydeconv7\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = layers.add([x, ffs[0]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(128, 3, 2, name=\"mydeconv6\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = layers.add([x, ffs[1]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(64, 3, 2, name=\"mydeconv5\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.add([x, ffs[2]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(32, 3, 2, name=\"mydeconv4\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.add([x, ffs[3]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(16, 3, 2, name=\"mydeconv3\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.add([x, ffs[4]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(16, 3, 1, name=\"mydeconv2\", resize_to=(360, 540))(x)\n",
    "#     x = MyDeconv(16, 3, 1, name=\"mydeconv1\", resize_to=(720, 1080), norm=norm)(x)\n",
    "    x = MyDeconv(9, 3, 2, name=\"mydeconv1\", resize_to=None, norm=norm)(x)\n",
    "    x = conv(9, 5, 1, name=\"last_conv1\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(9, 3, 1, name=\"last_conv2\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(6, 3, 1, name=\"last_conv3\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(3, 3, 1, name=\"last_conv5\", activation=\"sigmoid\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "\n",
    "#     x = deconv(64, kernel_size=1, strides=1, name=\"prelast_deconv\", norm=True)(x)\n",
    "#     x = deconv(3, kernel_size=1, strides=1, name=\"last_deconv\", norm=True)(x)\n",
    "#     x = layers.Conv2DTranspose(3, kernel_size=3, strides=1, padding=\"same\", \n",
    "#                       activation=\"sigmoid\", kernel_initializer=tf.keras.initializers.HeNormal(seed=32))(x)\n",
    "    \n",
    "#     x = MyRescale()(x)\n",
    "    x = tf.keras.layers.Rescaling(255.)(x)\n",
    "#     x = tf.keras.layers.Lambda(lambda x: tf.cast(x, tf.uint8))(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, x)\n",
    "\n",
    "# autoencoder = build_denoising_autoencoder()\n",
    "# autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder_large_v3():\n",
    "    class MyDeconv(tf.keras.layers.Layer):\n",
    "        def __init__(self, filters, kernel_size, strides, name, resize_to=None, norm=True):\n",
    "            super(MyDeconv, self).__init__(name=name)\n",
    "            self.filters = filters\n",
    "            self.kernel_size = kernel_size\n",
    "            self.resize_to = resize_to\n",
    "            self.strides = strides\n",
    "            self.norm = norm\n",
    "\n",
    "        def get_config(self):\n",
    "            config = super().get_config()\n",
    "            config.update({\n",
    "                \"filters\": self.filters,\n",
    "                \"kernel_size\": self.kernel_size,\n",
    "                \"resize_to\": self.resize_to,\n",
    "                \"strides\": self.strides,\n",
    "            })\n",
    "            return config\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            filters = self.filters\n",
    "            kernel_size = self.kernel_size\n",
    "            name = self.name\n",
    "\n",
    "            strides = self.strides if isinstance(self.strides, tuple) else (self.strides,self.strides)\n",
    "\n",
    "            if self.resize_to is None:\n",
    "                h,w = input_shape[1], input_shape[2]\n",
    "                self.resize_to = (int(h*strides[0]),int(w*strides[1]))\n",
    "\n",
    "            self.resize_layer = layers.Lambda(lambda x: tf.image.resize(x, self.resize_to, method=\"nearest\"), name=f\"resize_nearest_{name}\")\n",
    "\n",
    "            def build_conv(filters, kernel_size, name):\n",
    "                conv = layers.Conv2D(filters, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=True,\n",
    "                                  activation=\"relu\",\n",
    "                                kernel_initializer='glorot_uniform',\n",
    "\n",
    "        #                           kernel_initializer=tf.keras.initializers.HeNormal(seed=32),\n",
    "                                  name=name)\n",
    "                if self.norm:\n",
    "                    return tfa.layers.SpectralNormalization(conv, name=f\"{name}_spectral_norm\")\n",
    "                else:\n",
    "                    return conv\n",
    "\n",
    "            self.conv1 = build_conv(filters, kernel_size, name=f\"{name}_1\")\n",
    "            self.conv2 = build_conv(filters, kernel_size, name=f\"{name}_2\")\n",
    "\n",
    "\n",
    "        def call(self, inputs):\n",
    "            x = self.resize_layer(inputs)\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            return x\n",
    "    def maxpoolconv(filters, pool_kernel_size, kernel_size=3, strides=1, norm=True):\n",
    "        name = next(max_conv_name)\n",
    "        def fn(x):\n",
    "            x = conv(filters, kernel_size=3, strides=1, name=f\"{name}_1\", norm=norm)(x)\n",
    "            x = conv(filters, kernel_size=5, strides=1, name=f\"{name}_2\", norm=norm)(x)\n",
    "            return layers.MaxPool2D(pool_kernel_size, name=f\"{name}_maxpool\")(x)\n",
    "        return fn\n",
    "    \n",
    "    inputs = keras.Input(shape=(480, 720, 3))\n",
    "    norm = True\n",
    "    \n",
    "    x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "#     x = layers.Lambda(lambda x: tf.image.per_image_standardization(x))(inputs)\n",
    "    \n",
    "    ffs = []\n",
    "    \n",
    "    large_inputs = MyDeconv(16, 3, 1, name=\"input_ff\", resize_to=(720, 1080), norm=norm)(inputs)\n",
    "    \n",
    "    x = conv(16, 3, 1, name=\"first_conv1\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(32, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(64, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(128, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "    x = maxpoolconv(512, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.2)(x))\n",
    "#     x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = maxpoolconv(1024, (2,3), norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    \n",
    "    ffs.reverse()\n",
    "    x = conv(1024, 3, 1, name=\"middle_conv\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    \n",
    "    x = MyDeconv(512, 3, (2,3), name=\"mydeconv7\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = layers.add([x, ffs[0]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(128, 3, 2, name=\"mydeconv6\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = layers.add([x, ffs[1]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(64, 3, 2, name=\"mydeconv5\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.add([x, ffs[2]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(32, 3, 2, name=\"mydeconv4\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.add([x, ffs[3]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(16, 3, 2, name=\"mydeconv3\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.add([x, ffs[4]])\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MyDeconv(16, 3, 1, name=\"mydeconv2\", resize_to=(360, 540))(x)\n",
    "#     x = MyDeconv(16, 3, 1, name=\"mydeconv1\", resize_to=(720, 1080), norm=norm)(x)\n",
    "    x = MyDeconv(9, 3, 2, name=\"mydeconv1\", resize_to=None, norm=norm)(x)\n",
    "    x = tf.concat([x, large_inputs], axis=-1)\n",
    "    x = conv(9, 1, 1, name=\"last_conv1\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(9, 3, 1, name=\"last_conv2\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(6, 3, 1, name=\"last_conv3\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(3, 3, 1, name=\"last_conv5\", activation=\"sigmoid\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "\n",
    "#     x = deconv(64, kernel_size=1, strides=1, name=\"prelast_deconv\", norm=True)(x)\n",
    "#     x = deconv(3, kernel_size=1, strides=1, name=\"last_deconv\", norm=True)(x)\n",
    "#     x = layers.Conv2DTranspose(3, kernel_size=3, strides=1, padding=\"same\", \n",
    "#                       activation=\"sigmoid\", kernel_initializer=tf.keras.initializers.HeNormal(seed=32))(x)\n",
    "    \n",
    "#     x = MyRescale()(x)\n",
    "    x = tf.keras.layers.Rescaling(255.)(x)\n",
    "#     x = tf.keras.layers.Lambda(lambda x: tf.cast(x, tf.uint8))(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, x)\n",
    "\n",
    "# autoencoder = build_denoising_autoencoder()\n",
    "# autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "initial_learning_rate = 5e-7\n",
    "search_epochs = 60\n",
    "\n",
    "def lr_exp_decay(epoch, lr):\n",
    "    k = 0.2\n",
    "    return initial_learning_rate * math.exp(k*epoch)\n",
    "\n",
    "for i in range(search_epochs):\n",
    "    lr = lr_exp_decay(i, initial_learning_rate)\n",
    "    print(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_train_ds = div2k_ds('train').batch(2)\n",
    "large_test_ds = div2k_ds('validation').batch(2)\n",
    "\n",
    "class RenderImages(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        images_path = f\"./col_100_output_images/\"\n",
    "        image_name = images_path + f\"e_{epoch}.jpg\"\n",
    "#         display.clear_output()\n",
    "        print_validation(lambda x:autoencoder(x, training=False), batch_size=5, save=False, path=\"./\", datasets=(large_train_ds, large_test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(train_ds, test_ds):\n",
    "    version = \"find_lr\"\n",
    "\n",
    "    log_dir = f\"./prepa_autencoder_logs/{version}\"\n",
    "\n",
    "    # file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "    # file_writer.set_as_default()\n",
    "\n",
    "\n",
    "    model = TrainerAcc(autoencoder=build_autoencoder_large(), acc_gradients=4)\n",
    "    # model = build_autoencoder_large()\n",
    "\n",
    "    perceptual_loss = build_perceptual_loss(input_shape=(720, 1080, 3))\n",
    "\n",
    "    opt = tfa.optimizers.AdamW(weight_decay=0.0001, learning_rate=initial_learning_rate, beta_1=0.8, beta_2=0.99)\n",
    "\n",
    "    lm = tf.keras.callbacks.LearningRateScheduler(lr_exp_decay, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "    class LRMetric(tf.keras.metrics.Mean):\n",
    "        def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "            super().update_state(model.optimizer.lr)\n",
    "\n",
    "    class GradientUpdates(tf.keras.metrics.Metric):\n",
    "\n",
    "      def __init__(self, name='binary_true_positives', **kwargs):\n",
    "        super(GradientUpdates, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='gradient_updates', initializer='zeros', dtype=tf.int32)\n",
    "\n",
    "      def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.true_positives.assign(model.gradient_updates)\n",
    "\n",
    "      def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "\n",
    "\n",
    "    model.compile(optimizer=opt, loss=perceptual_loss, metrics=[GradientUpdates(name=\"gradient_upds\"), LRMetric(name=\"lr_metric\")])\n",
    "    # model.compile(optimizer=opt, loss=perceptual_loss, metrics=[LRMetric(name=\"lr_metric\")])\n",
    "\n",
    "\n",
    "\n",
    "    tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir,\n",
    "                      write_graph=True,\n",
    "                      histogram_freq = 1,\n",
    "                      update_freq=\"epoch\"\n",
    "                      )\n",
    "\n",
    "    # def on_batch_begin(batch, logs):\n",
    "    #     model.dummy_step += 1\n",
    "    #     model.acc_gradients = 3\n",
    "\n",
    "    # lm2 = tf.keras.callbacks.LambdaCallback(on_batch_begin=on_batch_begin)\n",
    "    class RenderImages(keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs):\n",
    "            images_path = f\"./col_100_output_images/\"\n",
    "            image_name = images_path + f\"e_{epoch}.jpg\"\n",
    "    #         display.clear_output()\n",
    "            print_validation(lambda x:autoencoder(x, training=False), batch_size=5, save=False, path=\"./\", datasets=(large_train_ds, large_test_ds))\n",
    "\n",
    "    ghistory = model.fit(train_ds.prefetch(tf.data.AUTOTUNE).repeat(),\n",
    "                                    epochs=search_epochs, \n",
    "                                    steps_per_epoch=200,\n",
    "                                    validation_data=test_ds.prefetch(tf.data.AUTOTUNE),\n",
    "          callbacks=[lm, tboard_callback])\n",
    "    \n",
    "# find_lr(large_train_ds, large_test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the best range of learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_lr_range = [1e-4, 5e-7]\n",
    "best_lr_range = [5e-6, 5e-7]\n",
    "\n",
    "initial_learning_rate = best_lr_range[0]\n",
    "search_epochs = 100\n",
    "\n",
    "def lr_from_search(epochs):\n",
    "    lrs = tf.linspace(best_lr_range[0], best_lr_range[1], epochs, name=None, axis=0)\n",
    "    def fn(epoch, lr):\n",
    "        return lrs[epoch]\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_from_range(epochs, lr_range):\n",
    "    start,end = lr_range\n",
    "    lrs = tf.linspace(start, end, epochs, name=None, axis=0)\n",
    "    def fn(epoch, lr):\n",
    "        if epoch > epochs:\n",
    "            return end\n",
    "        return lrs[epoch]\n",
    "    return fn\n",
    "    \n",
    "lr_from_range(10, (5e-6, 5e-7))(4, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RangedExpDecay(tf.keras.optimizers.schedules.ExponentialDecay):\n",
    "    def __init__(self, end, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.end = end\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        return tf.math.maximum(super().__call__(step), self.end)\n",
    "\n",
    "def schedule_exp_lr_range(start, end):\n",
    "    return RangedExpDecay(\n",
    "        end,\n",
    "        start,\n",
    "        decay_steps=50,\n",
    "        decay_rate=0.95,\n",
    "        staircase=False)\n",
    "\n",
    "\n",
    "# llr = schedule_exp_lr_range(best_lr_range[0], best_lr_range[1])\n",
    "\n",
    "# ll = [llr(i).numpy() for i in range((400//3)*100)]\n",
    "# plt.plot(ll)\n",
    "# llr((400//3)*100).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the found learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainStep(tf.keras.Model):\n",
    "    def __init__(self, n_gradients, autoencoder, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.autoencoder = autoencoder\n",
    "        print(f\"CustomTrainStep: n_gradients = {n_gradients}\")\n",
    "        self.n_gradients = tf.Variable(n_gradients, dtype=tf.int32, trainable=False)\n",
    "        self.n_acum_step = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "        self.update_count = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "        self.gradient_accumulation = [tf.Variable(tf.zeros_like(v, dtype=tf.float32), \n",
    "                                                  trainable=False) for v in self.trainable_variables]\n",
    "\n",
    "        \n",
    "    def call(self, data):\n",
    "        return self.autoencoder(data, training=False)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        self.n_acum_step.assign_add(1)\n",
    "\n",
    "        x, y = data\n",
    "        # Gradient Tape\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.autoencoder(x, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        # Calculate batch gradients\n",
    "        gradients = tape.gradient(loss, self.autoencoder.trainable_variables)\n",
    "        # Accumulate batch gradients\n",
    "        for i in range(len(self.gradient_accumulation)):\n",
    "            self.gradient_accumulation[i].assign_add(gradients[i])\n",
    " \n",
    "        # If n_acum_step reach the n_gradients then we apply accumulated gradients to update the variables otherwise do nothing\n",
    "        tf.cond(tf.equal(self.n_acum_step, self.n_gradients), self.apply_accu_gradients, lambda: None)\n",
    "\n",
    "        # update metrics\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def apply_accu_gradients(self):\n",
    "        # apply accumulated gradients\n",
    "        self.optimizer.apply_gradients(zip(self.gradient_accumulation, self.autoencoder.trainable_variables))\n",
    "        self.update_count.assign_add(1)\n",
    "\n",
    "        # reset\n",
    "        self.n_acum_step.assign(0)\n",
    "        for i in range(len(self.gradient_accumulation)):\n",
    "            self.gradient_accumulation[i].assign(tf.zeros_like(self.autoencoder.trainable_variables[i], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result yet:\n",
    "\n",
    "- In 150/300 epochs, with ranges best_lr_range = [3e-5, 5e-7] and linspace of size 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %rm -r ./prepa_autoencoder_ckpt_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cp -r ./prepa_autoencoder_ckpt_optimized_backupt ./prepa_autoencoder_ckpt_optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, don't rescale, only denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1 = \"0001\"\n",
    "model_v2 = \"0002\"\n",
    "\n",
    "def train_denoiser(autoencoder, name, train_ds, test_ds, v, epochs, lr_range, logsdir, output_size, load_checkpoint=True, n_gradients=3):\n",
    "    version = f\"{name}_v{v}\"\n",
    "    print(version)\n",
    "\n",
    "    log_dir = f\"./{logsdir}/{version}\"\n",
    "    print(f\"n_gradients={n_gradients}\")\n",
    "    model = CustomTrainStep(n_gradients=n_gradients, autoencoder=autoencoder)\n",
    "        \n",
    "    class LRMetric(tf.keras.metrics.Mean):\n",
    "        def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "            super().update_state(model.optimizer.lr)\n",
    "\n",
    "    class GradientUpdates(tf.keras.metrics.Metric):\n",
    "      def __init__(self, name='binary_true_positives', **kwargs):\n",
    "        super(GradientUpdates, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='gradient_updates', initializer='zeros', dtype=tf.int32)\n",
    "\n",
    "      def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.true_positives.assign(model.update_count)\n",
    "\n",
    "      def result(self):\n",
    "        return self.true_positives\n",
    "        \n",
    "    perceptual_loss = build_perceptual_loss(input_shape=(output_size[0], output_size[1], 3))\n",
    "    \n",
    "    lr_schedule=lr_range[0]\n",
    "    lr_sch_callback = tf.keras.callbacks.LearningRateScheduler(lr_from_range(epochs, lr_range), verbose=1)\n",
    "    opt = tfa.optimizers.AdamW(weight_decay=0.0001, learning_rate=lr_schedule, beta_1=0.8, beta_2=0.99)\n",
    "    \n",
    "    checkpoint_dir = f'./prepa_{name}_ckpt'\n",
    "    checkpoint = tf.train.Checkpoint(model=model.autoencoder, optimizer=opt)\n",
    "    ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)\n",
    "\n",
    "    \n",
    "    if load_checkpoint and ckpt_manager.latest_checkpoint:\n",
    "#             checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "            checkpoint.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
    "            model.autoencoder.save_weights(f'./saved_models/{name}_{model_v1}')\n",
    "    else:\n",
    "        print(\"No checkpoints found or loaded\")\n",
    "#     try:\n",
    "#         if ckpt_manager.latest_checkpoint:\n",
    "#             checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "#     except:\n",
    "#         print(\"Could not restore the checkopint\")  \n",
    "\n",
    "#     lr_sch_callback = tf.keras.callbacks.LearningRateScheduler(lr_from_search(epochs), verbose=1)\n",
    "    \n",
    "#     train_fn(model, 10, perceptual_loss, opt)\n",
    "\n",
    "#     with strategy.scope():\n",
    "    model.compile(optimizer=opt, loss=perceptual_loss, metrics=[\n",
    "        GradientUpdates(name=\"gradient_upds\"),\n",
    "        LRMetric(name=\"lr_metric\"),\n",
    "        \"mse\"\n",
    "    ])\n",
    "\n",
    "    tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir,\n",
    "                      write_graph=True,\n",
    "                      histogram_freq = 1,\n",
    "                      update_freq=\"epoch\"\n",
    "                      )\n",
    "\n",
    "\n",
    "    class RenderImages(keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs):\n",
    "            images_path = f\"./col_100_output_images/\"\n",
    "            image_name = images_path + f\"e_{epoch}.jpg\"\n",
    "            if epoch % 5 == 0:\n",
    "                display.clear_output()\n",
    "            print_validation(lambda x:model(x, training=False), batch_size=2, save=False, path=\"./\", datasets=(large_train_ds, large_test_ds))\n",
    "\n",
    "    def on_epoch_end(batch, logs):\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "\n",
    "    lm = tf.keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=False,\n",
    "                                                                  patience=30, min_delta=0.)  \n",
    "\n",
    "    ghistory = model.fit(train_ds.prefetch(tf.data.AUTOTUNE),\n",
    "                                    epochs=epochs,\n",
    "                                    validation_data=test_ds.prefetch(tf.data.AUTOTUNE),\n",
    "          callbacks=[\n",
    "              RenderImages(),\n",
    "#               early_stop,\n",
    "              lm,\n",
    "              lr_sch_callback,\n",
    "              tboard_callback])\n",
    "    \n",
    "    weights_path = f'./saved_models/{name}_{model_v2}'\n",
    "    \n",
    "    model.autoencoder.save_weights(weights_path)\n",
    "    print(f'model saved to: {weights_path}')\n",
    "    return weights_path, ghistory\n",
    "    \n",
    "# train_denoiser(build_denoising_autoencoder(),\n",
    "#                \"denoise_first\", \n",
    "#                div2k_ds_same_size(\"train\").batch(2),\n",
    "#                div2k_ds_same_size(\"validation\").batch(2),\n",
    "#                v,\n",
    "#                epochs=400,\n",
    "#                lr_range=(1e-4, 5e-7),\n",
    "#                logsdir=\"prepa_autencoder_logs\",\n",
    "#                output_size=(480, 720))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling\n",
    "\n",
    "(if this works, delete the next cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path, ghistory= train_denoiser(build_autoencoder_large(),\n",
    "               \"denoise_and_scale_large_v4\", \n",
    "               div2k_ds(\"train\").batch(2),\n",
    "               div2k_ds(\"validation\").batch(2),\n",
    "               v,\n",
    "               epochs=100,\n",
    "               lr_range=(2e-4, 5e-7),\n",
    "               logsdir=\"prepa_autencoder_logs\",\n",
    "               output_size=(720, 1080),\n",
    "                load_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path, ghistory= train_denoiser(build_autoencoder_large(),\n",
    "               \"denoise_and_scale_100e\", \n",
    "               div2k_ds(\"train\").batch(2),\n",
    "               div2k_ds(\"validation\").batch(2),\n",
    "               v,\n",
    "               epochs=100,\n",
    "               lr_range=(2e-4, 5e-7),\n",
    "               logsdir=\"prepa_autencoder_logs\",\n",
    "               output_size=(720, 1080),\n",
    "                load_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path, ghistory= train_denoiser(build_autoencoder_v2(),\n",
    "#                \"denoise_and_scale_100e_v2\", \n",
    "                \"denoise_and_scale_100e_v2_reprice\", \n",
    "               div2k_ds(\"train\").batch(2),\n",
    "               div2k_ds(\"validation\").batch(2),\n",
    "               v,\n",
    "               epochs=100,\n",
    "               lr_range=(6e-5, 5e-7),\n",
    "               logsdir=\"prepa_autencoder_logs\",\n",
    "               output_size=(720, 1080),\n",
    "                load_checkpoint=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023-01-28: The following code produces the best results yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path, ghistory= train_denoiser(build_autoencoder_large_v3(),\n",
    "               \"denoise_and_scale_100e_large_v3\", \n",
    "               div2k_ds(\"train\").batch(2),\n",
    "               div2k_ds(\"validation\").batch(2),\n",
    "               v,\n",
    "               epochs=200,\n",
    "               lr_range=(1e-4, 5e-7),\n",
    "               logsdir=\"prepa_autencoder_logs\",\n",
    "               output_size=(720, 1080),\n",
    "                load_checkpoint=False,\n",
    "                n_gradients=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path, ghistory= train_denoiser(build_autoencoder_large_v3(),\n",
    "               \"denoise_and_scale_100e_large_v4\", \n",
    "               div2k_ds(\"train\").batch(2),\n",
    "               div2k_ds(\"validation\").batch(2),\n",
    "               v,\n",
    "               epochs=100,\n",
    "               lr_range=(2e-4, 5e-7),\n",
    "               logsdir=\"prepa_autencoder_logs\",\n",
    "               output_size=(720, 1080),\n",
    "                load_checkpoint=False,\n",
    "                n_gradients=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - Train the model without gradient accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1 = \"0001\"\n",
    "model_v2 = \"0002\"\n",
    "\n",
    "def train_denoiser_fixed_lr_decay(autoencoder, name, train_ds, test_ds, v, epochs, lr_range, logsdir, output_size, load_checkpoint=True, n_gradients=3):\n",
    "    version = f\"{name}_v{v}\"\n",
    "    print(version)\n",
    "\n",
    "    log_dir = f\"./{logsdir}/{version}\"\n",
    "    print(f\"n_gradients={n_gradients}\")\n",
    "    model = CustomTrainStep(n_gradients=n_gradients, autoencoder=autoencoder)\n",
    "        \n",
    "    class LRMetric(tf.keras.metrics.Mean):\n",
    "        def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "            super().update_state(model.optimizer.lr)\n",
    "\n",
    "    class GradientUpdates(tf.keras.metrics.Metric):\n",
    "      def __init__(self, name='binary_true_positives', **kwargs):\n",
    "        super(GradientUpdates, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='gradient_updates', initializer='zeros', dtype=tf.int32)\n",
    "\n",
    "      def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.true_positives.assign(model.update_count)\n",
    "\n",
    "      def result(self):\n",
    "        return self.true_positives\n",
    "        \n",
    "    perceptual_loss = build_perceptual_loss(input_shape=(output_size[0], output_size[1], 3))\n",
    "    \n",
    "    lr_schedule=lr_range[0]\n",
    "    lr_sch_callback = tf.keras.callbacks.LearningRateScheduler(lr_from_range(100, lr_range), verbose=1)\n",
    "    opt = tfa.optimizers.AdamW(weight_decay=0.0001, learning_rate=lr_schedule, beta_1=0.8, beta_2=0.99)\n",
    "    \n",
    "    checkpoint_dir = f'./prepa_{name}_ckpt'\n",
    "    checkpoint = tf.train.Checkpoint(model=model.autoencoder, optimizer=opt)\n",
    "    ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)\n",
    "\n",
    "    \n",
    "    if load_checkpoint and ckpt_manager.latest_checkpoint:\n",
    "#             checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "            checkpoint.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
    "            model.autoencoder.save_weights(f'./saved_models/{name}_{model_v1}')\n",
    "    else:\n",
    "        print(\"No checkpoints found or loaded\")\n",
    "#     try:\n",
    "#         if ckpt_manager.latest_checkpoint:\n",
    "#             checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "#     except:\n",
    "#         print(\"Could not restore the checkopint\")  \n",
    "\n",
    "#     lr_sch_callback = tf.keras.callbacks.LearningRateScheduler(lr_from_search(epochs), verbose=1)\n",
    "    \n",
    "#     train_fn(model, 10, perceptual_loss, opt)\n",
    "\n",
    "#     with strategy.scope():\n",
    "    model.compile(optimizer=opt, loss=perceptual_loss, metrics=[\n",
    "        GradientUpdates(name=\"gradient_upds\"),\n",
    "        LRMetric(name=\"lr_metric\"),\n",
    "        \"mse\"\n",
    "    ])\n",
    "\n",
    "    tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir,\n",
    "                      write_graph=True,\n",
    "                      histogram_freq = 1,\n",
    "                      update_freq=\"epoch\"\n",
    "                      )\n",
    "\n",
    "\n",
    "    class RenderImages(keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs):\n",
    "            images_path = f\"./col_100_output_images/\"\n",
    "            image_name = images_path + f\"e_{epoch}.jpg\"\n",
    "            if epoch % 5 == 0:\n",
    "                display.clear_output()\n",
    "            print_validation(lambda x:model(x, training=False), batch_size=2, save=False, path=\"./\", datasets=(large_train_ds, large_test_ds))\n",
    "\n",
    "    def on_epoch_end(batch, logs):\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "\n",
    "    lm = tf.keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=False,\n",
    "                                                                  patience=30, min_delta=0.)  \n",
    "\n",
    "    ghistory = model.fit(train_ds.prefetch(tf.data.AUTOTUNE),\n",
    "                                    epochs=epochs,\n",
    "                                    validation_data=test_ds.prefetch(tf.data.AUTOTUNE),\n",
    "          callbacks=[\n",
    "              RenderImages(),\n",
    "#               early_stop,\n",
    "              lm,\n",
    "              lr_sch_callback,\n",
    "              tboard_callback])\n",
    "    \n",
    "    weights_path = f'./saved_models/{name}_{model_v2}'\n",
    "    \n",
    "    model.autoencoder.save_weights(weights_path)\n",
    "    print(f'model saved to: {weights_path}')\n",
    "    return weights_path, ghistory\n",
    "    \n",
    "# train_denoiser(build_denoising_autoencoder(),\n",
    "#                \"denoise_first\", \n",
    "#                div2k_ds_same_size(\"train\").batch(2),\n",
    "#                div2k_ds_same_size(\"validation\").batch(2),\n",
    "#                v,\n",
    "#                epochs=400,\n",
    "#                lr_range=(1e-4, 5e-7),\n",
    "#                logsdir=\"prepa_autencoder_logs\",\n",
    "#                output_size=(480, 720))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path, ghistory= train_denoiser_fixed_lr_decay(build_autoencoder_large_v3(),\n",
    "               \"denoise_and_scale_100e_large_v4\", \n",
    "               div2k_ds(\"train\").batch(2),\n",
    "               div2k_ds(\"validation\").batch(2),\n",
    "               v,\n",
    "               epochs=100,\n",
    "               lr_range=(2e-4, 5e-7),\n",
    "               logsdir=\"prepa_autencoder_logs\",\n",
    "               output_size=(720, 1080),\n",
    "                load_checkpoint=False,\n",
    "                n_gradients=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.save_weights('./saved_models/v0_0_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_grad_acc_model(model_name, model_fn):\n",
    "    model = model_fn()\n",
    "    model.load_weights(f'./saved_models/{model_name}')\n",
    "#     checkpoint_dir = './prepa_autoencoder_ckpt_optimized'\n",
    "#     checkpoint = tf.train.Checkpoint(model=model)\n",
    "#     ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)\n",
    "\n",
    "#     try:\n",
    "#         if ckpt_manager.latest_checkpoint:\n",
    "#             checkpoint.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
    "#     except:\n",
    "#         print(\"Could not restore the checkopint\") \n",
    "    return model\n",
    "\n",
    "def test_prepa(autoencoder):\n",
    "    prepa = [(str(p),'png') for p in pathlib.Path(\"./prepa\").glob('*.png')]\n",
    "\n",
    "    def gen_img(img_path, img_type):\n",
    "        raw_png = tf.io.read_file(str(img_path), name=img_path)\n",
    "        return tf.image.decode_png(raw_png, channels=3, name=img_path)\n",
    "\n",
    "    def gen_prepa():\n",
    "        for img_path, img_type in prepa:\n",
    "            yield gen_img(img_path, img_type)\n",
    "\n",
    "    it = iter(gen_prepa())    \n",
    "    for i in range(10):\n",
    "\n",
    "\n",
    "        img = next(it)\n",
    "        plt.figure()\n",
    "        plt.imshow(img)\n",
    "        plt.figure()\n",
    "        y_pred = autoencoder.predict(tf.expand_dims(img, axis=0))\n",
    "        y_pred = tf.cast(y_pred, tf.uint8)\n",
    "        plt.imshow(y_pred[0])\n",
    "\n",
    "\n",
    "    # tf.math.reduce_mean(\n",
    "    #     y_pred, axis=[1,2], keepdims=False, name=None\n",
    "    # )\n",
    "\n",
    "    # y = tf.reshape(y_pred, (1,-1,3))\n",
    "    # y = layers.AveragePooling1D(2)(tf.cast(y, tf.float32))\n",
    "    # y = layers.AveragePooling1D(2)(tf.cast(y, tf.float32))\n",
    "    # y = layers.AveragePooling1D(2)(tf.cast(y, tf.float32))\n",
    "    # # y = tf.image.resize(y, (720, 1080))\n",
    "    # y\n",
    "test_prepa(restore_grad_acc_model(\"denoise_and_scale_0002\", build_autoencoder_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prepa(restore_grad_acc_model(\"denoise_and_scale_100e_v2_0002\", build_autoencoder_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = restore_grad_acc_model(\"denoise_and_scale_100e_large_v3_0002\", build_autoencoder_large_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('./saved_models/denoise_autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prepa(tf.keras.models.load_model('./saved_models/denoise_autoencoder'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "4327198819dafd55a2243f22aba11bf2a7d9f0c32aced8ba7d18a900e49d0553"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
