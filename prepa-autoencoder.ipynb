{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda/\n",
    "!export CUDA_DIR=/usr/lib/cuda/\n",
    "# !export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:/home/pedro/miniconda3/envs/ml2/lib/\n",
    "# !export TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ${CUDA_DIR}/nvvm/libdevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(f\"gpus={gpus}\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten,\\\n",
    "                                    Reshape, LeakyReLU as LR,\\\n",
    "                                    Activation, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display # If using IPython, Colab or Jupyter\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://drive.google.com/uc?export=download&id=0B7EVK8r0v71pZjFTYXZWM3FlRnM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "\n",
    "data_dir = pathlib.Path(\"./prepa\")\n",
    "# prepa_dir = pathlib.Path(\"./prepa\")\n",
    "prepa_files = list(data_dir.glob('*.png'))\n",
    "all_files = []\n",
    "for filename in prepa_files:\n",
    "    all_files.append((filename, 'png'))\n",
    "for filename in list(data_dir.glob('*.jpg')):\n",
    "    all_files.append((filename, 'jpg'))\n",
    "    \n",
    "def tmp_images_gen():\n",
    "    for filename, img_type in all_files:\n",
    "        raw_image = tf.io.read_file(str(filename), name=filename)\n",
    "        if img_type == \"png\":\n",
    "            yield tf.image.decode_png(raw_image, channels=3, name=filename)\n",
    "        elif img_type == \"jpg\":\n",
    "            yield tf.image.decode_jpeg(raw_image, channels=3, name=filename)\n",
    "            \n",
    "\n",
    "def unsharp(x):\n",
    "    image = Image.fromarray(x)\n",
    "    return image.filter(ImageFilter.UnsharpMask(radius=2, percent=150))\n",
    "\n",
    "def conservative_smoothing_gray(data, filter_size):\n",
    "    temp = []\n",
    "    indexer = filter_size // 2\n",
    "    new_image = data.copy()\n",
    "    nrow, ncol, nch = data.shape\n",
    "    for ch in range(nch):\n",
    "        for i in range(nrow):\n",
    "            for j in range(ncol):\n",
    "                for k in range(i-indexer, i+indexer+1):\n",
    "                    for m in range(j-indexer, j+indexer+1):\n",
    "                        if (k > -1) and (k < nrow):\n",
    "                            if (m > -1) and (m < ncol):\n",
    "                                temp.append(data[k,m,ch])  \n",
    "                temp.remove(data[i,j,ch])\n",
    "\n",
    "                max_value = max(temp)\n",
    "                min_value = min(temp)\n",
    "\n",
    "                if data[i,j,ch] > max_value:\n",
    "                    new_image[i,j,ch] = max_value\n",
    "\n",
    "                elif data[i,j,ch] < min_value:\n",
    "                    new_image[i,j,ch] = min_value\n",
    "                temp =[]\n",
    "    return new_image.copy()\n",
    "\n",
    "\n",
    "all_filters = [\n",
    "    (\"Original\", lambda x:x),\n",
    "    (\"OpenCV\", lambda im: cv2.fastNlMeansDenoisingColored(im,None,10,10,7,21)),\n",
    "    (\"UnsharpMask\", unsharp),\n",
    "    (\"OpenCV_UnsharpMask\", lambda im: unsharp(cv2.fastNlMeansDenoisingColored(im,None,10,10,7,21))),\n",
    "    (\"bilateralFilter\", lambda im: cv2.bilateralFilter(im,9,75,75)),\n",
    "    (\"UnsharpMask_bilateralFilter\", lambda im: cv2.bilateralFilter(np.array(unsharp(im)),9,75,75)),\n",
    "    (\"bilateralFilter_UnsharpMask\", lambda im: unsharp(cv2.bilateralFilter(im,9,75,75)))\n",
    "\n",
    "]\n",
    "\n",
    "# iterr = iter(tmp_images_gen())\n",
    "# for i in range(8):\n",
    "#     next(iterr)\n",
    "# img = next(iterr).numpy()\n",
    "# # img2 = conservative_smoothing_gray(img,15)\n",
    "# plt.figure()\n",
    "# plt.imshow(img)\n",
    "# plt.figure()\n",
    "# plt.imshow(img2)\n",
    "# np.mean(np.abs(img-img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_iter = iter(tmp_images_gen())\n",
    "im_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_image = Image.open('./ds_images/482-Bachillerato-Internacional.jpg')\n",
    "large_image = large_image.resize((720,480), resample=Image.Resampling.BICUBIC)\n",
    "# large_image = large_image.crop((80, 150, 200, 280))\n",
    "# Image.fromarray(np.array(large_image))\n",
    "large_image = np.array(large_image)\n",
    "\n",
    "def add_vertical_lines_noise(x, shifts=2, line_height=2):\n",
    "    x = x.copy()\n",
    "    axis_for_roll = 1\n",
    "    y = np.roll(x, -shifts, axis=axis_for_roll)\n",
    "    j = 0\n",
    "    for i in range(x.shape[axis_for_roll]):\n",
    "        if j <= line_height:\n",
    "            x[:,i,:] = y[:,i,:]\n",
    "            \n",
    "        j+=1\n",
    "        if j == line_height * 2:\n",
    "            j = 0\n",
    "#     print(x.shape)\n",
    "    return x\n",
    "\n",
    "def add_horizontal_lines_noise(x, shifts=2, line_height=2):\n",
    "    x = x.copy()\n",
    "    axis_for_roll = 0\n",
    "    y = np.roll(x, -shifts, axis=1)\n",
    "    j = 0\n",
    "    for i in range(x.shape[axis_for_roll]):\n",
    "        if j <= line_height:\n",
    "            x[i,:,:] = y[i,:,:]\n",
    "            \n",
    "        \n",
    "        if j == line_height * 2:\n",
    "            j = 0\n",
    "        else:\n",
    "            j+=1\n",
    "#     print(x.shape)\n",
    "    return x\n",
    "\n",
    "x = add_horizontal_lines_noise(large_image, -7, 1)\n",
    "plt.figure()\n",
    "plt.imshow(x)\n",
    "\n",
    "# im_iter = iter(tmp_images_gen())\n",
    "\n",
    "# for _ in range(207):\n",
    "#     next(im_iter)\n",
    "    \n",
    "# x = next(im_iter).numpy()\n",
    "# y = add_horizontal_lines_noise(x, -7, 2)\n",
    "# # y = add_vertical_lines_noise(x, 10, 2)\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(x)\n",
    "# plt.axis('off')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(y)\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_iter = iter(tmp_images_gen())\n",
    "im_iter\n",
    "\n",
    "def create_dir(path):\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "       # Create a new directory because it does not exist\n",
    "       os.makedirs(path)\n",
    "\n",
    "def choose_interactive(im_iter, all_filters):\n",
    "\n",
    "    def render_options(im):\n",
    "        im = np.array(im)\n",
    "        plt.figure(figsize=(13,20))\n",
    "        rows = 4\n",
    "        cols = 2\n",
    "        i = 1\n",
    "\n",
    "        for f_title, f in all_filters:\n",
    "            plt.subplot(rows,cols,i)\n",
    "            plt.title(f\"{i} {f_title}\")\n",
    "            plt.imshow(f(im))\n",
    "            plt.axis('off')\n",
    "            i +=1\n",
    "\n",
    "        plt.subplots_adjust(wspace = 0.1, hspace = 0.2)\n",
    "\n",
    "    count = 338\n",
    "    for c in range(count):\n",
    "        next(im_iter)\n",
    "\n",
    "    im = True\n",
    "    while im is not None:\n",
    "        im = next(im_iter)\n",
    "    #     plt.figure()\n",
    "    #     plt.imshow(im)\n",
    "\n",
    "\n",
    "        render_options(im)\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "        x = input()\n",
    "        count += 1\n",
    "        display.clear_output()\n",
    "        print(f\"Use {x}, count={count}\")\n",
    "        \n",
    "        path2 = f\"./tmp2/Original/\"\n",
    "        create_dir(path2)\n",
    "        Image.fromarray(im.numpy()).save(f\"{path2}/{count}.jpeg\")\n",
    "        \n",
    "        for inn in x.split(\",\"):\n",
    "            if int(inn) == 0:\n",
    "                continue\n",
    "            fname, f = all_filters[int(inn)-1]\n",
    "            result = Image.fromarray(np.array(f(np.array(im))))\n",
    "            path1 = f\"./tmp2/Upgraded/\"\n",
    "            \n",
    "            create_dir(path1)\n",
    "            \n",
    "            result.save(f\"{path1}/{count}_{fname}.jpeg\")\n",
    "\n",
    "# choose_interactive(im_iter, all_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename, ftype):\n",
    "    raw_image = tf.io.read_file(str(filename), name=filename)\n",
    "    if ftype == \"png\":\n",
    "        return tf.image.decode_png(raw_image, channels=3, name=filename)\n",
    "    elif ftype == \"jpg\" or ftype == \"jpeg\":\n",
    "        return tf.image.decode_jpeg(raw_image, channels=3, name=filename)\n",
    "    \n",
    "original_images = [(re.search('tmp2/Original/([0-9]*)\\.jpeg', str(p)).group(1), str(p)) for p in pathlib.Path(\"./tmp2/Original\").glob('*.jpeg')]\n",
    "upgraded_images = [(re.search('tmp2/Upgraded/([0-9]*)_?([a-zA-Z0-9_]+)\\.jpeg', str(p)), str(p)) for p in pathlib.Path(\"./tmp2/Upgraded\").glob('*.jpeg')]\n",
    "\n",
    "original_images = {a:b for a,b in original_images}\n",
    "upgraded_images = [(a.group(1), a.group(2), b) for a,b in upgraded_images]\n",
    "\n",
    "mmap = {}\n",
    "for indx, op_name, img_path in upgraded_images:\n",
    "    if indx not in mmap:\n",
    "        mmap[indx] = [(op_name, img_path)]\n",
    "    else:\n",
    "        mmap[indx].append((op_name, img_path))\n",
    "\n",
    "filter_map = {a:b for a,b in all_filters}\n",
    "\n",
    "# upgraded_ds = [(original_images[indx], filter_map[op_name], img_path) for indx, op_name, img_path in upgraded_images]\n",
    "\n",
    "\n",
    "tmap = {a:i for i, (a,b) in enumerate(all_filters)}\n",
    "\n",
    "\n",
    "def augment(x):\n",
    "#     seed = (random.randint(0, 100),random.randint(0, 100))\n",
    "#     x = random_bright(x, training=True)\n",
    "    x = tf.image.random_brightness(x, 0.2)\n",
    "#     x = random_contrast(x, training=True)\n",
    "    x = tf.image.random_contrast(x, 0.2, 0.5)\n",
    "#     x = random_flip(x, training=True)\n",
    "#     x = random_rotation(x, training=True)\n",
    "    x = tf.image.flip_left_right(x)\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "#     x = tf.image.random_hue(x, 0.2)\n",
    "    return x\n",
    "\n",
    "def get_chosen_images(train=True):\n",
    "    original_path = pathlib.Path(\"./tmp2/Original\")\n",
    "    upgraded_path = pathlib.Path(\"./tmp2/Upgraded\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    train, test = train_test_split(list(mmap.items()), test_size=0.01, random_state=42)\n",
    "    print(len(train), len(test))\n",
    "    if train:\n",
    "        files = train\n",
    "    else:\n",
    "        files = test\n",
    "    def fn():\n",
    "        # for indx, filters in mmap.items():\n",
    "        for indx, filters in files:\n",
    "            original_filename = original_images[indx]\n",
    "            original = load_image(original_filename, \"jpeg\")\n",
    "            \n",
    "            original = augment(original)\n",
    "            \n",
    "            chosen = original\n",
    "            for tname, tfn in all_filters:\n",
    "            \n",
    "                chosen = tf.concat([chosen, np.asarray(tfn(original.numpy()))], axis=-1)\n",
    "            \n",
    "            label = [0.]*7\n",
    "#             print(\"CALL\")\n",
    "#             print(filters)\n",
    "            for tname, upgraded_filename in filters:\n",
    "#                 print(tname)\n",
    "#                 print(tmap[tname]-1)\n",
    "#                 indx, *transf = str(upgraded_filename).split(\"_\")\n",
    "#                 tname = \"_\".join(transf).replace(\".jpeg\",\"\")\n",
    "                label[tmap[tname]-1] = 1\n",
    "#                 print(label)\n",
    "            \n",
    "#             label = tf.cast(label, tf.float16)\n",
    "#             print(label, tf.math.reduce_sum(label))\n",
    "            label = label /tf.math.reduce_sum(label)\n",
    "            yield chosen, label\n",
    "    return fn\n",
    "# iter = get_chosen_images(train=False)()\n",
    "# next(iter)\n",
    "# # next(iter)\n",
    "# img, label = next(iter)\n",
    "# print(img.shape, label.shape)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(img[:,:,:3])\n",
    "# plt.figure()\n",
    "# plt.imshow(img[:,:,3:])\n",
    "\n",
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyConvLayer(tf.keras.layers.Layer):\n",
    "#   def __init__(self, filters, downscale):\n",
    "#     super(MyConvLayer, self).__init__()\n",
    "#     self.filters = filters\n",
    "#     self.downscale = downscale\n",
    "\n",
    "#   def build(self, input_shape):\n",
    "#     reg = tf.keras.regularizers.l1_l2(0.1,0.1)\n",
    "#     act = layers.LeakyReLU(alpha=0.2)\n",
    "#     filters = self.filters\n",
    "#     args = {\"padding\":'same', \"activation\":act, \"activity_regularizer\":reg, \"kernel_initializer\":tf.keras.initializers.HeNormal(seed=32)}\n",
    "#     self.conv1 = layers.Conv2D(filters, kernel_size=7, strides=1, **args)\n",
    "#     self.mp1 = layers.MaxPool2D(self.downscale,self.downscale)\n",
    "#     self.conv2 = layers.Conv2D(filters, kernel_size=5, strides=1, **args)\n",
    "#     self.mp2 = layers.MaxPool2D(self.downscale,self.downscale)\n",
    "#     self.conv3 = layers.Conv2D(filters, kernel_size=3, strides=1, **args)\n",
    "#     self.mp3 = layers.MaxPool2D(self.downscale,self.downscale)\n",
    "#     self.conv4 = layers.Conv2D(filters, kernel_size=1, strides=1, **args)\n",
    "\n",
    "#   def call(self, inputs):\n",
    "#     x = self.conv1(inputs)\n",
    "#     x = self.mp1(x)\n",
    "#     y = self.conv2(inputs)\n",
    "#     y = self.mp2(y)\n",
    "#     z = self.conv3(inputs)\n",
    "#     z = self.mp3(z)\n",
    "#     return self.conv4(tf.concat([x,y,z], axis=-1))\n",
    "\n",
    "# def get_categorizer():\n",
    "#     reg = tf.keras.regularizers.l1_l2(0.1,0.1)\n",
    "#     act = layers.LeakyReLU(alpha=0.2)\n",
    "#     #     args = {\"padding\":'same', \"activation\":act, \"activity_regularizer\":reg}\n",
    "#     args = {\"padding\":'same', \"activation\":act, \"activity_regularizer\":reg, \"kernel_initializer\":tf.keras.initializers.HeNormal(seed=32)}\n",
    "#     return tf.keras.Sequential(layers=[\n",
    "#         tf.keras.layers.Rescaling(1./255),\n",
    "# #         layers.BatchNormalization(),\n",
    "#         MyConvLayer(64, 2),\n",
    "#         layers.MaxPool2D(2,2),\n",
    "# #         layers.BatchNormalization(),\n",
    "#         layers.SpatialDropout2D(0.3),\n",
    "        \n",
    "#         layers.Conv2D(128, kernel_size=3, strides=1, **args),\n",
    "#         layers.MaxPool2D(2,2),\n",
    "# #         layers.BatchNormalization(),\n",
    "#         layers.SpatialDropout2D(0.3),\n",
    "        \n",
    "#         layers.Conv2D(256, kernel_size=3, strides=1, **args),\n",
    "#         layers.MaxPool2D(2,2),\n",
    "# #         layers.BatchNormalization(),\n",
    "\n",
    "        \n",
    "# # #         layers.SpatialDropout2D(0.3),\n",
    "# #         layers.Conv2D(256, kernel_size=3, strides=1, **args),\n",
    "# #         layers.MaxPool2D(2,2),\n",
    "# #         layers.Conv2D(512, kernel_size=3, strides=1, **args),\n",
    "# #         layers.MaxPool2D(2,2),\n",
    "# #         layers.BatchNormalization(),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(14, activation='relu', activity_regularizer=reg),\n",
    "# #         layers.BatchNormalization(),\n",
    "#         layers.Dense(7, activation='relu', activity_regularizer=reg)\n",
    "#     ], name=\"categorizer\")\n",
    "    \n",
    "# cdata_train = tf.data.Dataset.from_generator(get_chosen_images(train=True), output_signature=(\n",
    "#         tf.TensorSpec(shape=(480, 720, 24)),\n",
    "#         tf.TensorSpec(shape=(7)))).batch(1).prefetch(tf.data.AUTOTUNE)\n",
    "# cdata_test = tf.data.Dataset.from_generator(get_chosen_images(train=False), output_signature=(\n",
    "#         tf.TensorSpec(shape=(480, 720, 24)),\n",
    "#         tf.TensorSpec(shape=(7)))).batch(1).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# initial_learning_rate = 1e-03\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate,\n",
    "#     decay_steps=100,\n",
    "#     decay_rate=0.9,\n",
    "#     staircase=True)\n",
    "\n",
    "\n",
    "# cmodel = get_categorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True,\n",
    "#                                                               patience=10, min_delta=0.)  \n",
    "\n",
    "# ce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# def loss_fn(true_y, pred_y):\n",
    "# #     print(f\"true_y={true_y}, pred_y={pred_y}\")\n",
    "#     return ce(true_y, pred_y)\n",
    "\n",
    "# cmodel.compile(\n",
    "#                 optimizer=tfa.optimizers.AdamW(weight_decay=0.00001, learning_rate=lr_schedule),\n",
    "# #                 optimizer=\"adam\",\n",
    "#               loss=loss_fn,\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # class PrintResults(keras.callbacks.Callback):\n",
    "# #     def on_epoch_end(self, epoch, logs):\n",
    "# #         images_path = f\"./col_100_output_images/\"\n",
    "# #         image_name = images_path + f\"e_{epoch}.jpg\"\n",
    "# # #         display.clear_output()\n",
    "# #         print_validation(lambda x:cmodel(x, training=False), batch_size=5, save=False, path=\"./\")\n",
    "\n",
    "# cmodel.fit(cdata_train, validation_data=cdata_test, epochs=100, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdata_test = tf.data.Dataset.from_generator(get_chosen_images(train=False), output_signature=(\n",
    "#         tf.TensorSpec(shape=(480, 720, 24)),\n",
    "#         tf.TensorSpec(shape=(7)))).batch(1).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# # ti = next(iter(cdata_test))\n",
    "# # cmodel.predict()\n",
    "# ress = []\n",
    "# i = 0\n",
    "# for ti in cdata_test:\n",
    "#     img, y_true = ti\n",
    "#     img = tf.squeeze(img, axis=0)\n",
    "#     img = tf.cast(img, tf.uint8)\n",
    "# #     plt.ion()\n",
    "# #     plt.subplot(3,1,1)\n",
    "# #     plt.imshow(img[:,:,:3])\n",
    "# #     plt.subplot(3,1,2)\n",
    "# #     plt.imshow(img[:,:,3:6])\n",
    "# #     plt.subplot(3,1,3)\n",
    "# #     plt.imshow(img[:,:,6:9])\n",
    "# #     plt.draw()\n",
    "# #     plt.pause(0.001)\n",
    "#     print(y_true, cmodel.predict(ti))\n",
    "#     i+=1\n",
    "#     if i == 3:\n",
    "#         break\n",
    "        \n",
    "# # for (img, y_true), y_pred in ress:\n",
    "# #     print(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def image_generator(pictures = [], large_pictures = [], ds_pictures = [], return_ext=False):\n",
    "    random.shuffle(pictures)\n",
    "    def parse_name(filename):\n",
    "        return \"{}_\" + re.sub(r\"\\.(png|jpeg|jpg)\", r\"_{}.\\1\", os.path.basename(filename))\n",
    "    \n",
    "    def format_name(name, subname):\n",
    "        return name.format(random.randint(0, 1000), subname)   \n",
    "    \n",
    "    def yield_resized(img, fname):\n",
    "        input_w = 720\n",
    "        input_h = 480\n",
    "        cropped = tf.image.resize_with_crop_or_pad(\n",
    "          img, input_h ,input_w\n",
    "        )\n",
    "        variance = tf.math.reduce_variance(tf.cast(cropped, tf.float32))\n",
    "\n",
    "        if variance > 1000:        \n",
    "            yield cropped, format_name(fname, \"original\")\n",
    "            yield tf.image.flip_left_right(cropped), format_name(fname, \"center_crop\")\n",
    "    \n",
    "    def yield_cropped(img, fname):\n",
    "        input_w = 720\n",
    "        input_h = 480\n",
    "        \n",
    "        for i in range(200):\n",
    "            cropped = tf.image.random_crop(\n",
    "              img, size=[input_h, input_w, 3]\n",
    "            )\n",
    "\n",
    "            variance = tf.math.reduce_variance(tf.cast(cropped, tf.float32))\n",
    "            if variance > 1000:\n",
    "                yield cropped, format_name(fname, \"random_crop\")\n",
    "                yield tf.image.flip_left_right(cropped), format_name(fname, \"center_crop\")            \n",
    "    \n",
    "    def fn():\n",
    "        input_w = 720\n",
    "        input_h = 480\n",
    "        for filename in pictures:\n",
    "            fname = parse_name(filename)\n",
    "            raw_png = tf.io.read_file(str(filename), name=filename)\n",
    "            decoded_png_2 = tf.image.decode_png(raw_png, channels=3, name=filename)\n",
    "            decoded_png_2 = tf.image.resize(decoded_png_2, [input_h, input_w],\n",
    "                              method=tf.image.ResizeMethod.BILINEAR)\n",
    "\n",
    "            yield decoded_png_2, format_name(fname, \"original\")\n",
    "            yield tf.image.flip_left_right(decoded_png_2), format_name(fname, \"flipped\")\n",
    "\n",
    "        for filename in ds_pictures:\n",
    "            fname =  parse_name(filename)\n",
    "            raw_png = tf.io.read_file(str(filename), name=filename)\n",
    "            decoded_png = tf.image.decode_jpeg(raw_png, channels=3, name=filename)\n",
    "            \n",
    "            \n",
    "            for y in yield_resized(decoded_png, fname):\n",
    "                yield y\n",
    "\n",
    "            for y in yield_cropped(decoded_png, fname):\n",
    "                yield y\n",
    "\n",
    "#         for filename in large_pictures:\n",
    "#             fname =  parse_name(filename)\n",
    "#             raw_png = tf.io.read_file(str(filename), name=filename)\n",
    "#             decoded_png = tf.image.decode_jpeg(raw_png, channels=3, name=filename)\n",
    "            \n",
    "#             for y in yield_resized(decoded_png, fname):\n",
    "#                 yield y\n",
    "\n",
    "#             for y in yield_cropped(decoded_png, fname):\n",
    "#                 yield y\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from multiprocessing import Lock, Process, Queue, current_process, Value, Pool, cpu_count\n",
    "from concurrent import futures\n",
    "\n",
    "def cache_images():\n",
    "    data_dir = pathlib.Path(\"./prepa\")\n",
    "    pictures = list(data_dir.glob('*.png'))\n",
    "\n",
    "    # TODO: Remove filter\n",
    "    pictures = random.sample(pictures, 1000)\n",
    "\n",
    "\n",
    "    data_dir = pathlib.Path(\"./people\")\n",
    "    large_pictures = list(data_dir.glob('*.jpg'))\n",
    "\n",
    "\n",
    "    data_dir = pathlib.Path(\"./ds_images\")\n",
    "    ds_pictures = list(data_dir.glob('*.jpg'))\n",
    "    \n",
    "    approx_size = len(pictures)*2 + len(ds_pictures)*2 + len(ds_pictures)*200*2 + len(large_pictures) + len(large_pictures)*20\n",
    "    \n",
    "    gen = image_generator(pictures, large_pictures, ds_pictures)\n",
    "    \n",
    "    \n",
    "    print(\"starting\")\n",
    "    counter = Value('i', 0)\n",
    "    \n",
    "        \n",
    "    it = iter(gen())\n",
    "    con = True\n",
    "    \n",
    "    np = cpu_count()\n",
    "    print(f'You have {np} cores')\n",
    "\n",
    "\n",
    "\n",
    "    def f1(im, filename):\n",
    "            im.numpy()\n",
    "            \n",
    "            tf.keras.utils.save_img('./tmp/{}'.format(filename), im)\n",
    "            with counter.get_lock():\n",
    "                counter.value += 1\n",
    "\n",
    "            if (counter.value % 10 == 0):\n",
    "                clear_output(wait=True)\n",
    "                print(f\"{counter.value+1}/{approx_size}\")   \n",
    "            return f\"{im.shape} {filename}\"\n",
    "    with futures.ThreadPoolExecutor(max_workers=min(int((np/3) * 2), 16)) as executor:    \n",
    "        for im, filename  in it:\n",
    "            # print(im.shape)\n",
    "            assert (im.shape[0] == 480 and im.shape[1] == 720)\n",
    "#             im, filename = next(it)\n",
    "            future = executor.submit(f1, im, filename)\n",
    "#             future.add_done_callback(lambda x: print(f\"donee: {x}\"))\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('generated an exception: %s' % exc)\n",
    "        else:\n",
    "            print('%r page is' % data)\n",
    "    \n",
    "\n",
    "# cache_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_iter = iter(tmp_images_gen())\n",
    "# im_iter\n",
    "# count = 1180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(count):\n",
    "#     next(im_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# images, transf = next(iter)\n",
    "\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(images[:,:,0:3])\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(images[:,:,3:])\n",
    "# print(transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the cached images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def image_generator_cached(size=None):\n",
    "    data_dir = pathlib.Path(\"./tmp\")\n",
    "    # prepa_dir = pathlib.Path(\"./prepa\")\n",
    "    prepa_files = list(data_dir.glob('*.png'))\n",
    "    random.shuffle(prepa_files)\n",
    "    all_files = []\n",
    "    for filename in prepa_files:\n",
    "        all_files.append((filename, 'png'))\n",
    "    for filename in list(data_dir.glob('*.jpg')):\n",
    "        all_files.append((filename, 'jpg'))\n",
    "        \n",
    "        \n",
    "    train, test = train_test_split(all_files, test_size=0.1, random_state=42)\n",
    "    print(f\"Train: {len(train)} Test:{len(test)}\")\n",
    "    \n",
    "    random.shuffle(all_files)\n",
    "    if size:\n",
    "        all_files = all_files[:size]\n",
    "    \n",
    "    def fn():\n",
    "        for filename, img_type in train:\n",
    "            raw_image = tf.io.read_file(str(filename), name=filename)\n",
    "            if img_type == \"png\":\n",
    "                yield tf.image.decode_png(raw_image, channels=3, name=filename)\n",
    "            elif img_type == \"jpg\":\n",
    "                yield tf.image.decode_jpeg(raw_image, channels=3, name=filename)\n",
    "                \n",
    "    def fn_test():\n",
    "        for filename, img_type in test:\n",
    "            raw_image = tf.io.read_file(str(filename), name=filename)\n",
    "            if img_type == \"png\":\n",
    "                yield tf.image.decode_png(raw_image, channels=3, name=filename)\n",
    "            elif img_type == \"jpg\":\n",
    "                yield tf.image.decode_jpeg(raw_image, channels=3, name=filename)\n",
    "            \n",
    "    return fn, fn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, test_gen = image_generator_cached()\n",
    "\n",
    "train_len = 3113\n",
    "test_len = 346\n",
    "\n",
    "# for i, filename in train_gen():\n",
    "#     i = tf.cast(i, tf.float32)\n",
    "#     variance = tf.math.reduce_variance(i)\n",
    "#     if variance < 1000:\n",
    "#         print(filename, tf.math.reduce_variance(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from functools import reduce\n",
    "splits = tfds.even_splits('train', n=200, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_H = 480\n",
    "IMG_W = 720\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_len = 7164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 3\n",
    "EPOCHS=100\n",
    "steps_per_epoch=int(train_len/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import NoiseUtil, ImgUtils, DataLoader, DataManager\n",
    "\n",
    "           \n",
    "def add_noise(x,y):\n",
    "    downsize_image_ratio = random.choice([1/5])\n",
    "    sh = tf.cast(tf.shape(x), tf.float32)\n",
    "    \n",
    "    print(x)\n",
    "    \n",
    "    resized_size_h = sh[0]\n",
    "    resized_size_w = sh[1]\n",
    "    down = tf.image.resize(\n",
    "        x,\n",
    "        [int(resized_size_h * downsize_image_ratio), int(resized_size_w * downsize_image_ratio)],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "    \n",
    "    \n",
    "\n",
    "    x= tf.image.resize(\n",
    "        down,\n",
    "        [resized_size_h, resized_size_w],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "        \n",
    "    return tf.reshape(x, (resized_size_h, resized_size_w, 3)), y\n",
    "    \n",
    "    \n",
    "#     print(x.shape)\n",
    "\n",
    "    \n",
    "#     n = NoiseUtil.pixel_noise(x, random.choice([50,60]), 15, downsize_image_ratios=[1/4, 1/6])\n",
    "\n",
    "#     n = x + 0.2 * tf.random.normal(\n",
    "#         x.shape[1:],\n",
    "#         mean=0.0,\n",
    "#         stddev=1.0,\n",
    "#         dtype=tf.dtypes.float32,\n",
    "#     )\n",
    "\n",
    "#     return n,y\n",
    "\n",
    "random_bright = tf.keras.layers.RandomBrightness(factor=0.2)\n",
    "random_contrast = tf.keras.layers.RandomContrast(factor=0.2)\n",
    "random_flip = tf.keras.layers.RandomFlip()\n",
    "\n",
    "\n",
    "def augment(x):\n",
    "#     seed = (random.randint(0, 100),random.randint(0, 100))\n",
    "    x = random_bright(x, training=True)\n",
    "    x = random_contrast(x, training=True)\n",
    "    x = random_flip(x, training=True)\n",
    "    return x\n",
    "\n",
    "def get_train_data():\n",
    "    return tf.data.Dataset.from_generator(train_gen, output_signature=tf.TensorSpec(shape=(480, 720, 3)))\n",
    "    \n",
    "def get_test_data():\n",
    "    return tf.data.Dataset.from_generator(test_gen, output_signature=tf.TensorSpec(shape=(480, 720, 3)))\n",
    "\n",
    "\n",
    "def get_dist_ds(ds, ds_len):\n",
    "    c = ds.map(normm).map(expp).map(augment)\n",
    "    a = c.map(lambda y: (y,1))\n",
    "    b = c.map(lambda y: (y,0)).map(add_noise)\n",
    "    return a.concatenate(b).batch(BATCH_SIZE)\n",
    "\n",
    "def get_gen_ds(ds):\n",
    "    return ds.map(augment).map(lambda x: (x,x)).map(add_noise).batch(BATCH_SIZE)\n",
    "\n",
    "# train_ds = get_gen_ds(get_train_data())\n",
    "# test_ds = get_gen_ds(get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_validation(model=lambda x:x, batch_size=5, save=False, path=\"./\", max_size=20, datasets=([], [])):\n",
    "        rows = batch_size\n",
    "        cols = 3\n",
    "        train_ds, test_ds = datasets\n",
    "        def print_ds(dataset, save=False):\n",
    "            results = [(model(x),x, y) for x,y in dataset]\n",
    "            plt.ion()\n",
    "            plt.show()\n",
    "            print(rows, cols)\n",
    "            plt.figure(figsize=((max_size+15) / cols, max_size / rows))\n",
    "            for x,x_prev, y in results:\n",
    "#                 x = (x * 127.5) + 127.5\n",
    "#                 y = (y * 127.5) + 127.5\n",
    "#                 x_prev = (x_prev * 127.5) + 127.5\n",
    "#                 x = x * 255.\n",
    "#                 y = y * 255.\n",
    "#                 x_prev = x_prev * 255.\n",
    "                def info(label, img):\n",
    "                    print(f\"{label} Min:{tf.math.reduce_min(img, axis=[0,1,2])} Max:{tf.math.reduce_max(img, axis=[0,1,2])} Mean:{tf.math.reduce_mean(img, axis=[0,1,2])}, Variance:{tf.math.reduce_variance(img, axis=[0,1,2])}\")\n",
    "    \n",
    "                info(\"x: \", x_prev)\n",
    "                info(\"y_pred: \", x)\n",
    "                info(\"y_true: \", y)\n",
    "\n",
    "                x = tf.cast(x, tf.uint8)\n",
    "                x_prev = tf.cast(x_prev, tf.uint8)\n",
    "                y = tf.cast(y, tf.uint8)\n",
    "#                 x = tf.clip_by_value(x, 0.0, 1.0)\n",
    "#                 y = tf.clip_by_value(y, 0.0, 1.0)\n",
    "                assert x.shape == y.shape\n",
    "    \n",
    "                for i in range(x.shape[0]):\n",
    "                    im = x[i,:,:,:]\n",
    "                    plt.subplot(cols, rows, i+1)\n",
    "                    plt.imshow(im)\n",
    "                    plt.title(\"Denoised\")\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                for i in range(x_prev.shape[0]):\n",
    "                    im = x_prev[i,:,:,:]\n",
    "                    plt.subplot(cols, rows, i+x_prev.shape[0]+1)\n",
    "                    plt.imshow(im)\n",
    "                    plt.title(\"With noise\")\n",
    "                    plt.axis('off')\n",
    "\n",
    "\n",
    "                for i in range(y.shape[0]):\n",
    "                    im = y[i,:,:,:]\n",
    "                    plt.subplot(cols, rows, i+x.shape[0]+x_prev.shape[0]+1)\n",
    "                    plt.imshow(im)\n",
    "                    plt.title(\"Original\")\n",
    "                    plt.axis('off')\n",
    "            plt.subplots_adjust(wspace = 0.1, hspace = 0.5)\n",
    "            if save:\n",
    "                plt.savefig(path)\n",
    "        \n",
    "            plt.draw()\n",
    "            plt.pause(0.001)\n",
    "            \n",
    "        print_ds(test_ds.map(lambda x,y: (x[0], y[0])).take(batch_size).batch(batch_size), save=save)\n",
    "        print_ds(train_ds.map(lambda x,y: (x[0], y[0])).take(batch_size).batch(batch_size), save=False)\n",
    "        \n",
    "# print_validation(model=lambda x:x, batch_size=2, save=False, path=\"./\", datasets=(train_ds, test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds, next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = get_gen_ds(get_train_data())\n",
    "# test_ds = get_gen_ds(get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y = next(iter(train_ds))\n",
    "# keras.losses.MeanSquaredError()(x,y)\n",
    "# x = (x * 127.5) + 127.5\n",
    "# y = (y * 127.5) + 127.5\n",
    "# x = tf.cast(x, tf.uint8)\n",
    "# y = tf.cast(y, tf.uint8)\n",
    "# plt.imshow(x[0])\n",
    "# plt.figure()\n",
    "# plt.imshow(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def build_perceptual_loss(input_shape=(480, 720, 3)):\n",
    "    print(input_shape)\n",
    "    vgg = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    vgg.trainable = False ## Not trainable weights\n",
    "\n",
    "\n",
    "    selected_layers = ['block1_conv1', 'block2_conv2',\"block3_conv3\" ,'block4_conv3','block5_conv3']\n",
    "    selected_layer_weights = [1.0, 4.0 , 4.0 , 8.0 , 16.0]\n",
    "\n",
    "\n",
    "    outputs = [vgg.get_layer(l).output for l in selected_layers]\n",
    "    prediction_model = Model(vgg.input, outputs)\n",
    "\n",
    "    def perceptual_loss(input_image , reconstruct_image):\n",
    "        input_image = tf.keras.applications.vgg16.preprocess_input(input_image)\n",
    "        reconstruct_image = tf.keras.applications.vgg16.preprocess_input(reconstruct_image)\n",
    "\n",
    "        h1_list = prediction_model(input_image)\n",
    "        h2_list = prediction_model(reconstruct_image)\n",
    "\n",
    "        rc_loss = 0.0\n",
    "\n",
    "        for h1, h2, weight in zip(h1_list, h2_list, selected_layer_weights):\n",
    "            h1 = K.batch_flatten(h1)\n",
    "            h2 = K.batch_flatten(h2)\n",
    "            rc_loss = rc_loss + weight * K.sum(K.square(h1 - h2), axis=-1)\n",
    "\n",
    "        return rc_loss\n",
    "    \n",
    "    return perceptual_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len\n",
    "\n",
    "small_epochs = 30\n",
    "\n",
    "\n",
    "small_steps_per_epoch = int((train_len/small_epochs)/BATCH_SIZE)\n",
    "small_steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder():\n",
    "    inputs = keras.Input(shape=(480, 720, 3))\n",
    "    reg = tf.keras.regularizers.l1_l2(0.1,0.1)\n",
    "    act = layers.LeakyReLU(alpha=0.2)\n",
    "#     args = {\"padding\":'same', \"activation\":act, \"activity_regularizer\":reg}\n",
    "    args = {\"padding\":'same', \"activation\":act, \"kernel_initializer\":tf.keras.initializers.HeNormal(seed=32)}\n",
    "    \n",
    "    x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "    x = layers.Conv2D(128, kernel_size=5, strides=1, dilation_rate=2, **args)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(2,2)(x)\n",
    "    x = layers.SpatialDropout2D(0.3)(x)\n",
    "    x = layers.Conv2D(128, kernel_size=3, strides=1, dilation_rate=2, **args)(x)\n",
    "    x = layers.MaxPool2D(2,2)(x)\n",
    "    x = layers.SpatialDropout2D(0.3)(x)\n",
    "    x = layers.Conv2D(128, kernel_size=3, strides=1, **args)(x)\n",
    "    x = layers.MaxPool2D(2,2)(x)\n",
    "    x = layers.Conv2D(256, kernel_size=5, strides=2, **args)(x)\n",
    "    x = layers.Conv2D(512, kernel_size=(2,3), strides=(2,3), **args)(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(512, kernel_size=(3,3), strides=(2,3), **args)(x)\n",
    "    x = layers.Conv2DTranspose(256, kernel_size=4, strides=2, **args)(x)\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=2, strides=2, **args)(x)\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=3, strides=1, **args)(x)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = layers.Conv2DTranspose(64, kernel_size=3, strides=1, **args)(x)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = layers.Conv2DTranspose(32, kernel_size=3, strides=1, **args)(x)\n",
    "    x = layers.Conv2DTranspose(3, kernel_size=3, strides=1, **args)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, x)\n",
    "    \n",
    "\n",
    "autoencoder = build_autoencoder()\n",
    "\n",
    "class RenderImages(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        images_path = f\"./col_100_output_images/\"\n",
    "        image_name = images_path + f\"e_{epoch}.jpg\"\n",
    "#         display.clear_output()\n",
    "        print_validation(lambda x:autoencoder(x, training=False), batch_size=5, save=False, path=\"./\")\n",
    "        \n",
    "class LRMetric(tf.keras.metrics.Mean):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        lr = autoencoder.optimizer.lr\n",
    "        current_lr = lr(autoencoder.optimizer.iterations)\n",
    "        super().update_state(current_lr)\n",
    "        \n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=False,\n",
    "#                                                               patience=10, min_delta=0.)  \n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove horizontal lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [(str(p),'jpeg') for p in pathlib.Path(\"./people\").glob('*.jpg')]\n",
    "ds_images = [(str(p),'jpeg') for p in pathlib.Path(\"./ds_images\").glob('*.jpg')]\n",
    "large_images = [*people, *ds_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(large_images)\n",
    "large_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelation_noise(x):\n",
    "    downsize_image_ratio = random.choice([1/2,1/5,1/10, 1/12])\n",
    "    sh = tf.cast(tf.shape(x), tf.float32)\n",
    "    \n",
    "    resized_size_h = sh[0]\n",
    "    resized_size_w = sh[1]\n",
    "    down = tf.image.resize(\n",
    "        x,\n",
    "        [int(resized_size_h * downsize_image_ratio), int(resized_size_w * downsize_image_ratio)],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "    x= tf.image.resize(\n",
    "        down,\n",
    "        [resized_size_h, resized_size_w],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "    return x\n",
    "\n",
    "def get_right_dims(shape):\n",
    "    print(shape)\n",
    "    h, w, c = shape\n",
    "    # 624, 936\n",
    "    while h > 624*1.5 and w > 936*1.5:\n",
    "        h *= 0.9\n",
    "        w *= 0.9\n",
    "    h *= 1.1\n",
    "    w *= 1.1\n",
    "    return (int(h),int(w))\n",
    "\n",
    "def random_brightness(x):\n",
    "#     x = tf.image.random_brightness(x, 0.2)\n",
    "    x = tf.image.random_contrast(x, 0.2, 0.5)\n",
    "    return x\n",
    "\n",
    "def manual_filter(slice_paths):\n",
    "    count = 1055\n",
    "    for idx, (filename, img_type) in enumerate(slice_paths):\n",
    "        input_w = 720\n",
    "        input_h = 480\n",
    "        raw_image = tf.io.read_file(filename, name=filename)\n",
    "        if img_type == \"png\":\n",
    "            img = tf.image.decode_png(raw_image, channels=3, name=filename)\n",
    "        elif img_type == \"jpg\" or img_type == \"jpeg\":\n",
    "            img = tf.image.decode_jpeg(raw_image, channels=3, name=filename)\n",
    "            \n",
    "        h,w = get_right_dims(img.shape)\n",
    "\n",
    "        img = tf.image.resize(\n",
    "            img,\n",
    "            [h, w],\n",
    "            preserve_aspect_ratio=True,\n",
    "            antialias=False,\n",
    "            name=None)\n",
    "        img = tf.cast(img, tf.uint8)\n",
    "\n",
    "        for i in range(100):\n",
    "            # * 1.3\n",
    "            cropped = tf.image.random_crop(\n",
    "              img, size=[624, 936, 3]\n",
    "            )\n",
    "            cropped_small = tf.image.resize(\n",
    "                cropped,\n",
    "                [480, 720],\n",
    "                preserve_aspect_ratio=True,\n",
    "                antialias=False,\n",
    "                name=None)\n",
    "            \n",
    "            ts = [lambda x: add_horizontal_lines_noise(x.numpy(), random.randint(-10, -8), random.randint(2, 5)),\n",
    "                 pixelation_noise,\n",
    "                  lambda x: add_horizontal_lines_noise(pixelation_noise(x).numpy(), random.randint(-10, -8), random.randint(2, 5))\n",
    "                 ]\n",
    "            \n",
    "            fn = random.choice(ts)\n",
    "            cropped_small = fn(cropped_small)\n",
    "            \n",
    "            cropped_small = tf.cast(cropped_small, tf.uint8)\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.title(f\"{cropped.shape}\")\n",
    "            plt.imshow(cropped)\n",
    "            plt.axis(\"Off\")\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.title(f\"{cropped_small.shape}\")\n",
    "            plt.imshow(cropped_small)\n",
    "            plt.axis(\"Off\")\n",
    "            plt.ion()\n",
    "            plt.show()\n",
    "            x = input()\n",
    "            \n",
    "            display.clear_output()\n",
    "            print(f\"Count={count}\")\n",
    "            if x == \"3\":\n",
    "                break\n",
    "            if x == \"1\":\n",
    "                count += 1\n",
    "                print(\"Saved!\")\n",
    "                path1 = \"./upscale_imgs/\"\n",
    "                create_dir(path1)\n",
    "                Image.fromarray(cropped.numpy()).save(f\"{path1}/{count}_large.jpeg\")\n",
    "                Image.fromarray(cropped_small.numpy()).save(f\"{path1}/{count}_small.jpeg\")\n",
    "\n",
    "# manual_filter(large_images)\n",
    "\n",
    "#                 for y1 in yield_resized_cropped(img, \"p{}_{}.jpeg\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscale_ds = [(re.search('upscale_imgs/([0-9]*)_?([a-zA-Z0-9_]+)\\.jpeg', str(p)), str(p), 'jpeg') for p in pathlib.Path(\"./upscale_imgs\").glob('*.jpeg')]\n",
    "upscale_ds = [(r.group(1), r.group(2), (fname, ftype)) for r, fname, ftype in upscale_ds]\n",
    "upscale_ds_map = {}\n",
    "for idx, itype, fdata in upscale_ds:\n",
    "    if idx not in upscale_ds_map:\n",
    "        upscale_ds_map[idx] = {}\n",
    "    upscale_ds_map[idx][itype] = fdata\n",
    "# upscale_ds.sort()\n",
    "upscale_ds = [(fdata[\"small\"], fdata[\"large\"]) for fdata in upscale_ds_map.values()]\n",
    "\n",
    "def gen_img(filename, img_type):\n",
    "    raw_image = tf.io.read_file(filename, name=filename)\n",
    "    if img_type == \"png\":\n",
    "        return tf.image.decode_png(raw_image, channels=3, name=filename)\n",
    "    elif img_type == \"jpg\" or img_type == \"jpeg\":\n",
    "        return tf.image.decode_jpeg(raw_image, channels=3, name=filename)\n",
    "\n",
    "def yield_small_and_large():\n",
    "    random.shuffle(upscale_ds)\n",
    "    train, test = train_test_split(upscale_ds, test_size=0.1, random_state=42)\n",
    "    print(f\"Train: {len(train)} Test:{len(test)}\")\n",
    "    \n",
    "    def train_gen():\n",
    "        for indx, (small, large) in enumerate(train):\n",
    "            small_img = gen_img(*small)\n",
    "            large_img = gen_img(*large)\n",
    "            large_img = tf.image.resize(large_img, (810, 1215))\n",
    "            yield tf.random.Generator.from_seed(int(idx)).normal(shape=[2]), small_img, large_img\n",
    "    \n",
    "    def test_gen():\n",
    "        for indx, (small, large) in enumerate(test):\n",
    "            small_img = gen_img(*small)\n",
    "            large_img = gen_img(*large)\n",
    "            large_img = tf.image.resize(large_img, (810, 1215))\n",
    "            yield tf.random.Generator.from_seed(int(idx)).normal(shape=[2]), small_img, large_img\n",
    "    return train_gen, test_gen\n",
    "        \n",
    "train_gen, test_gen = yield_small_and_large()\n",
    "\n",
    "def augment_img(x):\n",
    "#     x = tf.image.stateless_random_brightness(x, 0.2, seed)\n",
    "#     x = tf.image.random_contrast(x, 0.2, 0.5)\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    return x\n",
    "\n",
    "def augment(idx, x, y):\n",
    "    return augment_img(idx, x), augment_img(idx, y)\n",
    "\n",
    "def create_ds(gen_fn):\n",
    "    return tf.data.Dataset.from_generator(gen_fn, output_signature=(\n",
    "                tf.TensorSpec(shape=(2)),\n",
    "                tf.TensorSpec(shape=(480, 720, 3)),\n",
    "                tf.TensorSpec(shape=(810, 1215, 3))\n",
    "        )).map(augment)\n",
    "\n",
    "large_train, large_test = train_test_split(large_images, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "def create_ds_2(image_paths):\n",
    "    def gen_fn_inner():\n",
    "        for image_name, image_type in image_paths:\n",
    "            img = gen_img(image_name, image_type)\n",
    "            \n",
    "            if img.shape[0] < 720 or img.shape[1] < 1080:\n",
    "                continue\n",
    "            \n",
    "            cache = []\n",
    "            for _ in range(10):\n",
    "            \n",
    "                large_img = tf.image.random_crop(\n",
    "                  img, size=[720, 1080, 3]\n",
    "                )\n",
    "                \n",
    "                large_img = augment_img(large_img)\n",
    "            \n",
    "                small_img = tf.image.resize(large_img, (480, 720))\n",
    "\n",
    "                ts = [lambda x: add_horizontal_lines_noise(x.numpy(), random.randint(-10, -8), random.randint(2, 5)),\n",
    "                     pixelation_noise,\n",
    "                      lambda x: add_horizontal_lines_noise(pixelation_noise(x).numpy(), random.randint(-10, -8), random.randint(2, 5))\n",
    "                     ]\n",
    "\n",
    "                fn = random.choice(ts)\n",
    "                small_img = fn(small_img)\n",
    "                small_img = tf.cast(small_img, tf.uint8)\n",
    "\n",
    "                cache.append((small_img, large_img ))\n",
    "            \n",
    "            random.shuffle(cache)\n",
    "            for c in cache:\n",
    "                yield c\n",
    "    return tf.data.Dataset.from_generator(gen_fn_inner, output_signature=(\n",
    "                tf.TensorSpec(shape=(480, 720, 3)),\n",
    "                tf.TensorSpec(shape=(720, 1080, 3))\n",
    "        ))\n",
    "\n",
    "# i = iter(large_train_ds)\n",
    "# x,y = next(i)\n",
    "# x = tf.cast(x, tf.uint8)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (i1, i2) in enumerate(create_ds_2(large_train).batch(1)):\n",
    "#     print(i, i1.shape, i2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1023/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_train_ds = create_ds(train_gen).batch(2)\n",
    "# large_test_ds = create_ds(test_gen).batch(1)\n",
    "\n",
    "large_train_ds = create_ds_2(large_train).batch(2)\n",
    "large_test_ds = create_ds_2(large_test).batch(1)\n",
    "\n",
    "perceptual_loss = build_perceptual_loss(input_shape=(720, 1080, 3))\n",
    "\n",
    "#x = tfa.layers.GroupNormalization()(x)\n",
    "# = layers.SpatialDropout2D(0.3)(x)\n",
    "#x = layers.UpSampling2D((2,3))(x)\n",
    "\n",
    "class MyRescale(tf.keras.layers.Layer):\n",
    "  def __init__(self):\n",
    "    super(MyRescale, self).__init__()\n",
    "  def build(self, input_shape):\n",
    "     self.kernel = self.add_weight(\"kernel\", initializer=tf.keras.initializers.Constant(value=255))\n",
    "\n",
    "\n",
    "  def call(self, inputs):\n",
    "   return inputs * self.kernel\n",
    "\n",
    "class MyConcat(tf.keras.layers.Layer):\n",
    "  def __init__(self):\n",
    "    super(MyConcat, self).__init__()\n",
    "  def build(self, input_shape):\n",
    "     self.kernel = self.add_weight(\"kernel\", initializer=tf.keras.initializers.Constant(value=1))\n",
    "\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x, y = inputs\n",
    "    return tf.concat([x,y* self.kernel], axis=-1) \n",
    "\n",
    "class MyDeconv(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, name, resize_to=None, norm=True):\n",
    "        super(MyDeconv, self).__init__(name=name)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.resize_to = resize_to\n",
    "        self.strides = strides\n",
    "        self.norm = norm\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"resize_to\": self.resize_to,\n",
    "            \"strides\": self.strides,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        filters = self.filters\n",
    "        kernel_size = self.kernel_size\n",
    "        name = self.name\n",
    "        \n",
    "        strides = self.strides if isinstance(self.strides, tuple) else (self.strides,self.strides)\n",
    "                     \n",
    "        if self.resize_to is None:\n",
    "            h,w = input_shape[1], input_shape[2]\n",
    "            self.resize_to = (int(h*strides[0]),int(w*strides[1]))\n",
    "        \n",
    "        self.resize_layer = layers.Lambda(lambda x: tf.image.resize(x, self.resize_to, method=\"nearest\"), name=f\"resize_nearest_{name}\")\n",
    "        \n",
    "        def build_conv(filters, kernel_size, name):\n",
    "            conv = layers.Conv2D(filters, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=True,\n",
    "                              activation=\"relu\",\n",
    "    #                           kernel_initializer=tf.keras.initializers.HeNormal(seed=32),\n",
    "                              name=name)\n",
    "            if self.norm:\n",
    "                return tfa.layers.SpectralNormalization(conv, name=f\"{name}_spectral_norm\")\n",
    "            else:\n",
    "                return conv\n",
    "            \n",
    "        self.conv1 = build_conv(filters, kernel_size, name=f\"{name}_1\")\n",
    "        self.conv2 = build_conv(filters, kernel_size, name=f\"{name}_2\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.resize_layer(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "# def get_activation():\n",
    "    # return layers.LeakyReLU(alpha=0.2)\n",
    "act = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "def maxconv_name():\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        yield f\"max_conv_{i}\"\n",
    "        \n",
    "def deconv_name():\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        yield f\"deconv_{i}\"\n",
    "        \n",
    "max_conv_name = iter(maxconv_name())\n",
    "deconv_name_i = iter(deconv_name())\n",
    "\n",
    "def deconv(filters, kernel_size, strides, name, norm=False, activation=\"relu\", **args):\n",
    "    if norm:\n",
    "        return tfa.layers.SpectralNormalization(\n",
    "            layers.Conv2DTranspose(filters, kernel_size=kernel_size, strides=strides, padding=\"same\", use_bias=False,\n",
    "                          activation=activation, kernel_initializer=tf.keras.initializers.HeNormal(seed=32),\n",
    "                          name=name, **args), name=f\"{name}_spectral_norm\")\n",
    "    return layers.Conv2DTranspose(filters, kernel_size=kernel_size, strides=strides, padding=\"same\", use_bias=False, \n",
    "                      activation=activation, kernel_initializer=tf.keras.initializers.HeNormal(seed=32),\n",
    "                      name=name, **args)\n",
    "\n",
    "def conv(filters, kernel_size, strides, name, norm=False, use_init = True, use_bias=False, activation=\"relu\", **args):\n",
    "    if norm:\n",
    "        return tfa.layers.SpectralNormalization(\n",
    "            layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding=\"same\", use_bias=use_bias,\n",
    "                          activation=activation,\n",
    "                          kernel_initializer=tf.keras.initializers.HeNormal(seed=32) if use_init else None,\n",
    "                          name=name, **args), name=f\"{name}_spectral_norm\")\n",
    "    return layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding=\"same\", use_bias=use_bias,\n",
    "                      activation=activation,\n",
    "                      kernel_initializer=tf.keras.initializers.HeNormal(seed=32) if use_init else None,\n",
    "                      name=name, **args)\n",
    "\n",
    "def maxpoolconv(filters, pool_kernel_size, kernel_size=3, strides=1, norm=True):\n",
    "    name = next(max_conv_name)\n",
    "    def fn(x):\n",
    "        x = conv(filters, kernel_size=kernel_size, strides=1, name=name, norm=norm)(x)\n",
    "        return layers.MaxPool2D(pool_kernel_size, name=f\"{name}_maxpool\")(x)\n",
    "    return fn\n",
    "\n",
    "# def upscaleconv(filters, pool_kernel_size, kernel_size=3, strides=1, norm=True):\n",
    "#     name = next(deconv_name_i)\n",
    "#     def fn(x):\n",
    "#         x = layers.UpSampling2D(pool_kernel_size, name=f\"upsampling_{name}\")(x)\n",
    "#         x = deconv(filters, kernel_size=kernel_size, strides=strides, name=name, norm=norm)(x)\n",
    "#         return x\n",
    "#     return fn\n",
    "\n",
    "# def resizeconv(filters, new_size, kernel_size=3, strides=1, norm=True):\n",
    "#     name = next(deconv_name_i)\n",
    "#     def fn(x):\n",
    "#         x = layers.Lambda(lambda x: tf.image.resize(x, new_size, method=\"nearest\"), name=f\"resize_nearest_{name}\")(x)\n",
    "#         x = deconv(filters, kernel_size=kernel_size, strides=strides, name=name, norm=norm)(x)\n",
    "#         return x\n",
    "#     return fn\n",
    "\n",
    "def build_autoencoder_large():\n",
    "    inputs = keras.Input(shape=(480, 720, 3))\n",
    "    norm = False\n",
    "    \n",
    "    x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "    \n",
    "    ffs = []\n",
    "    \n",
    "    x = conv(16, 3, 1, name=\"first_conv3\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.8)(x))\n",
    "    x = maxpoolconv(32, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.8)(x))\n",
    "    x = maxpoolconv(64, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.8)(x))\n",
    "    x = maxpoolconv(128, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.8)(x))\n",
    "    x = maxpoolconv(256, 2, norm=norm)(x)\n",
    "    ffs.append(layers.SpatialDropout2D(0.8)(x))\n",
    "#     x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = maxpoolconv(512, (2,3), norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    \n",
    "    ffs.reverse()\n",
    "\n",
    "    x = MyDeconv(512, 3, (2,3), name=\"mydeconv7\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = tf.concat([x, ffs[0]], axis=-1)\n",
    "    x = MyDeconv(256, 3, 2, name=\"mydeconv6\", resize_to=None, norm=norm)(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    x = tf.concat([x, ffs[1]], axis=-1)\n",
    "    x = MyDeconv(128, 3, 2, name=\"mydeconv5\", resize_to=None, norm=norm)(x)\n",
    "    x = tf.concat([x, ffs[2]], axis=-1)\n",
    "    x = MyDeconv(64, 3, 2, name=\"mydeconv4\", resize_to=None, norm=norm)(x)\n",
    "    x = tf.concat([x, ffs[3]], axis=-1)\n",
    "    x = MyDeconv(32, 3, 2, name=\"mydeconv3\", resize_to=None, norm=norm)(x)\n",
    "    x = tf.concat([x, ffs[4]], axis=-1)\n",
    "#     x = MyDeconv(128, 3, 1, name=\"mydeconv2\", resize_to=(360, 540))(x)\n",
    "    x = MyDeconv(16, 3, 1, name=\"mydeconv1\", resize_to=(720, 1080), norm=norm)(x)\n",
    "    x = conv(9, 3, 1, name=\"last_conv3\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "    x = conv(3, 3, 1, name=\"last_conv1\", activation=\"sigmoid\", use_init=False, use_bias=True, norm=norm)(x)\n",
    "\n",
    "#     x = deconv(64, kernel_size=1, strides=1, name=\"prelast_deconv\", norm=True)(x)\n",
    "#     x = deconv(3, kernel_size=1, strides=1, name=\"last_deconv\", norm=True)(x)\n",
    "#     x = layers.Conv2DTranspose(3, kernel_size=3, strides=1, padding=\"same\", \n",
    "#                       activation=\"sigmoid\", kernel_initializer=tf.keras.initializers.HeNormal(seed=32))(x)\n",
    "    \n",
    "#     x = MyRescale()(x)\n",
    "    x = tf.keras.layers.Rescaling(255.)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, x)\n",
    "    \n",
    "\n",
    "class RenderImages(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        images_path = f\"./col_100_output_images/\"\n",
    "        image_name = images_path + f\"e_{epoch}.jpg\"\n",
    "#         display.clear_output()\n",
    "        print_validation(lambda x:autoencoder(x, training=False), batch_size=5, save=False, path=\"./\")\n",
    "        \n",
    "class LRMetric(tf.keras.metrics.Mean):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        lr = autoencoder.optimizer.lr\n",
    "        current_lr = lr(autoencoder.optimizer.iterations)\n",
    "        super().update_state(current_lr)\n",
    "        \n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=False,\n",
    "#                                                               patience=10, min_delta=0.)  \n",
    "\n",
    "autoencoder = build_autoencoder_large()\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = 200\n",
    "l2 = 12\n",
    "\n",
    "(l1 // l2) * l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = build_autoencoder_large()\n",
    "\n",
    "initial_learning_rate = 5e-5\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=500,\n",
    "    decay_rate=0.95,\n",
    "    staircase=True)\n",
    "\n",
    "class RenderImages(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        images_path = f\"./col_100_output_images/\"\n",
    "        image_name = images_path + f\"e_{epoch}.jpg\"\n",
    "#         display.clear_output()\n",
    "        print_validation(lambda x:autoencoder(x, training=False), batch_size=2, save=False, path=\"./\", datasets=(large_train_ds, large_test_ds))\n",
    "        \n",
    "        \n",
    "# class RenderImagesWithCast(keras.callbacks.Callback):\n",
    "#     def on_batch_end(self, epoch, logs):\n",
    "#         it = iter(large_test_ds.take(1)\n",
    "#         img = next(it)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img)\n",
    "#         plt.figure()\n",
    "#         print(img.shape)\n",
    "#         y_pred = autoencoder.predict(tf.expand_dims(img, axis=0))\n",
    "#         y_pred = tf.cast(y_pred, tf.uint8)\n",
    "#         plt.imshow(y_pred[0])\n",
    "        \n",
    "#         print_validation(lambda x:autoencoder(x, training=False), batch_size=2, save=False, path=\"./\", datasets=(large_train_ds, large_test_ds))\n",
    "        \n",
    "        \n",
    "opt = tfa.optimizers.AdamW(weight_decay=0.0001, learning_rate=lr_schedule, beta_1=0.8, beta_2=0.99)\n",
    "\n",
    "checkpoint_dir = './prepa_autoencoder_ckpt'\n",
    "checkpoint = tf.train.Checkpoint(model=autoencoder, optimizer=opt)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)\n",
    "\n",
    "# try:\n",
    "#     if ckpt_manager.latest_checkpoint:\n",
    "#         checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "# except:\n",
    "#     print(\"Could not restore the checkopint\")\n",
    "    \n",
    "def on_epoch_end(batch, logs):\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "                                                        \n",
    "lm = tf.keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "class CovMetric(tf.keras.metrics.Mean):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        cov = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(y_true, y_pred)\n",
    "        super().update_state(cov)\n",
    "        \n",
    "        \n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def ploss_ce(true_y, pred_y):\n",
    "    return perceptual_loss(true_y, pred_y)\n",
    "    # print(f\"{label} Min:{tf.math.reduce_min(img, axis=[0,1,2])} Max:{tf.math.reduce_max(img, axis=[0,1,2])} Mean:{tf.math.reduce_mean(img, axis=[0,1,2])}, Variance:{tf.math.reduce_variance(img, axis=[0,1,2])}\")\n",
    "    \n",
    "#     min_loss = mse(tf.math.reduce_min(true_y, axis=[1,2]), tf.math.reduce_min(pred_y, axis=[1,2]))\n",
    "#     max_loss = mse(tf.math.reduce_max(true_y, axis=[1,2]), tf.math.reduce_max(pred_y, axis=[1,2]))\n",
    "# #     mean_loss = mse(tf.math.reduce_mean(true_y, axis=[1,2]), tf.math.reduce_mean(pred_y, axis=[1,2]))\n",
    "# #     variance_loss = mse(tf.math.reduce_variance(true_y, axis=[1,2]), tf.math.reduce_variance(pred_y, axis=[1,2]))\n",
    "    \n",
    "#     return mse(true_y, pred_y) + min_loss + max_loss \n",
    "# #     loss = perceptual_loss(true_y, pred_y)\n",
    "# # #     mse_loss = 0.0\n",
    "#     mse_loss = mse(true_y, pred_y) + 0.000001\n",
    "#     mse_loss = ((loss // mse_loss) // 100) * mse_loss\n",
    "    \n",
    "#     return loss + mse_loss\n",
    "        \n",
    "\n",
    "version = \"v9.1_slower\"\n",
    "    \n",
    "autoencoder.compile(\n",
    "#                     optimizer=\"adam\",\n",
    "#                     optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.6),\n",
    "#                     optimizer=tf.keras.optimizers.experimental.SGD(learning_rate=1e-5),\n",
    "#                 tfa.optimizers.LazyAdam(0.001),\n",
    "                optimizer=tfa.optimizers.AdamW(weight_decay=0.0001, learning_rate=lr_schedule, \n",
    "                                               beta_1=0.8, beta_2=0.99\n",
    "#                                                , clipnorm=5\n",
    "                                              ),\n",
    "#                     loss='mean_squared_error',\n",
    "                loss=ploss_ce,\n",
    "                    metrics=[\"mse\"],\n",
    "#                    metrics=[LRMetric()],\n",
    "                )\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=False,\n",
    "                                                              patience=10, min_delta=0.)  \n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = f\"./prepa_autencoder_logs/{version}\",\n",
    "                  write_graph=True,\n",
    "                  histogram_freq = 1,\n",
    "                  update_freq=\"epoch\"\n",
    "                  )\n",
    "\n",
    "ghistory = autoencoder.fit(large_train_ds.prefetch(tf.data.AUTOTUNE),\n",
    "                                epochs=200, \n",
    "#                                     steps_per_epoch=5, \n",
    "#                                     steps_per_epoch=small_steps_per_epoch,\n",
    "                                validation_data=large_test_ds,\n",
    "      callbacks=[RenderImages(), lm, tboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(large_train_ds)\n",
    "for i in range(20):\n",
    "    next(it)\n",
    "img, img2 = next(it)\n",
    "\n",
    "\n",
    "\n",
    "x = img\n",
    "x = tf.keras.layers.Rescaling(1./255)(x)\n",
    "x = layers.MaxPool2D(2,2)(x)\n",
    "plt.imshow(x[0])\n",
    "plt.figure()\n",
    "x = layers.MaxPool2D(2,2)(x)\n",
    "plt.imshow(x[0])\n",
    "plt.figure()\n",
    "x = layers.MaxPool2D(2,2)(x)\n",
    "plt.imshow(x[0])\n",
    "plt.figure()\n",
    "x = layers.MaxPool2D(2,2)(x)\n",
    "plt.imshow(x[0])\n",
    "plt.figure()\n",
    "x = layers.MaxPool2D(2,3)(x)\n",
    "plt.imshow(x[0])\n",
    "plt.figure()\n",
    "# x = layers.MaxPool2D(2,2)(x)\n",
    "# x = layers.MaxPool2D(2,2)(x)\n",
    "# x = layers.UpSampling2D((2,2))(x)\n",
    "# \n",
    "x = layers.UpSampling2D((2,3))(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Lambda(lambda x: tf.image.resize(x, (360, 540), method=\"nearest\"))(x)\n",
    "x = layers.Lambda(lambda x: tf.image.resize(x, (720, 1080), method=\"nearest\"))(x)\n",
    "x = tf.keras.layers.Rescaling(255)(x)\n",
    "\n",
    "def info(label, img):\n",
    "    print(f\"{label} Min:{tf.math.reduce_min(img, axis=[0,1,2])} Max:{tf.math.reduce_max(img, axis=[0,1,2])} Mean:{tf.math.reduce_mean(img, axis=[0,1,2])}, Variance:{tf.math.reduce_variance(img, axis=[0,1,2])}\")\n",
    "    \n",
    "info(\"IMG\", img)\n",
    "info(\"X\", x)\n",
    "\n",
    "img = tf.cast(img, tf.uint8)\n",
    "img2 = tf.cast(img2, tf.uint8)\n",
    "x = tf.cast(x, tf.uint8)\n",
    "\n",
    "plt.imshow(img[0])\n",
    "plt.figure()\n",
    "plt.imshow(x[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = 480, 720\n",
    "\n",
    "x,y = x/2,y/2\n",
    "print(x,y)\n",
    "x,y = x/2,y/2\n",
    "print(x,y)\n",
    "x,y = x/2,y/2\n",
    "print(x,y)\n",
    "x,y = x/2,y/2\n",
    "print(x,y)\n",
    "x,y = x/2,y/2\n",
    "print(x,y)\n",
    "\n",
    "\n",
    "x,y = x*2,y*2\n",
    "print(x,y)\n",
    "x,y = x*2,y*2\n",
    "print(x,y)\n",
    "x,y = x*2,y*2\n",
    "print(x,y)\n",
    "x,y = x*2,y*2\n",
    "print(x,y)\n",
    "# x,y = x*3,y*3\n",
    "# print(x,y)\n",
    "\n",
    "(x,y),(480, 720), (720, 1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #720, 1080\n",
    "240*1.5, 360*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepa = [(str(p),'png') for p in pathlib.Path(\"./prepa\").glob('*.png')]\n",
    "\n",
    "def gen_prepa():\n",
    "    for img_path, img_type in prepa:\n",
    "        yield gen_img(img_path, img_type)\n",
    "        \n",
    "it = iter(gen_prepa())\n",
    "\n",
    "img = next(it)\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.figure()\n",
    "print(img.shape)\n",
    "y_pred = autoencoder.predict(tf.expand_dims(img, axis=0))\n",
    "y_pred = tf.cast(y_pred, tf.uint8)\n",
    "plt.imshow(y_pred[0])\n",
    "\n",
    "\n",
    "# tf.math.reduce_mean(\n",
    "#     y_pred, axis=[1,2], keepdims=False, name=None\n",
    "# )\n",
    "\n",
    "# y = tf.reshape(y_pred, (1,-1,3))\n",
    "# y = layers.AveragePooling1D(2)(tf.cast(y, tf.float32))\n",
    "# y = layers.AveragePooling1D(2)(tf.cast(y, tf.float32))\n",
    "# y = layers.AveragePooling1D(2)(tf.cast(y, tf.float32))\n",
    "# # y = tf.image.resize(y, (720, 1080))\n",
    "# y\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_learning_rate = 1e-03\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "\n",
    "class RenderImages(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        images_path = f\"./col_100_output_images/\"\n",
    "        image_name = images_path + f\"e_{epoch}.jpg\"\n",
    "#         display.clear_output()\n",
    "        print_validation(lambda x:autoencoder(x, training=False), batch_size=2, save=False, path=\"./\", datasets=(people_ds, people_test_ds))\n",
    "        \n",
    "\n",
    "autoencoder = build_autoencoder()\n",
    "\n",
    "autoencoder.compile(\n",
    "                    optimizer=\"adam\",\n",
    "#                     optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.6),\n",
    "#                 optimizer=tfa.optimizers.AdamW(weight_decay=0.00001, learning_rate=lr_schedule),\n",
    "#                     loss='mean_squared_error',\n",
    "                loss=perceptual_loss,\n",
    "#                     metrics=[\"accuracy\"],\n",
    "#                    metrics=[LRMetric()],\n",
    "                )\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=False,\n",
    "                                                              patience=10, min_delta=0.)  \n",
    "\n",
    "ghistory = autoencoder.fit(people_ds.prefetch(tf.data.AUTOTUNE),\n",
    "                                epochs=10, \n",
    "#                                     steps_per_epoch=5, \n",
    "#                                     steps_per_epoch=small_steps_per_epoch,\n",
    "                                validation_data=people_test_ds.take(5),\n",
    "      callbacks=[RenderImages(), early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_validation(lambda x:autoencoder(x, training=False), batch_size=2, save=False, path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(preds.shape[0]):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(imgs[i])\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.title(\"OpenCV\")\n",
    "    plt.imshow(cv2.fastNlMeansDenoisingColored(imgs[i].numpy(),None,10,10,7,21))\n",
    "    plt.figure()\n",
    "    plt.title(\"UnsharpMask\")\n",
    "    plt.imshow(unsharp(imgs[i]))\n",
    "    plt.figure()\n",
    "    plt.title(\"UnsharpMask on autoencoder\")\n",
    "    plt.imshow(unsharp(preds[i]))\n",
    "    plt.title(\"conservative_smoothing_gray\")\n",
    "    plt.imshow(cv2.bilateralFilter(np.array(unsharp(imgs[i])),9,75,75))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Autoencoder\")\n",
    "    plt.imshow(preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "4327198819dafd55a2243f22aba11bf2a7d9f0c32aced8ba7d18a900e49d0553"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
