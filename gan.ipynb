{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda\n",
    "!export CUDA_DIR=\"/usr/lib/cuda\"\n",
    "!export TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(8)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_virtual_device_configuration(physical_devices[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8000)])\n",
    "# tf.config.experimental.set_virtual_device_configuration(physical_devices[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2000)])\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "# print(\"GPUS: {}\".format(len(physical_devices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "layers = tf.keras.layers\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "# train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "# train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "# !rm -rf ./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return (image -127.5) / 127.5\n",
    "\n",
    "def denormalize(image):\n",
    "    return tf.cast(image * 127.5 + 127.5, np.uint8).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "data_dir = pathlib.Path(\"./prepa\")\n",
    "pictures = list(data_dir.glob('*.png'))\n",
    "pictures.sort()\n",
    "pictures\n",
    "\n",
    "\n",
    "data_dir = pathlib.Path(\"./people\")\n",
    "large_pictures = list(data_dir.glob('*.jpg'))\n",
    "large_pictures.sort()\n",
    "large_pictures[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_w = 720\n",
    "input_h = 480\n",
    "\n",
    "\n",
    "# input_h = 672\n",
    "# input_w = 976\n",
    "\n",
    "# input_h *= 1.2\n",
    "# input_w *= 1.2\n",
    "\n",
    "\n",
    "# input_h = 576\n",
    "# input_w = 864\n",
    "\n",
    "hwfactor = input_h / input_w\n",
    "\n",
    "input_h, input_w\n",
    "\n",
    "BUFFER_SIZE = 800\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "\n",
    "BUFFER_SIZE = 10\n",
    "BATCH_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_h = int(input_h)\n",
    "input_w = int(input_w)\n",
    "input_h, input_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enlarge image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = 1\n",
    "resize_factor = 1/rf # about 0.0833\n",
    "resized_size_h = int(input_h * resize_factor)\n",
    "resized_size_w = int(input_w * resize_factor)\n",
    "\n",
    "print(resized_size_h, resized_size_h * rf, input_h)\n",
    "assert resized_size_h * rf == input_h\n",
    "\n",
    "print(resized_size_w, resized_size_w * rf, input_w)\n",
    "assert resized_size_w * rf == input_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(pictures)\n",
    "large_image_count = len(large_pictures) + len(large_pictures) * 20 * 2\n",
    "print(f\"image_count={image_count}, large_image_count={large_image_count}\")\n",
    "\n",
    "image_count += large_image_count\n",
    "\n",
    "def make_dataset(pictures, large_pictures):\n",
    "  def load_large_images():\n",
    "    for filename in large_pictures:\n",
    "      raw_png = tf.io.read_file(str(filename), name=filename)\n",
    "      decoded_png = tf.image.decode_jpeg(raw_png, channels=3, name=filename)\n",
    "      cropped = tf.image.resize_with_crop_or_pad(\n",
    "          decoded_png,input_h ,input_w\n",
    "      )\n",
    "      yield cropped\n",
    "\n",
    "      for i in range(20):\n",
    "        cropped = tf.image.random_crop(\n",
    "          decoded_png, size=[input_h, input_w, 3])\n",
    "        yield cropped\n",
    "        # yield tf.image.random_flip_left_right(cropped)\n",
    "\n",
    "    for filename in pictures:\n",
    "        raw_png = tf.io.read_file(str(filename), name=filename)\n",
    "        decoded_png_2 = tf.image.decode_png(raw_png, channels=3, name=filename)\n",
    "        decoded_png_2 = tf.image.resize(decoded_png_2, [input_h, input_w],\n",
    "                          method=tf.image.ResizeMethod.BILINEAR)\n",
    "        \n",
    "        yield decoded_png_2\n",
    "        yield tf.image.flip_left_right(decoded_png_2)\n",
    "\n",
    "        \n",
    "\n",
    "  train_ds = tf.data.Dataset.from_generator(load_large_images,  output_signature=\n",
    "         tf.TensorSpec(shape=(input_h, input_w, 3), dtype=tf.float16)).map(normalize)\n",
    "\n",
    "  def resize_and_couple(images):\n",
    "    # return (images,images)\n",
    "    down = tf.image.resize(\n",
    "        images,\n",
    "        [int(resized_size_h / 8), int(resized_size_w / 8)],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None)\n",
    "\n",
    "\n",
    "    return (images, tf.image.resize(\n",
    "        down,\n",
    "        [resized_size_h, resized_size_w],\n",
    "        preserve_aspect_ratio=True,\n",
    "        antialias=False,\n",
    "        name=None))\n",
    "\n",
    "  zipped_train_dataset = train_ds.interleave(\n",
    "      lambda x: tf.data.Dataset.from_tensors(x).map(resize_and_couple, num_parallel_calls=tf.data.AUTOTUNE),\n",
    "      cycle_length=4, num_parallel_calls=tf.data.AUTOTUNE,\n",
    "      deterministic=False\n",
    "  )\n",
    "  # Batch and shuffle the data\n",
    "  return zipped_train_dataset\n",
    "  # train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(1)\n",
    "\n",
    "# lp_imgs = list(train_ds.shuffle(200).take(2))\n",
    "train_ds = make_dataset(pictures, large_pictures).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# i = 1\n",
    "# for img_ind in range(len(lp_imgs)):\n",
    "#     plt.figure(figsize=(12, 9))\n",
    "#     img = denormalize(lp_imgs[img_ind])\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis('off')\n",
    "#     i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_samples(size=2):\n",
    "    some_pictures = random.choices(pictures, k=size)\n",
    "    some_large_pictures = random.choices(large_pictures, k=size) \n",
    "    return make_dataset(some_pictures, some_large_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_size_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_w = input_w\n",
    "model_input_h = input_h\n",
    "\n",
    "model_input_w, model_input_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_size_w, resized_size_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_w, input_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(stride, base_kernel, K):\n",
    "    lst = list(range(0,base_kernel+stride, stride))\n",
    "    return lst[min(range(len(lst)), key = lambda i: abs(lst[i]-K))]\n",
    "\n",
    "closest(2, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsamples_per_scale = {\n",
    "    2: 1,\n",
    "    4: 2,\n",
    "    8: 3\n",
    "}\n",
    "\n",
    "\n",
    "def pixel_shuffle(scale):\n",
    "    return lambda x: tf.nn.depth_to_space(x, scale)\n",
    "\n",
    "\n",
    "def upsample(x_in, num_filters):\n",
    "    x = layers.Conv2D(num_filters, kernel_size=3, padding='same')(x_in)\n",
    "    x = layers.Lambda(pixel_shuffle(scale=2))(x)\n",
    "    return layers.PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "init_fn = tf.keras.initializers.LecunNormal(seed=123)\n",
    "\n",
    "\n",
    "def residual_block(block_input, num_filters, momentum=0.8):\n",
    "    x = layers.Conv2D(num_filters, kernel_size=3, padding='same', kernel_initializer=init_fn)(block_input)\n",
    "    x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    x = layers.Conv2D(num_filters, kernel_size=3, padding='same', kernel_initializer=init_fn)(x)\n",
    "    x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "    return x\n",
    "\n",
    "def make_sgenerator_model(scale=8, num_filters=64):\n",
    "    # needs to be divisible by the stride to avoid checkerboard patterns\n",
    "    base_f = 6\n",
    "    def make_kernel(s):\n",
    "        return closest(min(2,s), s, s*hwfactor)\n",
    "    kernel_size = make_kernel(base_f)\n",
    "    num_upsamples = upsamples_per_scale[scale]\n",
    "\n",
    "    lr = tf.keras.Input(shape=(None, None, 3))\n",
    "    x = layers.Conv2D(32, kernel_size=make_kernel(3), padding='same', kernel_initializer=init_fn, activation='leaky_relu')(lr)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = tf.nn.leaky_relu(x)\n",
    "    x = layers.Concatenate()([x,lr])\n",
    "\n",
    "    f = x\n",
    "\n",
    "    x = layers.Conv2D(32, kernel_size=make_kernel(3), padding='same', kernel_initializer=init_fn, activation='leaky_relu')(lr)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = tf.nn.leaky_relu(x)\n",
    "    x = layers.Concatenate()([x,f])\n",
    "    \n",
    "    f = x\n",
    "\n",
    "    x = layers.Conv2D(32, kernel_size=make_kernel(3), padding='same', kernel_initializer=init_fn, activation='leaky_relu')(lr)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = tf.nn.leaky_relu(x)\n",
    "    x = layers.Concatenate()([x,f])\n",
    "\n",
    "    x = layers.Conv2D(3, kernel_size=9, padding='same', kernel_initializer=init_fn, activation='tanh')(x)\n",
    "    return tf.keras.Model(lr, x, name=\"generator\")\n",
    "make_sgenerator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_grid_size(x):\n",
    "    col = int(math.sqrt(x))\n",
    "    row = int(x / col)\n",
    "\n",
    "    y = int(x - (col*row))\n",
    "    row+=y\n",
    "\n",
    "    return row, col\n",
    "\n",
    "def get_bi_column(x, col=2):\n",
    "    row = int(x / col)\n",
    "\n",
    "    y = int(x - (col*row))\n",
    "    row+=y\n",
    "\n",
    "    return row, col\n",
    "\n",
    "get_bi_column(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_samples_ds = get_random_samples(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.LecunNormal()\n",
    "initializer(shape=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(filters=3, kernel_size=(1,1), name=None, kernel_initializer=\"Zeros\", normalize=False, activation=None, strides=(1,1)):\n",
    "    act = {\n",
    "        \"leaky_relu\": tf.nn.leaky_relu,\n",
    "        \"tanh\": tf.nn.tanh\n",
    "        }\n",
    "    def fn(x):\n",
    "        x = layers.Conv2D(3, kernel_size=kernel_size, kernel_initializer=kernel_initializer, strides=strides, padding=\"same\", name=name)(x)\n",
    "        if (normalize):\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        if activation and activation in act:\n",
    "            print(activation)\n",
    "            x = act[activation](x)\n",
    "        return x\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnvs():\n",
    "    base_f = 1\n",
    "    kernel_size = closest(base_f, base_f, base_f*hwfactor)\n",
    "\n",
    "    kernel_size_100 = closest(100, 100, 100*hwfactor)\n",
    "\n",
    "    convs = [\n",
    "        # (\"Zeros (kernel=100)\", conv(kernel_size=kernel_size_100)),\n",
    "        # (\"Zeros\", conv(kernel_size=kernel_size)),\n",
    "        # (\"Zeros (norm)\", conv(kernel_size=kernel_size, normalize=True)),\n",
    "        # (\"Zeros (norm & relu)\", conv(kernel_size=kernel_size, normalize=True, activation=\"leaky_relu\")),\n",
    "        # (\"Zeros (norm & relu, stride=10)\", conv(kernel_size=kernel_size, normalize=True, strides=(10,10), activation=\"leaky_relu\")),\n",
    "        (\"LecunNormal\", conv(kernel_initializer=tf.keras.initializers.LecunNormal(seed=123))),\n",
    "        (\"LecunNormal (kernel=3)\", conv(kernel_size=closest(3, 3, 3*hwfactor), kernel_initializer=tf.keras.initializers.LecunNormal(seed=123))),\n",
    "        (\"LecunNormal (norm)\", conv(kernel_initializer=tf.keras.initializers.LecunNormal(seed=123), normalize=True)),\n",
    "        (\"LecunNormal (norm & relu)\", conv(kernel_initializer=tf.keras.initializers.LecunNormal(seed=123), normalize=True, activation=\"leaky_relu\")),\n",
    "        (\"LecunNormal (kernel=3, norm & relu)\", conv(kernel_size=closest(3, 3, 3*hwfactor), kernel_initializer=tf.keras.initializers.LecunNormal(seed=123), normalize=True, activation=\"leaky_relu\")),\n",
    "        # (\"VarianceScaling\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.VarianceScaling())),\n",
    "        # (\"VarianceScaling (norm)\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.VarianceScaling(), normalize=True)),\n",
    "        # (\"VarianceScaling (norm & relu)\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.VarianceScaling(), normalize=True, activation=\"leaky_relu\")),\n",
    "        # (\"LecunUniform\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.LecunUniform())),\n",
    "        # (\"LecunUniform (norm)\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.LecunUniform(), normalize=True)),\n",
    "        # (\"LecunUniform (norm & relu)\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.LecunUniform(), normalize=True, activation=\"leaky_relu\"))\n",
    "    ]\n",
    "\n",
    "\n",
    "    for images, resized_images in random_samples_ds.shuffle(125).take(2):\n",
    "        plt.figure()\n",
    "        # plt.figure(figsize=(12,4))\n",
    "       \n",
    "        # im[:,:,1] = 1\n",
    "        # im[:,:,2] = 1\n",
    "        # plt.imshow(im)\n",
    "        # print(images.shape)\n",
    "        # down_model = downsample(3, 4)\n",
    "        # down_result = down_model(tf.cast(tf.expand_dims(images, axis=0), np.float32))\n",
    "        # print (down_result.shape)\n",
    "\n",
    "        # plt.figure()\n",
    "        # plt.title(\"down_result\")\n",
    "        # plt.imshow(denormalize(np.squeeze(down_result)))\n",
    "\n",
    "        # up_model = upsample(3, 4)\n",
    "        # up_result = up_model(down_result)\n",
    "        # print (up_result.shape)\n",
    "\n",
    "        # plt.figure()\n",
    "        # plt.title(\"up_result\")\n",
    "        # plt.imshow(denormalize(np.squeeze(up_result)))\n",
    "        \n",
    "        \n",
    "        for (cname, cfn) in convs:\n",
    "            im = np.copy(images)\n",
    "            conv_image = tf.squeeze(cfn(tf.cast(tf.expand_dims(im, axis=0), np.float16)))\n",
    "            pp = lambda x: (np.max(np.unique(x)), np.min(np.unique(x)))\n",
    "            print(cname, pp(im), pp(conv_image))\n",
    "            plt.figure(figsize=(12,4))\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.title(\"Original\")\n",
    "            plt.imshow(denormalize(im))\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.title(f\"Conv: {cname}\")\n",
    "            plt.imshow(denormalize(conv_image))\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1,3,3)\n",
    "            plt.title(f\"Original + Conv: {cname}\")\n",
    "            if conv_image.shape != im.shape:\n",
    "                im = tf.image.resize(im, [conv_image.shape[0], conv_image.shape[1]])\n",
    "            plt.imshow(denormalize(tf.add(conv_image, im)))\n",
    "            plt.axis('off')\n",
    "\n",
    "# test_cnvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_generator(generator, discriminator, size=2):\n",
    "    # test_dataset = tf.data.Dataset.zip((train_ds, resized_ds))\n",
    "    \n",
    "\n",
    "    sample = random.randrange(0, image_count-size-1)\n",
    "    test_data = random_samples_ds.shuffle(sample).take(size).batch(size)\n",
    "    for images, resized_images in test_data:\n",
    "        generated_images = generator(resized_images, training=False)\n",
    "\n",
    "        print(f\"images={images.shape}, resized_images={resized_images.shape}, generated_images={generated_images.shape}\")\n",
    "\n",
    "        imgs = zip(images, resized_images, generated_images)\n",
    "\n",
    "        col, row = get_bi_column(size*3, 3)\n",
    "\n",
    "        # print(f\"col={col}, row={row}\")\n",
    "\n",
    "        fig = plt.figure(figsize=(row * 10, col * 7))\n",
    "\n",
    "        i = 0\n",
    "        for img_set in imgs:\n",
    "            for img in img_set:\n",
    "                plt.subplot(col, row, i+1)\n",
    "                im = np.copy(img)\n",
    "                im = denormalize(im)\n",
    "                plt.imshow(im)\n",
    "                plt.axis('off')\n",
    "                i += 1\n",
    "\n",
    "        decision = discriminator(generated_images)\n",
    "        print (f\"Decision for the scaled images: {decision}\")\n",
    "\n",
    "\n",
    "    return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[input_h, input_w, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "generator = make_sgenerator_model()\n",
    "\n",
    "generated_image = test_generator(generator, discriminator, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[1000, 10000], values=[1e-2, 1e-4, 1e-5])\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = f'logs/gan/train/{current_time}'\n",
    "train_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './gan4_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)\n",
    "try:\n",
    "    if ckpt_manager.latest_checkpoint:\n",
    "        checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "except:\n",
    "    print(\"Could not restore the checkopint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(generator, discriminator, epoch, save=True): \n",
    "  predictions = test_generator(generator, discriminator, 3)\n",
    "  if save == True:\n",
    "    plt.savefig('./gan_output/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "generate_and_save_images(generator, discriminator, 0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "import sys\n",
    "\n",
    "def sigint_handler(signal, frame):\n",
    "    print ('KeyboardInterrupt is caught')\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    sys.exit(0)\n",
    "signal.signal(signal.SIGINT, sigint_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "# with tf.device(gpus[0].name):\n",
    "\n",
    "class GANModel(tf.keras.Model):\n",
    "  def __init__(self, gen, disc):\n",
    "    super(GANModel, self).__init__(name=\"GANModel\")\n",
    "    self.generator = gen\n",
    "    self.discriminator = disc\n",
    "\n",
    "  def train_step(self, all_images):\n",
    "    images, resized = all_images\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(resized, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        _gen_loss = gen_loss\n",
    "        \n",
    "        images = tf.cast(images, tf.float32)\n",
    "        \n",
    "        ssim = tf.math.reduce_sum(tf.image.ssim(images, generated_images, 255.0))\n",
    "        ms_ssim = tf.math.reduce_sum(tf.image.ssim_multiscale(images, generated_images, 255.0))\n",
    "        \n",
    "        gen_loss += (1.0 - ssim) + (1.0 - ms_ssim)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return {\"gen_loss\": _gen_loss, \"disc_loss\":disc_loss, \"ssim\":ssim, \"ms_ssim\":ms_ssim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs=None):\n",
    "    generate_and_save_images(generator, discriminator,\n",
    "                    epoch + 1)\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                                ckpt_save_path))\n",
    "# def on_batch_end(batch, logs=None):\n",
    "#     if batch % 10 == 0:\n",
    "#         train_log_dir = 'logs/gan/train'\n",
    "#         train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "#         tf.summary.trace_export(\n",
    "#                 \"train\", step=batch, profiler_outdir=train_log_dir\n",
    "#             )\n",
    "#         tf.summary.scalar('gen_loss', gen_loss_m.result(), step=i)\n",
    "#         tf.summary.scalar('perc_loss', perc_loss_m.result(), step=i)\n",
    "#         tf.summary.scalar('disc_loss', disc_loss_m.result(), step=i)\n",
    "#         train_summary_writer.flush()\n",
    "                                                        \n",
    "lm = tf.keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = train_log_dir,\n",
    "      write_graph=True, # visualize the graph\n",
    "     histogram_freq = 1, update_freq=100,\n",
    "     profile_batch = (1,600))\n",
    "\n",
    "# train(train_ds, EPOCHS)\n",
    "model = GANModel(generator, discriminator)\n",
    "model.compile(metrics=[\"gen_loss\", \"disc_loss\", \"ms_ssim\", \"ms\"])\n",
    "model.fit(train_ds.repeat(), epochs=400, callbacks=[tboard_callback, lm], steps_per_epoch=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_model(model, new_input_shape=(None, 40, 40, 3)):\n",
    "    # replace input shape of first layer\n",
    "    # model.layers[1].batch_input_shape = new_input_shape\n",
    "    # input_layer = layers.InputLayer(input_shape=new_input_shape, name=\"input_1\")\n",
    "    # model.input = input_layer\n",
    "\n",
    "    new_model = make_sgenerator_model(new_input_shape)\n",
    "\n",
    "    # feel free to modify additional parameters of other layers, for example...\n",
    "    # model._layers[2].pool_size = (8, 8)\n",
    "    # model._layers[2].strides = (8, 8)\n",
    "\n",
    "    # rebuild model architecture by exporting and importing via json\n",
    "    # new_model = keras.models.model_from_json(model.to_json())\n",
    "    new_model.summary()\n",
    "\n",
    "    # copy weights from old model to new one\n",
    "    for layer in new_model.layers:\n",
    "        try:\n",
    "            layer.set_weights(model.get_layer(name=layer.name).get_weights())\n",
    "        except:\n",
    "            print(\"Could not transfer weights for layer {}\".format(layer.name))\n",
    "\n",
    "    # test new model on a random input image\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = checkpoint_dir+\"/weights/weights-{epoch:04d}.ckpt\"\n",
    "\n",
    "generator.save_weights(checkpoint_path.format(epoch=0))\n",
    "discriminator.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./weights/gan/2/{}/\"\n",
    "\n",
    "gen_path = os.path.join(save_path.format(\"generator\"))\n",
    "tf.saved_model.save(generator, gen_path)\n",
    "disc_path = os.path.join(save_path.format(\"discriminator\"))\n",
    "tf.saved_model.save(discriminator, disc_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_generator = tf.saved_model.load(gen_path)\n",
    "loaded_discriminator = tf.saved_model.load(disc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save_images(loaded_generator, loaded_discriminator,\n",
    "                             9999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3eb1d97f310157d3301c56d5a4919c8700f9ebf12a6d6528ee13f9dc017cc412"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
