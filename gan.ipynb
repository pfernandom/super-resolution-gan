{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda\n",
    "!export CUDA_DIR=\"/usr/lib/cuda\"\n",
    "!export TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.threading.set_inter_op_parallelism_threads(0)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(0)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_virtual_device_configuration(physical_devices[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8000)])\n",
    "# tf.config.experimental.set_virtual_device_configuration(physical_devices[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2000)])\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "# print(\"GPUS: {}\".format(len(physical_devices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "layers = tf.keras.layers\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "# train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "# train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "# !rm -rf ./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return (image -127.5) / 127.5\n",
    "\n",
    "def denormalize(image):\n",
    "    return tf.cast(image * 127.5 + 127.5, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_w = 720\n",
    "input_h = 480\n",
    "\n",
    "\n",
    "# input_h = 672\n",
    "# input_w = 976\n",
    "\n",
    "# input_h *= 1.2\n",
    "# input_w *= 1.2\n",
    "\n",
    "\n",
    "# input_h = 576\n",
    "# input_w = 864\n",
    "\n",
    "hwfactor = input_h / input_w\n",
    "\n",
    "input_h, input_w\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "EPOCHS=1000\n",
    "STEPS_PER_EPOCH = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_h = int(input_h)\n",
    "input_w = int(input_w)\n",
    "input_h, input_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enlarge image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = 1\n",
    "resize_factor = 1/rf # about 0.0833\n",
    "resized_size_h = int(input_h * resize_factor)\n",
    "resized_size_w = int(input_w * resize_factor)\n",
    "\n",
    "print(resized_size_h, resized_size_h * rf, input_h)\n",
    "assert resized_size_h * rf == input_h\n",
    "\n",
    "print(resized_size_w, resized_size_w * rf, input_w)\n",
    "assert resized_size_w * rf == input_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def image_generator(pictures = [], large_pictures = [], ds_pictures = [], return_ext=False):\n",
    "    def parse_name(filename):\n",
    "        return \"{}_\" + re.sub(r\"\\.(png|jpeg|jpg)\", r\"_{}.\\1\", os.path.basename(filename))\n",
    "    \n",
    "    def format_name(name, subname):\n",
    "        return name.format(random.randint(0, 1000), subname)\n",
    "    def fn():\n",
    "        for filename in pictures:\n",
    "            fname = parse_name(filename)\n",
    "            raw_png = tf.io.read_file(str(filename), name=filename)\n",
    "            decoded_png_2 = tf.image.decode_png(raw_png, channels=3, name=filename)\n",
    "            decoded_png_2 = tf.image.resize(decoded_png_2, [input_h, input_w],\n",
    "                              method=tf.image.ResizeMethod.BILINEAR)\n",
    "\n",
    "            yield decoded_png_2, format_name(fname, \"original\")\n",
    "            yield tf.image.flip_left_right(decoded_png_2), format_name(fname, \"flipped\")\n",
    "\n",
    "        for filename in ds_pictures:\n",
    "            fname =  parse_name(filename)\n",
    "            raw_png = tf.io.read_file(str(filename), name=filename)\n",
    "            decoded_png = tf.image.decode_jpeg(raw_png, channels=3, name=filename)\n",
    "            cropped = tf.image.resize_with_crop_or_pad(\n",
    "              decoded_png,input_h ,input_w\n",
    "            )\n",
    "            yield cropped, format_name(fname, \"original\")\n",
    "            yield tf.image.flip_left_right(cropped), format_name(fname, \"center_crop\")\n",
    "\n",
    "            for i in range(200):\n",
    "                cropped = tf.image.random_crop(\n",
    "                  decoded_png, size=[input_h, input_w, 3])\n",
    "                yield cropped, format_name(fname, \"random_crop_\"+str(i))\n",
    "                yield tf.image.flip_left_right(cropped), format_name(fname, \"random_crop_and_flip_\"+str(i))\n",
    "\n",
    "        for filename in large_pictures:\n",
    "            fname =  parse_name(filename)\n",
    "            raw_png = tf.io.read_file(str(filename), name=filename)\n",
    "            decoded_png = tf.image.decode_jpeg(raw_png, channels=3, name=filename)\n",
    "            cropped = tf.image.resize_with_crop_or_pad(\n",
    "              decoded_png,input_h ,input_w\n",
    "            )\n",
    "            yield cropped, format_name(fname, \"center_crop\")\n",
    "\n",
    "            for i in range(20):\n",
    "                cropped = tf.image.random_crop(\n",
    "                  decoded_png, size=[input_h, input_w, 3])\n",
    "                yield cropped, format_name(fname, \"random_crop_\"+str(i))\n",
    "            # yield tf.image.random_flip_left_right(cropped)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from multiprocessing import Lock, Process, Queue, current_process, Value, Pool, cpu_count\n",
    "from concurrent import futures\n",
    "\n",
    "def cache_images():\n",
    "    data_dir = pathlib.Path(\"./prepa\")\n",
    "    pictures = list(data_dir.glob('*.png'))\n",
    "\n",
    "\n",
    "    data_dir = pathlib.Path(\"./people\")\n",
    "    large_pictures = list(data_dir.glob('*.jpg'))\n",
    "\n",
    "\n",
    "    data_dir = pathlib.Path(\"./ds_images\")\n",
    "    ds_pictures = list(data_dir.glob('*.jpg'))\n",
    "    \n",
    "    approx_size = len(pictures)*2 + len(ds_pictures)*2 + len(ds_pictures)*200*2 + len(large_pictures) + len(large_pictures)*20\n",
    "    \n",
    "    gen = image_generator(pictures, large_pictures, ds_pictures)\n",
    "    \n",
    "    \n",
    "    print(\"starting\")\n",
    "    counter = Value('i', 0)\n",
    "    \n",
    "        \n",
    "    it = iter(gen())\n",
    "    con = True\n",
    "    \n",
    "    np = cpu_count()\n",
    "    print(f'You have {np} cores')\n",
    "\n",
    "\n",
    "\n",
    "    def f1(im, filename):\n",
    "            im.numpy()\n",
    "            tf.keras.utils.save_img('./tmp/{}'.format(filename), im)\n",
    "            with counter.get_lock():\n",
    "                counter.value += 1\n",
    "\n",
    "            if (counter.value % 10 == 0):\n",
    "                clear_output(wait=True)\n",
    "                print(f\"{counter.value+1}/{approx_size}\")   \n",
    "            return f\"{im.shape} {filename}\"\n",
    "    with futures.ThreadPoolExecutor(max_workers=16) as executor:    \n",
    "        for im, filename  in it:\n",
    "#             im, filename = next(it)\n",
    "            future = executor.submit(f1, im, filename)\n",
    "#             future.add_done_callback(lambda x: print(f\"donee: {x}\"))\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('generated an exception: %s' % exc)\n",
    "        else:\n",
    "            print('%r page is' % data)\n",
    "    \n",
    "\n",
    "# cache_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the cached images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def image_generator_cached(size=None):\n",
    "    data_dir = pathlib.Path(\"./tmp\")\n",
    "    all_files = []\n",
    "    for filename in list(data_dir.glob('*.png')):\n",
    "        all_files.append((filename, 'png'))\n",
    "    for filename in list(data_dir.glob('*.jpg')):\n",
    "        all_files.append((filename, 'jpg'))\n",
    "    \n",
    "    random.shuffle(all_files)\n",
    "    if size:\n",
    "        all_files = all_files[:size]\n",
    "    \n",
    "    def fn():\n",
    "        for filename, img_type in all_files:\n",
    "            raw_image = tf.io.read_file(str(filename), name=filename)\n",
    "            if img_type == \"png\":\n",
    "                yield tf.image.decode_png(raw_image, channels=3, name=filename)\n",
    "            elif img_type == \"jpg\":\n",
    "                yield tf.image.decode_jpeg(raw_image, channels=3, name=filename)\n",
    "            \n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(pathlib.Path(\"./tmp\").glob('*')))\n",
    "print(f\"image_count={image_count}\")\n",
    "\n",
    "fraction = int((STEPS_PER_EPOCH * EPOCHS) / image_count)\n",
    "print(fraction)\n",
    "\n",
    "dataset_size = int((STEPS_PER_EPOCH * EPOCHS) / (fraction + 1))\n",
    "print(f\"better dataset size: {dataset_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dataset(size=None):\n",
    "    load_large_images = image_generator_cached(size)\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_generator(load_large_images,  output_signature=\n",
    "         tf.TensorSpec(shape=(input_h, input_w, 3), dtype=tf.float16)).map(normalize)\n",
    "\n",
    "    def resize_and_couple(images):\n",
    "        # return (images,images)\n",
    "        down = tf.image.resize(\n",
    "            images,\n",
    "            [int(resized_size_h / 8), int(resized_size_w / 8)],\n",
    "            preserve_aspect_ratio=True,\n",
    "            antialias=False,\n",
    "            name=None)\n",
    "\n",
    "\n",
    "        return (images, tf.image.resize(\n",
    "            down,\n",
    "            [resized_size_h, resized_size_w],\n",
    "            preserve_aspect_ratio=True,\n",
    "            antialias=False,\n",
    "            name=None))\n",
    "\n",
    "    zipped_train_dataset = train_ds.interleave(\n",
    "      lambda x: tf.data.Dataset.from_tensors(x).map(resize_and_couple, num_parallel_calls=tf.data.AUTOTUNE),\n",
    "      cycle_length=4, num_parallel_calls=tf.data.AUTOTUNE,\n",
    "      deterministic=False\n",
    "    )\n",
    "    # Batch and shuffle the data\n",
    "    return zipped_train_dataset\n",
    "    # train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(1)\n",
    "\n",
    "# lp_imgs = list(train_ds.shuffle(200).take(2))\n",
    "train_ds = make_dataset(dataset_size).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_samples(size=2):\n",
    "    return make_dataset(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_size_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_w = input_w\n",
    "model_input_h = input_h\n",
    "\n",
    "model_input_w, model_input_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_size_w, resized_size_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_w, input_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(stride, base_kernel, K):\n",
    "    lst = list(range(0,base_kernel+stride, stride))\n",
    "    return lst[min(range(len(lst)), key = lambda i: abs(lst[i]-K))]\n",
    "\n",
    "closest(2, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_grid_size(x):\n",
    "    col = int(math.sqrt(x))\n",
    "    row = int(x / col)\n",
    "\n",
    "    y = int(x - (col*row))\n",
    "    row+=y\n",
    "\n",
    "    return row, col\n",
    "\n",
    "def get_bi_column(x, col=2):\n",
    "    row = int(x / col)\n",
    "\n",
    "    y = int(x - (col*row))\n",
    "    row+=y\n",
    "\n",
    "    return row, col\n",
    "\n",
    "get_bi_column(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_generator(generator, discriminator, size=2):\n",
    "    # test_dataset = tf.data.Dataset.zip((train_ds, resized_ds))\n",
    "    random_samples_ds = get_random_samples(size)\n",
    "    test_data = random_samples_ds.batch(size)\n",
    "    for images, resized_images in test_data:\n",
    "        generated_images = generator(resized_images, training=False)\n",
    "\n",
    "        print(f\"images={images.shape}, resized_images={resized_images.shape}, generated_images={generated_images.shape}\")\n",
    "\n",
    "        imgs = zip(images, resized_images, generated_images)\n",
    "\n",
    "        col, row = get_bi_column(size*3, 3)\n",
    "\n",
    "        # print(f\"col={col}, row={row}\")\n",
    "\n",
    "        fig = plt.figure(figsize=(row * 10, col * 7))\n",
    "\n",
    "        i = 0\n",
    "        for img_set in imgs:\n",
    "            for img in img_set:\n",
    "                plt.subplot(col, row, i+1)\n",
    "                im = np.copy(img)\n",
    "                im = denormalize(im)\n",
    "                plt.imshow(im)\n",
    "                plt.axis('off')\n",
    "                i += 1\n",
    "\n",
    "        decision = discriminator(generated_images, training=False)\n",
    "        print(f\"Decision shape: {decision.shape}\")\n",
    "        print (f\"Decision for the scaled images: {decision}\")\n",
    "\n",
    "\n",
    "    return generated_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "model = VGG19(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    ")\n",
    "model.trainable = False\n",
    "\n",
    "content_model = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.output\n",
    ")\n",
    "\n",
    "\n",
    "# model = VGG19(\n",
    "#     include_top=False,\n",
    "#     weights='imagenet',\n",
    "# )\n",
    "# model.trainable = False\n",
    "\n",
    "# def load_and_process_image(image_path):\n",
    "#     img = load_img(image_path)\n",
    "#     # convert image to array\n",
    "#     img = img_to_array(img)\n",
    "#     img = preprocess_input(img)\n",
    "#     img = np.expand_dims(img, axis=0)\n",
    "#     return img\n",
    "\n",
    "# def deprocess(img):\n",
    "#     # perform the inverse of the pre processing step\n",
    "#     i = np.copy(img)\n",
    "#     i[:, :, 0] += 103.939\n",
    "#     i[:, :, 1] += 116.779\n",
    "#     i[:, :, 2] += 123.68\n",
    "#     # convert RGB to BGR\n",
    "#     i = i[:, :, ::-1]\n",
    " \n",
    "#     i = np.clip(i, 0, 255).astype('uint8')\n",
    "#     return i\n",
    " \n",
    " \n",
    "# def display_image(img):\n",
    "#     # remove one dimension if image has 4 dimension\n",
    "#     if len(img.shape) == 4:\n",
    "#         img = np.squeeze(img, axis=0)\n",
    " \n",
    "#     img = deprocess(img)\n",
    " \n",
    "#     plt.grid(False)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.imshow(img)\n",
    "#     return\n",
    "\n",
    "# content_path = \"people/82561291_1774936235970438_4637967906859122688_o-1.jpg\"\n",
    "# content_img = load_and_process_image(content_path)\n",
    "# display_image(content_img)\n",
    "\n",
    "\n",
    "# def get_content_model():\n",
    "#     content_layer = 'block5_conv2'\n",
    "#     content_model = tf.keras.Model(\n",
    "#         inputs=model.input,\n",
    "#         outputs=model.get_layer(content_layer).output\n",
    "#     )\n",
    "#     # content_model.summary()\n",
    "#     return content_model\n",
    "\n",
    "# c_model = get_content_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_kernel(s):\n",
    "        return closest(min(2,s), s, s*hwfactor), s\n",
    "\n",
    "# init_fn = tf.keras.initializers.LecunUniform(seed=123)\n",
    "# init_fn = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "def residual_block(block_input, filters=64, momentum=0.8):\n",
    "#     x = layers.Conv2D(filters, kernel_size=3, padding='same', kernel_initializer=init_fn)(block_input)\n",
    "    x = tfa.layers.SpectralNormalization(\n",
    "        layers.Conv2D(filters, kernel_size=3, padding='same'))(block_input)\n",
    "#     x = tfa.layers.SpectralNormalization(\n",
    "#         layers.Conv2D(filters, kernel_size=3, padding='same', kernel_initializer=init_fn))(block_input)\n",
    "#     x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "#     x = tfa.layers.SpectralNormalization(\n",
    "#         layers.Conv2D(filters, kernel_size=3, padding='same', kernel_initializer=init_fn))(x)\n",
    "    x = tfa.layers.SpectralNormalization(\n",
    "        layers.Conv2D(filters, kernel_size=3, padding='same'))(x)\n",
    "#     x = layers.Conv2D(filters, kernel_size=3, padding='same', kernel_initializer=init_fn)(x)\n",
    "#     x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    x = layers.Add()([block_input,x]) \n",
    "#     x = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True, \n",
    "#                                          beta_initializer=\"random_uniform\", gamma_initializer=\"random_uniform\")(x)\n",
    "#     x = tfa.layers.GroupNormalization(groups=8, axis=3)(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def pixel_shuffle(x, channels, downsampleFactor, momentum=0.8):\n",
    "    if downsampleFactor == 1:\n",
    "#         x = layers.Conv2D(channels * (downsampleFactor ** 2), 3, padding=\"same\",\n",
    "#                activation=\"relu\", kernel_initializer=\"Orthogonal\",\n",
    "#                          strides=2)(x)\n",
    "#         x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "        x = tfa.layers.SpectralNormalization(\n",
    "            layers.Conv2D(channels * 2, 3, padding=\"same\",\n",
    "               activation=\"leaky_relu\", kernel_initializer=\"Orthogonal\",\n",
    "                         strides=2))(x)\n",
    "        outputs = tf.nn.depth_to_space(x, 2)\n",
    "    else:\n",
    "        x = tfa.layers.SpectralNormalization(\n",
    "            layers.Conv2D(channels * (downsampleFactor * 2), 3, padding=\"same\",\n",
    "               activation=\"relu\", kernel_initializer=\"Orthogonal\"))(x)\n",
    "#         x = layers.Conv2D(channels * (downsampleFactor ** 2), 3, padding=\"same\",\n",
    "#                activation=\"relu\", kernel_initializer=\"Orthogonal\")(x)\n",
    "#         x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "        outputs = tf.nn.depth_to_space(x, downsampleFactor)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def upscale_block(block_input, filters=64, scale=1):\n",
    "# def upscale_block(block_input, filters=128, scale=1):\n",
    "#     x = layers.Conv2D(filters, kernel_size=3, padding='same', kernel_initializer=init_fn)(block_input)\n",
    "    x = tfa.layers.SpectralNormalization(\n",
    "        layers.Conv2D(filters, kernel_size=3, padding='same'))(block_input)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "    x = pixel_shuffle(x, filters, 1)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def make_sgenerator_model(scale=8, num_filters=64):\n",
    "    # needs to be divisible by the stride to avoid checkerboard patterns\n",
    "    block_size = 64\n",
    "    \n",
    "\n",
    "    inputs = tf.keras.Input(shape=(None, None, 3))\n",
    "    pre_x = layers.Conv2D(block_size, kernel_size=9, padding='same')(inputs)\n",
    "#     pre_x = layers.Conv2D(block_size, kernel_size=9, padding='same', kernel_initializer=init_fn)(inputs)\n",
    "#     pre_x = layers.BatchNormalization()(pre_x)\n",
    "    pre_x = layers.PReLU(shared_axes=[1, 2])(pre_x)\n",
    "    \n",
    "    x = residual_block(pre_x)\n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    \n",
    "    x = tfa.layers.SpectralNormalization(\n",
    "        layers.Conv2D(block_size, kernel_size=3, padding='same'))(x)\n",
    "#     x =  layers.Conv2D(block_size, kernel_size=3, padding='same', kernel_initializer=init_fn)(inputs)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([pre_x,x])\n",
    "#     x = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True, \n",
    "#                                          beta_initializer=\"random_uniform\", gamma_initializer=\"random_uniform\")(x)\n",
    "#     x = tfa.layers.GroupNormalization(groups=8, axis=3)(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = upscale_block(x)\n",
    "#     x = upscale_block(x)\n",
    "    \n",
    "#     x = layers.Conv2D(3, kernel_size=9, padding='same', kernel_initializer=init_fn, activation='tanh')(x)\n",
    "#     x = tfa.layers.WeightNormalization(data_init=False)(x)\n",
    "    x = layers.Conv2D(3, kernel_size=9, padding='same', activation='tanh')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, x, name=\"generator\")\n",
    "# test_model = make_sgenerator_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_bloc(filters, strides):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tfa.layers.SpectralNormalization(\n",
    "        layers.Conv2D(filters, kernel_size=3, strides=strides, padding='same')))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    return model\n",
    "    \n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    filters = 64\n",
    "    model.add(\n",
    "        layers.Conv2D(filters, kernel_size=3, padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(disc_bloc(filters, 2))\n",
    "#     model.add(disc_bloc(filters*2, 1))\n",
    "    model.add(disc_bloc(filters*2, 2))\n",
    "#     model.add(disc_bloc(filters*4, 1))\n",
    "    model.add(disc_bloc(filters*4, 2))\n",
    "#     model.add(disc_bloc(filters*8, 1))\n",
    "    model.add(disc_bloc(filters*8, 2))\n",
    "    model.add(layers.Dense(1024))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "generator = make_sgenerator_model()\n",
    "\n",
    "discriminator.build(input_shape=[2, input_h, input_w, 3])\n",
    "print(discriminator.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    \n",
    "    total_loss = (real_loss + fake_loss)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = f'logs/gan/train/{current_time}'\n",
    "train_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(generator, discriminator, epoch, save=True): \n",
    "    predictions = test_generator(generator, discriminator, 3)\n",
    "    if save == True:\n",
    "        plt.savefig('./gan_output/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# generate_and_save_images(generator, discriminator, 0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "import sys\n",
    "\n",
    "def sigint_handler(signal, frame):\n",
    "    print ('KeyboardInterrupt is caught')\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    sys.exit(0)\n",
    "signal.signal(signal.SIGINT, sigint_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrgen=tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[1000, 10000], values=[0.1, 1e-4, 1e-5])\n",
    "# lrdist=tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[1000, 10000], values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0004, beta_1=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './gan5_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if ckpt_manager.latest_checkpoint:\n",
    "        checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "except:\n",
    "    print(\"Could not restore the checkopint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "# with tf.device(gpus[0].name):\n",
    "\n",
    "class GANModel(tf.keras.Model):\n",
    "  def __init__(self, gen, disc):\n",
    "    super(GANModel, self).__init__(name=\"GANModel\")\n",
    "    self.generator = gen\n",
    "    self.discriminator = disc\n",
    "\n",
    "  def train_step(self, all_images):\n",
    "    images, resized = all_images\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(resized, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        \n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        _gen_loss = gen_loss\n",
    "        \n",
    "        mse = tf.reduce_mean(tf.square(tf.cast(images, tf.float32) - generated_images))\n",
    "        gen_loss+=mse*100\n",
    "        \n",
    "        #         # avoid too large errors\n",
    "#         real_output = tf.clip_by_value(real_output, 0.0, 255.0)\n",
    "#         fake_output = tf.clip_by_value(fake_output, 0.0, 255.0)\n",
    "        \n",
    "        #         # avoid too large errors\n",
    "#         real_output = tf.clip_by_value(real_output, 0.0, 255.0)\n",
    "#         fake_output = tf.clip_by_value(fake_output, 0.0, 255.0)\n",
    "        \n",
    "        ssim_loss =   (same_ms_ssim - ssim)\n",
    "        ms_ssim_loss =  (same_ms_ssim - ms_ssim)\n",
    "        ssim_losses =  tf.math.minimum(gen_loss, ssim_loss + ms_ssim_loss)\n",
    "        \n",
    "#         gen_loss += ssim_losses\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "#     gradients_of_generator, _ = tf.clip_by_global_norm(gradients_of_generator, 5.0)\n",
    "#     gradients_of_discriminator, _ = tf.clip_by_global_norm(gradients_of_discriminator, 5.0)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return {\"gen_loss\": gen_loss, \"disc_loss\":disc_loss, \"_gen_loss\": _gen_loss,\n",
    "            \"mse\":mse,\n",
    "#             \"ssim_loss\":ssim_loss, \"ms_ssim_loss\":ms_ssim_loss, \n",
    "            \"ssim\":ssim, \"ms_ssim\":ms_ssim, \"same_ms_ssim\":same_ms_ssim }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs=None):\n",
    "    pass\n",
    "#     clear_output(wait=True)\n",
    "#     generate_and_save_images(generator, discriminator,\n",
    "#                     epoch + 1)\n",
    "#     ckpt_save_path = ckpt_manager.save()\n",
    "#     print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "#                                                                 ckpt_save_path))\n",
    "def on_batch_begin(batch, logs):\n",
    "    if batch % 900 == 0:\n",
    "        print(\"Logs:\")\n",
    "        print(logs)\n",
    "        if \"gen_loss\" in logs:\n",
    "            \n",
    "            tf.summary.scalar('batch_gen_loss', logs[\"gen_loss\"], step=batch*BATCH_SIZE)\n",
    "            tf.summary.scalar('batch_disc_loss', logs[\"disc_loss\"], step=batch*BATCH_SIZE)\n",
    "            tf.summary.scalar('ms_ssim', logs[\"ms_ssim\"], step=batch*BATCH_SIZE)\n",
    "        clear_output(wait=True)\n",
    "        generate_and_save_images(generator, discriminator,\n",
    "                        batch + 1)\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for batch {} at {}'.format(batch+1,\n",
    "                                                                    ckpt_save_path))\n",
    "                                                        \n",
    "lm = tf.keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end, on_batch_begin=on_batch_begin)\n",
    "\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = train_log_dir,\n",
    "      write_graph=True, # visualize the graph\n",
    "     histogram_freq = 1, update_freq=100,\n",
    "#      profile_batch = (1,200)\n",
    "                                                )\n",
    "\n",
    "# train(train_ds, EPOCHS)\n",
    "model = GANModel(generator, discriminator)\n",
    "model.compile(metrics=[\"gen_loss\", \"disc_loss\", \"ms_ssim\"])\n",
    "# model.compile(metrics=[\"gen_loss\", \"disc_loss\", \"ms_ssim\", \"ms\"], run_eagerly=True)\n",
    "model.fit(\n",
    "    train_ds.repeat(),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[tboard_callback, lm],\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#     steps_per_epoch=int(image_count/BATCH_SIZE),\n",
    "    workers=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_model(model, new_input_shape=(None, 40, 40, 3)):\n",
    "    # replace input shape of first layer\n",
    "    # model.layers[1].batch_input_shape = new_input_shape\n",
    "    # input_layer = layers.InputLayer(input_shape=new_input_shape, name=\"input_1\")\n",
    "    # model.input = input_layer\n",
    "\n",
    "    new_model = make_sgenerator_model(new_input_shape)\n",
    "\n",
    "    # feel free to modify additional parameters of other layers, for example...\n",
    "    # model._layers[2].pool_size = (8, 8)\n",
    "    # model._layers[2].strides = (8, 8)\n",
    "\n",
    "    # rebuild model architecture by exporting and importing via json\n",
    "    # new_model = keras.models.model_from_json(model.to_json())\n",
    "    new_model.summary()\n",
    "\n",
    "    # copy weights from old model to new one\n",
    "    for layer in new_model.layers:\n",
    "        try:\n",
    "            layer.set_weights(model.get_layer(name=layer.name).get_weights())\n",
    "        except:\n",
    "            print(\"Could not transfer weights for layer {}\".format(layer.name))\n",
    "\n",
    "    # test new model on a random input image\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = checkpoint_dir+\"/weights/weights-{epoch:04d}.ckpt\"\n",
    "\n",
    "generator.save_weights(checkpoint_path.format(epoch=0))\n",
    "discriminator.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./weights/gan/2/{}/\"\n",
    "\n",
    "gen_path = os.path.join(save_path.format(\"generator\"))\n",
    "tf.saved_model.save(generator, gen_path)\n",
    "disc_path = os.path.join(save_path.format(\"discriminator\"))\n",
    "tf.saved_model.save(discriminator, disc_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_generator = tf.saved_model.load(gen_path)\n",
    "loaded_discriminator = tf.saved_model.load(disc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save_images(loaded_generator, loaded_discriminator,\n",
    "                             9999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2744f6c25693ac877979453ded1c25dc1ff02e7b3df8339df6da7a707ce476a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
