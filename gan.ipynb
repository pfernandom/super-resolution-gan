{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda\n",
    "!export CUDA_DIR=\"/usr/lib/cuda\"\n",
    "!export TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.threading.set_inter_op_parallelism_threads(0)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(0)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_virtual_device_configuration(physical_devices[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8000)])\n",
    "# tf.config.experimental.set_virtual_device_configuration(physical_devices[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2000)])\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "# print(\"GPUS: {}\".format(len(physical_devices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "layers = tf.keras.layers\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "# train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "# train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "# !rm -rf ./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return (image -127.5) / 127.5\n",
    "\n",
    "def denormalize(image):\n",
    "    return tf.cast(image * 127.5 + 127.5, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_w = 720\n",
    "input_h = 480\n",
    "\n",
    "\n",
    "# input_h = 672\n",
    "# input_w = 976\n",
    "\n",
    "# input_h *= 1.2\n",
    "# input_w *= 1.2\n",
    "\n",
    "\n",
    "# input_h = 576\n",
    "# input_w = 864\n",
    "\n",
    "hwfactor = input_h / input_w\n",
    "\n",
    "input_h, input_w\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "EPOCHS=400\n",
    "STEPS_PER_EPOCH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_h = int(input_h)\n",
    "input_w = int(input_w)\n",
    "input_h, input_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enlarge image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = 1\n",
    "resize_factor = 1/rf # about 0.0833\n",
    "resized_size_h = int(input_h * resize_factor)\n",
    "resized_size_w = int(input_w * resize_factor)\n",
    "\n",
    "print(resized_size_h, resized_size_h * rf, input_h)\n",
    "assert resized_size_h * rf == input_h\n",
    "\n",
    "print(resized_size_w, resized_size_w * rf, input_w)\n",
    "assert resized_size_w * rf == input_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def image_generator(pictures = [], large_pictures = [], ds_pictures = [], return_ext=False):\n",
    "    def parse_name(filename):\n",
    "        return \"{}_\" + re.sub(r\"\\.(png|jpeg|jpg)\", r\"_{}.\\1\", os.path.basename(filename))\n",
    "    \n",
    "    def format_name(name, subname):\n",
    "        return name.format(random.randint(0, 1000), subname)\n",
    "    def fn():\n",
    "        for filename in pictures:\n",
    "            fname = parse_name(filename)\n",
    "            raw_png = tf.io.read_file(str(filename), name=filename)\n",
    "            decoded_png_2 = tf.image.decode_png(raw_png, channels=3, name=filename)\n",
    "            decoded_png_2 = tf.image.resize(decoded_png_2, [input_h, input_w],\n",
    "                              method=tf.image.ResizeMethod.BILINEAR)\n",
    "\n",
    "            yield decoded_png_2, format_name(fname, \"original\")\n",
    "            yield tf.image.flip_left_right(decoded_png_2), format_name(fname, \"flipped\")\n",
    "\n",
    "        for filename in ds_pictures:\n",
    "            fname =  parse_name(filename)\n",
    "            raw_png = tf.io.read_file(str(filename), name=filename)\n",
    "            decoded_png = tf.image.decode_jpeg(raw_png, channels=3, name=filename)\n",
    "            cropped = tf.image.resize_with_crop_or_pad(\n",
    "              decoded_png,input_h ,input_w\n",
    "            )\n",
    "            yield cropped, format_name(fname, \"original\")\n",
    "            yield tf.image.flip_left_right(cropped), format_name(fname, \"center_crop\")\n",
    "\n",
    "            for i in range(200):\n",
    "                cropped = tf.image.random_crop(\n",
    "                  decoded_png, size=[input_h, input_w, 3])\n",
    "                yield cropped, format_name(fname, \"random_crop_\"+str(i))\n",
    "                yield tf.image.flip_left_right(cropped), format_name(fname, \"random_crop_and_flip_\"+str(i))\n",
    "\n",
    "        for filename in large_pictures:\n",
    "            fname =  parse_name(filename)\n",
    "            raw_png = tf.io.read_file(str(filename), name=filename)\n",
    "            decoded_png = tf.image.decode_jpeg(raw_png, channels=3, name=filename)\n",
    "            cropped = tf.image.resize_with_crop_or_pad(\n",
    "              decoded_png,input_h ,input_w\n",
    "            )\n",
    "            yield cropped, format_name(fname, \"center_crop\")\n",
    "\n",
    "            for i in range(20):\n",
    "                cropped = tf.image.random_crop(\n",
    "                  decoded_png, size=[input_h, input_w, 3])\n",
    "                yield cropped, format_name(fname, \"random_crop_\"+str(i))\n",
    "            # yield tf.image.random_flip_left_right(cropped)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from multiprocessing import Lock, Process, Queue, current_process, Value, Pool, cpu_count\n",
    "from concurrent import futures\n",
    "\n",
    "def cache_images():\n",
    "    data_dir = pathlib.Path(\"./prepa\")\n",
    "    pictures = list(data_dir.glob('*.png'))\n",
    "\n",
    "\n",
    "    data_dir = pathlib.Path(\"./people\")\n",
    "    large_pictures = list(data_dir.glob('*.jpg'))\n",
    "\n",
    "\n",
    "    data_dir = pathlib.Path(\"./ds_images\")\n",
    "    ds_pictures = list(data_dir.glob('*.jpg'))\n",
    "    \n",
    "    approx_size = len(pictures)*2 + len(ds_pictures)*2 + len(ds_pictures)*200*2 + len(large_pictures) + len(large_pictures)*20\n",
    "    \n",
    "    gen = image_generator(pictures, large_pictures, ds_pictures)\n",
    "    \n",
    "    \n",
    "    print(\"starting\")\n",
    "    counter = Value('i', 0)\n",
    "    \n",
    "        \n",
    "    it = iter(gen())\n",
    "    con = True\n",
    "    \n",
    "    np = cpu_count()\n",
    "    print(f'You have {np} cores')\n",
    "\n",
    "\n",
    "\n",
    "    def f1(im, filename):\n",
    "            im.numpy()\n",
    "            tf.keras.utils.save_img('./tmp/{}'.format(filename), im)\n",
    "            with counter.get_lock():\n",
    "                counter.value += 1\n",
    "\n",
    "            if (counter.value % 10 == 0):\n",
    "                clear_output(wait=True)\n",
    "                print(f\"{counter.value+1}/{approx_size}\")   \n",
    "            return f\"{im.shape} {filename}\"\n",
    "    with futures.ThreadPoolExecutor(max_workers=16) as executor:    \n",
    "        for im, filename  in it:\n",
    "#             im, filename = next(it)\n",
    "            future = executor.submit(f1, im, filename)\n",
    "#             future.add_done_callback(lambda x: print(f\"donee: {x}\"))\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('generated an exception: %s' % exc)\n",
    "        else:\n",
    "            print('%r page is' % data)\n",
    "    \n",
    "\n",
    "# cache_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the cached images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def image_generator_cached(size=None):\n",
    "    data_dir = pathlib.Path(\"./tmp\")\n",
    "    all_files = []\n",
    "    for filename in list(data_dir.glob('*.png')):\n",
    "        all_files.append((filename, 'png'))\n",
    "    for filename in list(data_dir.glob('*.jpg')):\n",
    "        all_files.append((filename, 'jpg'))\n",
    "    \n",
    "    random.shuffle(all_files)\n",
    "    if size:\n",
    "        all_files = all_files[:size]\n",
    "    \n",
    "    def fn():\n",
    "        for filename, img_type in all_files:\n",
    "            raw_image = tf.io.read_file(str(filename), name=filename)\n",
    "            if img_type == \"png\":\n",
    "                yield tf.image.decode_png(raw_image, channels=3, name=filename)\n",
    "            elif img_type == \"jpg\":\n",
    "                yield tf.image.decode_jpeg(raw_image, channels=3, name=filename)\n",
    "            \n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(pathlib.Path(\"./tmp\").glob('*')))\n",
    "print(f\"image_count={image_count}\")\n",
    "\n",
    "fraction = int((STEPS_PER_EPOCH * EPOCHS) / image_count)\n",
    "print(fraction)\n",
    "\n",
    "dataset_size = int((STEPS_PER_EPOCH * EPOCHS) / (fraction + 1))\n",
    "print(f\"better dataset size: {dataset_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dataset(size=None):\n",
    "    load_large_images = image_generator_cached(size)\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_generator(load_large_images,  output_signature=\n",
    "         tf.TensorSpec(shape=(input_h, input_w, 3), dtype=tf.float16)).map(normalize)\n",
    "\n",
    "    def resize_and_couple(images):\n",
    "        # return (images,images)\n",
    "        down = tf.image.resize(\n",
    "            images,\n",
    "            [int(resized_size_h / 8), int(resized_size_w / 8)],\n",
    "            preserve_aspect_ratio=True,\n",
    "            antialias=False,\n",
    "            name=None)\n",
    "\n",
    "\n",
    "        return (images, tf.image.resize(\n",
    "            down,\n",
    "            [resized_size_h, resized_size_w],\n",
    "            preserve_aspect_ratio=True,\n",
    "            antialias=False,\n",
    "            name=None))\n",
    "\n",
    "    zipped_train_dataset = train_ds.interleave(\n",
    "      lambda x: tf.data.Dataset.from_tensors(x).map(resize_and_couple, num_parallel_calls=tf.data.AUTOTUNE),\n",
    "      cycle_length=4, num_parallel_calls=tf.data.AUTOTUNE,\n",
    "      deterministic=False\n",
    "    )\n",
    "    # Batch and shuffle the data\n",
    "    return zipped_train_dataset\n",
    "    # train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(1)\n",
    "\n",
    "# lp_imgs = list(train_ds.shuffle(200).take(2))\n",
    "train_ds = make_dataset(dataset_size).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_samples(size=2):\n",
    "    return make_dataset(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_size_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_w = input_w\n",
    "model_input_h = input_h\n",
    "\n",
    "model_input_w, model_input_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_size_w, resized_size_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_w, input_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(stride, base_kernel, K):\n",
    "    lst = list(range(0,base_kernel+stride, stride))\n",
    "    return lst[min(range(len(lst)), key = lambda i: abs(lst[i]-K))]\n",
    "\n",
    "closest(2, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_grid_size(x):\n",
    "    col = int(math.sqrt(x))\n",
    "    row = int(x / col)\n",
    "\n",
    "    y = int(x - (col*row))\n",
    "    row+=y\n",
    "\n",
    "    return row, col\n",
    "\n",
    "def get_bi_column(x, col=2):\n",
    "    row = int(x / col)\n",
    "\n",
    "    y = int(x - (col*row))\n",
    "    row+=y\n",
    "\n",
    "    return row, col\n",
    "\n",
    "get_bi_column(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "num_random_samples = 10\n",
    "random_samples_ds = get_random_samples(num_random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.LecunNormal()\n",
    "initializer(shape=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(filters=3, kernel_size=(1,1), name=None, kernel_initializer=\"Zeros\", normalize=False, activation=None, strides=(1,1)):\n",
    "    act = {\n",
    "        \"leaky_relu\": tf.nn.leaky_relu,\n",
    "        \"tanh\": tf.nn.tanh\n",
    "        }\n",
    "    def fn(x):\n",
    "        x = layers.Conv2D(3, kernel_size=kernel_size, kernel_initializer=kernel_initializer, strides=strides, padding=\"same\", name=name)(x)\n",
    "        if (normalize):\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        if activation and activation in act:\n",
    "            print(activation)\n",
    "            x = act[activation](x)\n",
    "        return x\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnvs():\n",
    "    base_f = 1\n",
    "    kernel_size = closest(base_f, base_f, base_f*hwfactor)\n",
    "\n",
    "    kernel_size_100 = closest(100, 100, 100*hwfactor)\n",
    "\n",
    "    convs = [\n",
    "        # (\"Zeros (kernel=100)\", conv(kernel_size=kernel_size_100)),\n",
    "        # (\"Zeros\", conv(kernel_size=kernel_size)),\n",
    "        # (\"Zeros (norm)\", conv(kernel_size=kernel_size, normalize=True)),\n",
    "        # (\"Zeros (norm & relu)\", conv(kernel_size=kernel_size, normalize=True, activation=\"leaky_relu\")),\n",
    "        # (\"Zeros (norm & relu, stride=10)\", conv(kernel_size=kernel_size, normalize=True, strides=(10,10), activation=\"leaky_relu\")),\n",
    "        (\"LecunNormal\", conv(kernel_initializer=tf.keras.initializers.LecunNormal(seed=123))),\n",
    "        (\"LecunNormal (kernel=3)\", conv(kernel_size=closest(3, 3, 3*hwfactor), kernel_initializer=tf.keras.initializers.LecunNormal(seed=123))),\n",
    "        (\"LecunNormal (norm)\", conv(kernel_initializer=tf.keras.initializers.LecunNormal(seed=123), normalize=True)),\n",
    "        (\"LecunNormal (norm & relu)\", conv(kernel_initializer=tf.keras.initializers.LecunNormal(seed=123), normalize=True, activation=\"leaky_relu\")),\n",
    "        (\"LecunNormal (kernel=3, norm & relu)\", conv(kernel_size=closest(3, 3, 3*hwfactor), kernel_initializer=tf.keras.initializers.LecunNormal(seed=123), normalize=True, activation=\"leaky_relu\")),\n",
    "        # (\"VarianceScaling\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.VarianceScaling())),\n",
    "        # (\"VarianceScaling (norm)\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.VarianceScaling(), normalize=True)),\n",
    "        # (\"VarianceScaling (norm & relu)\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.VarianceScaling(), normalize=True, activation=\"leaky_relu\")),\n",
    "        # (\"LecunUniform\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.LecunUniform())),\n",
    "        # (\"LecunUniform (norm)\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.LecunUniform(), normalize=True)),\n",
    "        # (\"LecunUniform (norm & relu)\", conv(kernel_size=kernel_size, kernel_initializer=tf.keras.initializers.LecunUniform(), normalize=True, activation=\"leaky_relu\"))\n",
    "    ]\n",
    "\n",
    "\n",
    "    for images, resized_images in random_samples_ds.shuffle(125).take(2):\n",
    "        plt.figure()\n",
    "        # plt.figure(figsize=(12,4))\n",
    "       \n",
    "        # im[:,:,1] = 1\n",
    "        # im[:,:,2] = 1\n",
    "        # plt.imshow(im)\n",
    "        # print(images.shape)\n",
    "        # down_model = downsample(3, 4)\n",
    "        # down_result = down_model(tf.cast(tf.expand_dims(images, axis=0), np.float32))\n",
    "        # print (down_result.shape)\n",
    "\n",
    "        # plt.figure()\n",
    "        # plt.title(\"down_result\")\n",
    "        # plt.imshow(denormalize(np.squeeze(down_result)))\n",
    "\n",
    "        # up_model = upsample(3, 4)\n",
    "        # up_result = up_model(down_result)\n",
    "        # print (up_result.shape)\n",
    "\n",
    "        # plt.figure()\n",
    "        # plt.title(\"up_result\")\n",
    "        # plt.imshow(denormalize(np.squeeze(up_result)))\n",
    "        \n",
    "        \n",
    "        for (cname, cfn) in convs:\n",
    "            im = np.copy(images)\n",
    "            conv_image = tf.squeeze(cfn(tf.cast(tf.expand_dims(im, axis=0), np.float16)))\n",
    "            pp = lambda x: (np.max(np.unique(x)), np.min(np.unique(x)))\n",
    "            print(cname, pp(im), pp(conv_image))\n",
    "            plt.figure(figsize=(12,4))\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.title(\"Original\")\n",
    "            plt.imshow(denormalize(im))\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.title(f\"Conv: {cname}\")\n",
    "            plt.imshow(denormalize(conv_image))\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1,3,3)\n",
    "            plt.title(f\"Original + Conv: {cname}\")\n",
    "            if conv_image.shape != im.shape:\n",
    "                im = tf.image.resize(im, [conv_image.shape[0], conv_image.shape[1]])\n",
    "            plt.imshow(denormalize(tf.add(conv_image, im)))\n",
    "            plt.axis('off')\n",
    "\n",
    "# test_cnvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_generator(generator, discriminator, size=2):\n",
    "    # test_dataset = tf.data.Dataset.zip((train_ds, resized_ds))\n",
    "    \n",
    "\n",
    "    sample = random.randrange(size, num_random_samples-1)\n",
    "    test_data = random_samples_ds.shuffle(sample).take(size).batch(size)\n",
    "    for images, resized_images in test_data:\n",
    "        generated_images = generator(resized_images, training=False)\n",
    "\n",
    "        print(f\"images={images.shape}, resized_images={resized_images.shape}, generated_images={generated_images.shape}\")\n",
    "\n",
    "        imgs = zip(images, resized_images, generated_images)\n",
    "\n",
    "        col, row = get_bi_column(size*3, 3)\n",
    "\n",
    "        # print(f\"col={col}, row={row}\")\n",
    "\n",
    "        fig = plt.figure(figsize=(row * 10, col * 7))\n",
    "\n",
    "        i = 0\n",
    "        for img_set in imgs:\n",
    "            for img in img_set:\n",
    "                plt.subplot(col, row, i+1)\n",
    "                im = np.copy(img)\n",
    "                im = denormalize(im)\n",
    "                plt.imshow(im)\n",
    "                plt.axis('off')\n",
    "                i += 1\n",
    "\n",
    "        decision = discriminator(generated_images)\n",
    "        print(f\"Decision shape: {decision.shape}\")\n",
    "        print (f\"Decision for the scaled images: {decision}\")\n",
    "\n",
    "\n",
    "    return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_architecture(down_stack, up_stack, v=False):\n",
    "    sample = random.randrange(0, image_count-1)\n",
    "    test_data = random_samples_ds.shuffle(1).take(1).batch(1)\n",
    "    def p(x):\n",
    "        if v:\n",
    "            print(x)\n",
    "            \n",
    "    for images, inputs in test_data:\n",
    "           \n",
    "#         inputs = tf.constant(range(input_w*input_h*2*3), tf.float16)\n",
    "#         inputs = tf.reshape(inputs, (2,input_w, input_h, 3))\n",
    "\n",
    "    #     print((2,input_w, input_h, 3))\n",
    "        p(inputs.shape)\n",
    "\n",
    "        x = inputs\n",
    "\n",
    "        skips = []\n",
    "        i = 0\n",
    "        for down in down_stack:\n",
    "            p(f\"Down: {i}\")\n",
    "            x = down(x)\n",
    "            i+=1\n",
    "            p(x.shape)\n",
    "            skips.append(x)\n",
    "\n",
    "        skips = reversed(skips[:-1])\n",
    "\n",
    "        i = 0\n",
    "        for up, skip in zip(up_stack, skips):\n",
    "            p(f\"Up: {i}\")\n",
    "            x = up(x)\n",
    "            p(x.shape)\n",
    "            i+=1\n",
    "\n",
    "        assert upsample(3, 3)(x).shape == inputs.shape\n",
    "    #     x = tf.keras.layers.Concatenate()([x, skip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_kernel(s):\n",
    "        return closest(min(2,s), s, s*hwfactor), s\n",
    "\n",
    "def pixel_shuffle(scale):\n",
    "    return lambda x: tf.nn.depth_to_space(x, scale)\n",
    "\n",
    "init_fn = tf.keras.initializers.LecunUniform(seed=123)\n",
    "\n",
    "def residual_block(block_input, filters=64, momentum=0.8):\n",
    "    x = layers.Conv2D(filters, kernel_size=3, padding='same', kernel_initializer=init_fn)(block_input)\n",
    "    x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    x = layers.Conv2D(filters, kernel_size=3, padding='same', kernel_initializer=init_fn)(x)\n",
    "    x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    x = layers.Add()([block_input,x]) \n",
    "    return x\n",
    "\n",
    "def pixel_shuffle(x, channels, downsampleFactor):\n",
    "    if downsampleFactor == 1:\n",
    "        x = layers.Conv2D(channels * (downsampleFactor ** 2), 3, padding=\"same\",\n",
    "               activation=\"relu\", kernel_initializer=\"Orthogonal\",\n",
    "                         strides=2)(x)\n",
    "        outputs = tf.nn.depth_to_space(x, 2)\n",
    "    else:\n",
    "        x = layers.Conv2D(channels * (downsampleFactor ** 2), 3, padding=\"same\",\n",
    "               activation=\"relu\", kernel_initializer=\"Orthogonal\")(x)\n",
    "        outputs = tf.nn.depth_to_space(x, downsampleFactor)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def upscale_block(block_input, filters=256, scale=1):\n",
    "# def upscale_block(block_input, filters=128, scale=1):\n",
    "    x = layers.Conv2D(filters, kernel_size=3, padding='same', kernel_initializer=init_fn)(block_input)\n",
    "    x = pixel_shuffle(x, filters, 1)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def make_sgenerator_model(scale=8, num_filters=64):\n",
    "    # needs to be divisible by the stride to avoid checkerboard patterns\n",
    "    block_size = 64\n",
    "    \n",
    "\n",
    "    inputs = tf.keras.Input(shape=(None, None, 3))\n",
    "    pre_x = layers.Conv2D(block_size, kernel_size=9, padding='same', kernel_initializer=init_fn)(inputs)\n",
    "    pre_x = layers.PReLU(shared_axes=[1, 2])(pre_x)\n",
    "    \n",
    "    x = residual_block(pre_x)\n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    \n",
    "    x = layers.Conv2D(block_size, kernel_size=3, padding='same', kernel_initializer=init_fn)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([pre_x,x])\n",
    "    \n",
    "    x = upscale_block(x)\n",
    "    x = upscale_block(x)\n",
    "    \n",
    "    x = layers.Conv2D(3, kernel_size=9, padding='same', kernel_initializer=init_fn)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, x, name=\"generator\")\n",
    "# test_model = make_sgenerator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (input_w, input_h)\n",
    "x = x[0] / 2, x[1] / 2\n",
    "print(x)\n",
    "x = x[0] / 2, x[1] / 2\n",
    "print(x)\n",
    "x = x[0] / 2, x[1] / 2\n",
    "print(x)\n",
    "x = x[0] / 2, x[1] / 2\n",
    "print(x)\n",
    "x = x[0] / 3, x[1] / 2\n",
    "print(x)\n",
    "x = x[0] / 3, x[1] / 3\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_discriminator_model():\n",
    "#     model = tf.keras.Sequential()\n",
    "#     model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "#                                      input_shape=[input_h, input_w, 3]))\n",
    "#     model.add(layers.LeakyReLU())\n",
    "#     model.add(layers.Dropout(0.3))\n",
    "\n",
    "#     model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "#     model.add(layers.LeakyReLU())\n",
    "#     model.add(layers.Dropout(0.3))\n",
    "\n",
    "#     model.add(layers.Flatten())\n",
    "#     model.add(layers.Dense(1))\n",
    "\n",
    "#     return model\n",
    "\n",
    "def disc_bloc(filters, strides):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(filters, kernel_size=3, strides=strides, padding='same', kernel_initializer=init_fn))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    return model\n",
    "    \n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, kernel_size=3, padding='same', kernel_initializer=init_fn))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(disc_bloc(64, 2))\n",
    "    model.add(disc_bloc(128, 1))\n",
    "    model.add(disc_bloc(128, 2))\n",
    "    model.add(disc_bloc(256, 1))\n",
    "    model.add(disc_bloc(256, 2))\n",
    "    model.add(disc_bloc(512, 1))\n",
    "    model.add(disc_bloc(512, 2))\n",
    "    model.add(layers.Dense(1024))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "generator = make_sgenerator_model()\n",
    "\n",
    "discriminator.build(input_shape=[2, input_h, input_w, 3])\n",
    "print(discriminator.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(tf.constant([255,255], tf.float16),tf.constant([1,1], tf.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bce_loss(self, real, pred):\n",
    "#     # compute binary cross entropy loss without reduction\n",
    "#     BCE = tf.keras.losses.BinaryCrossentropy(reduction=Reduction.NONE)\n",
    "#     loss = BCE(real, pred)\n",
    "#     # compute reduced mean over the entire batch\n",
    "#     loss = reduce_mean(loss) * (1. / self.numReplicas)\n",
    "#     # return reduced bce loss\n",
    "#     return loss\n",
    "\n",
    "# def mse_loss(self, real, pred):\n",
    "#     # compute mean squared error loss without reduction\n",
    "#     MSE = tf.keras.losses.MeanSquaredError(reduction=Reduction.NONE)\n",
    "#     loss = MSE(real, pred)\n",
    "#     # compute reduced mean over the entire batch\n",
    "#     loss = reduce_mean(loss) * (1. / self.numReplicas)\n",
    "#     # return reduced mse loss\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = f'logs/gan/train/{current_time}'\n",
    "train_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(generator, discriminator, epoch, save=True): \n",
    "  predictions = test_generator(generator, discriminator, 3)\n",
    "  if save == True:\n",
    "    plt.savefig('./gan_output/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "generate_and_save_images(generator, discriminator, 0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "import sys\n",
    "\n",
    "def sigint_handler(signal, frame):\n",
    "    print ('KeyboardInterrupt is caught')\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    sys.exit(0)\n",
    "signal.signal(signal.SIGINT, sigint_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrgen=tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[1000, 10000], values=[0.1, 1e-4, 1e-5])\n",
    "# lrdist=tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[1000, 10000], values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './gan4_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if ckpt_manager.latest_checkpoint:\n",
    "        checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "except:\n",
    "    print(\"Could not restore the checkopint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "# with tf.device(gpus[0].name):\n",
    "\n",
    "class GANModel(tf.keras.Model):\n",
    "  def __init__(self, gen, disc):\n",
    "    super(GANModel, self).__init__(name=\"GANModel\")\n",
    "    self.generator = gen\n",
    "    self.discriminator = disc\n",
    "\n",
    "  def train_step(self, all_images):\n",
    "    images, resized = all_images\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(resized, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        \n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        _gen_loss = gen_loss\n",
    "        \n",
    "        images = tf.cast(images, tf.float32)\n",
    "        \n",
    "        #         # avoid too large errors\n",
    "        real_output = tf.clip_by_value(real_output, 0.0, 255.0)\n",
    "        fake_output = tf.clip_by_value(fake_output, 0.0, 255.0)\n",
    "        \n",
    "        dimages = denormalize(images)\n",
    "        dgenerated_images = denormalize(generated_images)\n",
    "        ssim = tf.math.reduce_sum(tf.image.ssim(dimages, dgenerated_images, 255.0))\n",
    "        ms_ssim = tf.math.reduce_sum(tf.image.ssim_multiscale(dimages, dgenerated_images, 255.0))\n",
    "        same_ms_ssim = tf.math.reduce_sum(tf.image.ssim_multiscale(dimages, dimages, 255.0))\n",
    "        \n",
    "        ssim_loss = (same_ms_ssim - ssim)\n",
    "        ms_ssim_loss = (same_ms_ssim - ms_ssim)\n",
    "        ssim_losses =  tf.math.minimum(gen_loss, ssim_loss + ms_ssim_loss)\n",
    "        \n",
    "#         gen_loss += ssim_losses\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return {\"gen_loss\": gen_loss, \"disc_loss\":disc_loss, \"_gen_loss\": _gen_loss, \"ssim_loss\":ssim_loss,\n",
    "            \"ms_ssim_loss\":ms_ssim_loss, \"ssim\":ssim, \"ms_ssim\":ms_ssim, \"same_ms_ssim\":same_ms_ssim }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs=None):\n",
    "    clear_output(wait=True)\n",
    "    generate_and_save_images(generator, discriminator,\n",
    "                    epoch + 1)\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                                ckpt_save_path))\n",
    "                                                        \n",
    "lm = tf.keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = train_log_dir,\n",
    "      write_graph=True, # visualize the graph\n",
    "     histogram_freq = 1, update_freq=100,\n",
    "#      profile_batch = (1,200)\n",
    "                                                )\n",
    "\n",
    "# train(train_ds, EPOCHS)\n",
    "model = GANModel(generator, discriminator)\n",
    "model.compile(metrics=[\"gen_loss\", \"disc_loss\", \"ms_ssim\", \"ms\"])\n",
    "# model.compile(metrics=[\"gen_loss\", \"disc_loss\", \"ms_ssim\", \"ms\"], run_eagerly=True)\n",
    "model.fit(train_ds.repeat(), epochs=EPOCHS, callbacks=[tboard_callback, lm], steps_per_epoch=STEPS_PER_EPOCH, workers=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def change_model(model, new_input_shape=(None, 40, 40, 3)):\n",
    "    # replace input shape of first layer\n",
    "    # model.layers[1].batch_input_shape = new_input_shape\n",
    "    # input_layer = layers.InputLayer(input_shape=new_input_shape, name=\"input_1\")\n",
    "    # model.input = input_layer\n",
    "\n",
    "    new_model = make_sgenerator_model(new_input_shape)\n",
    "\n",
    "    # feel free to modify additional parameters of other layers, for example...\n",
    "    # model._layers[2].pool_size = (8, 8)\n",
    "    # model._layers[2].strides = (8, 8)\n",
    "\n",
    "    # rebuild model architecture by exporting and importing via json\n",
    "    # new_model = keras.models.model_from_json(model.to_json())\n",
    "    new_model.summary()\n",
    "\n",
    "    # copy weights from old model to new one\n",
    "    for layer in new_model.layers:\n",
    "        try:\n",
    "            layer.set_weights(model.get_layer(name=layer.name).get_weights())\n",
    "        except:\n",
    "            print(\"Could not transfer weights for layer {}\".format(layer.name))\n",
    "\n",
    "    # test new model on a random input image\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = checkpoint_dir+\"/weights/weights-{epoch:04d}.ckpt\"\n",
    "\n",
    "generator.save_weights(checkpoint_path.format(epoch=0))\n",
    "discriminator.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./weights/gan/2/{}/\"\n",
    "\n",
    "gen_path = os.path.join(save_path.format(\"generator\"))\n",
    "tf.saved_model.save(generator, gen_path)\n",
    "disc_path = os.path.join(save_path.format(\"discriminator\"))\n",
    "tf.saved_model.save(discriminator, disc_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_generator = tf.saved_model.load(gen_path)\n",
    "loaded_discriminator = tf.saved_model.load(disc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save_images(loaded_generator, loaded_discriminator,\n",
    "                             9999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3eb1d97f310157d3301c56d5a4919c8700f9ebf12a6d6528ee13f9dc017cc412"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
