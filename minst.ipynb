{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda-11.8/\n",
    "!export CUDA_DIR=\"/usr/local/cuda-11.8/\"\n",
    "!export TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(f\"gpus={gpus}\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten,\\\n",
    "                                    Reshape, LeakyReLU as LR,\\\n",
    "                                    Activation, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display # If using IPython, Colab or Jupyter\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "import datetime\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import NoiseUtil, ImgUtils, DataLoader, DataManager\n",
    "           \n",
    "def train_get():\n",
    "   for x, y in zip(x_train, y_train):\n",
    "        x = tf.expand_dims(x, axis=2)\n",
    "        yield x\n",
    "\n",
    "def test_get():\n",
    "   for x in x_test:\n",
    "        x = tf.expand_dims(x, axis=2)\n",
    "        yield x\n",
    "\n",
    "\n",
    "def add_noise(x,y):\n",
    "    n = NoiseUtil.pixel_noise(x, 25, 5)\n",
    "\n",
    "#     n = x + 0.4 * tf.random.normal(\n",
    "#         x.shape[1:],\n",
    "#         mean=0.0,\n",
    "#         stddev=1.0,\n",
    "#         dtype=tf.dtypes.float32,\n",
    "#     )\n",
    "\n",
    "    return n,y\n",
    "dm = DataManager.create_label_with_input_transform(train_get, test_get, (28,28,1), add_noise)\n",
    "dm.print_validation() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = iter(dm.get_test_data(2))\n",
    "# i,j = next(it)\n",
    "# plt.imshow(ImgUtils.denormalize(j, cast=tf.uint8)[1])\n",
    "# plt.figure()\n",
    "# plt.imshow(ImgUtils.denormalize(NoiseUtil.pixel_noise(j, 10, 5), cast=tf.uint8)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = tf.reshape(tf.constant(range(2*12*12*1)), (2,12,12,1))\n",
    "\n",
    "# NoiseUtil.pixel_noise(im, 10, 2)[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_t(filters, norm=False):\n",
    "    conv = tf.keras.Sequential()\n",
    "    if norm:\n",
    "        conv.add(tfa.layers.SpectralNormalization(\n",
    "            layers.Conv2DTranspose(filters, 2, 2, padding=\"same\")\n",
    "        ))\n",
    "    else:\n",
    "        conv.add(layers.Conv2DTranspose(filters, 2, 2, padding=\"same\"))\n",
    "    conv.add(layers.LeakyReLU())\n",
    "    return conv\n",
    "\n",
    "class InceptionBlock(layers.Layer):\n",
    "\n",
    "    def __init__(self, filters=32, strides=1):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.strides = strides\n",
    "    \n",
    "    def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "        filters = self.filters\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.conv_x1 = get_conv(filters, kernel=2, strides=self.strides)\n",
    "        self.conv_x2 = get_conv(filters, kernel=3, strides=self.strides)\n",
    "        self.conv_x3 = get_conv(filters, kernel=5, strides=self.strides)\n",
    "        self.out = get_conv(filters, kernel=1, strides=1)\n",
    "\n",
    "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "        x1 = self.conv_x1(inputs)\n",
    "        x2 = self.conv_x2(inputs)\n",
    "        x3 = self.conv_x3(inputs)\n",
    "\n",
    "        x = tf.concat([x1,x2,x3], axis=-1)\n",
    "#         x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "def get_conv(filters, kernel=2, strides=2, norm=False):\n",
    "    conv = tf.keras.Sequential()\n",
    "    if norm:\n",
    "        conv.add(tfa.layers.SpectralNormalization(\n",
    "            layers.Conv2D(filters, kernel, strides, padding=\"same\")\n",
    "        ))\n",
    "    else:\n",
    "        conv.add(layers.Conv2D(filters, kernel, strides, padding=\"same\"))\n",
    "    conv.add(layers.LeakyReLU())\n",
    "    return conv\n",
    "    \n",
    "def get_encoder():\n",
    "    encoder = tf.keras.Sequential(name=\"encoder\")\n",
    "    # encoder.add(layers.GaussianDropout(0.2))\n",
    "    encoder.add(InceptionBlock(32))\n",
    "    encoder.add(layers.Dropout(0.5))\n",
    "    \n",
    "    encoder.add(get_conv(128, 3, 1, norm=True))\n",
    "    encoder.add(layers.Dropout(0.5))\n",
    "    \n",
    "    encoder.add(get_conv(256, 3, 2, norm=True))\n",
    "    encoder.add(layers.Dropout(0.5))\n",
    "\n",
    "    encoder.add(get_conv(512, 3, 2, norm=True))\n",
    "    encoder.add(layers.Dropout(0.5))\n",
    "    return encoder\n",
    "\n",
    "def get_decoder():\n",
    "    decoder = tf.keras.Sequential(name=\"decoder\")\n",
    "    decoder.add(get_conv_t(256, norm=True))\n",
    "    decoder.add(layers.Dropout(0.5))\n",
    "    decoder.add(get_conv(128, 3, 1))\n",
    "    decoder.add(layers.Dropout(0.5))\n",
    "    decoder.add(get_conv_t(32))\n",
    "    decoder.add(layers.Dropout(0.5))\n",
    "    decoder.add(get_conv(3, 1, 1))\n",
    "    decoder.add(layers.Dropout(0.5))\n",
    "    decoder.add(layers.Conv2D(1, 3, padding='same', activation='sigmoid'))\n",
    "    return decoder\n",
    "\n",
    "class AutoEncoder(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(AutoEncoder, self).__init__()\n",
    "    \n",
    "  def build(self, input_shape):\n",
    "    self.encoder = get_encoder()\n",
    "    self.decoder = get_decoder()\n",
    "    self.encoder.build(input_shape=input_shape)\n",
    "    sh = self.encoder.output_shape\n",
    "    self.flatten = layers.Flatten()\n",
    "    self.seq1 = layers.Dense(1024)\n",
    "    self.reshape = layers.Reshape([*sh[1:]])\n",
    "    self.inputs_dropout = layers.Dropout(0.5)\n",
    "\n",
    "    \n",
    "  def call(self, inputs):\n",
    "#     x = self.inputs_dropout(inputs)\n",
    "    x = self.encoder(inputs)\n",
    "    x = self.flatten(x)\n",
    "    x = self.reshape(x)\n",
    "    x = self.inputs_dropout(x)\n",
    "    x = self.decoder(x)\n",
    "    \n",
    "    # x_inputs = self.conv_input(inputs)\n",
    "    \n",
    "    # x = self.add([x * self.gamma, x_inputs])\n",
    "    # x = self.attention(x)\n",
    "#     x = self.last(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import SSIM, SSIM_Multiscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = f'logs/minst/minst_v2_spectral4'\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = train_log_dir,\n",
    "  write_graph=True,\n",
    "  histogram_freq = 1,\n",
    "  update_freq=\"batch\"\n",
    "  )\n",
    "\n",
    "EPOCHS = 60\n",
    "model = AutoEncoder()\n",
    "\n",
    "class SkMetrics(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.validation_loss = []\n",
    "        self.epoch_n = 0\n",
    "        self.start = time.time()\n",
    "        tf.summary.scalar(\"start_time\", self.start )\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        self.end = time.time()\n",
    "        tf.summary.scalar(\"end_time\", self.end )\n",
    "        tf.summary.scalar(\"training_time\", self.end-self.start)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.epoch_start = time.time()\n",
    "        tf.summary.scalar(\"epoch_start_time\", self.epoch_start, step=epoch)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.epoch_n = epoch\n",
    "        self.epoch_end = time.time()\n",
    "        tf.summary.scalar(\"epoch_end_time\", self.epoch_end, step=epoch)\n",
    "        tf.summary.scalar(\"epoch_total_time\", self.epoch_end-self.epoch_start, step=epoch)\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        def expand_and_predict(x):\n",
    "            return model(x, training=False)\n",
    "        if batch % 499 == 0 and batch > 0:\n",
    "            display.clear_output()\n",
    "            dm.print_validation(expand_and_predict)\n",
    "        \n",
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        return mse\n",
    "\n",
    "BATCH_SIZE = 25\n",
    "epochs=100\n",
    "steps_per_epoch=500\n",
    "\n",
    "boundaries = [steps_per_epoch*10, steps_per_epoch*25, steps_per_epoch*60, steps_per_epoch*90, steps_per_epoch*95]\n",
    "values = [0.001, 0.00075, 0.0005, 0.0001, 0.00005, 0.00001]\n",
    "learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries, values)\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate_fn)\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# model.compile(run_eagerly=True)\n",
    "model.compile(loss=keras.losses.MeanSquaredError(), optimizer=opt, metrics=[\"mse\", \"accuracy\", SSIM()])\n",
    "history = model.fit(dm.get_training_data(BATCH_SIZE).repeat(), epochs=epochs, steps_per_epoch=steps_per_epoch, validation_data=dm.get_test_data(BATCH_SIZE), callbacks=[SkMetrics(), tboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4327198819dafd55a2243f22aba11bf2a7d9f0c32aced8ba7d18a900e49d0553"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
